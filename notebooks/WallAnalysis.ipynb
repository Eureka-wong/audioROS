{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"figure.max_open_warning\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import get_setup\n",
    "\n",
    "distance = 5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 5)\n",
    "for yaw_deg, marker in zip([0,15,30], [\"o\", \"*\", \"x\"]):\n",
    "    source, mic_positions = get_setup(distance_cm=distance, yaw_deg=yaw_deg)\n",
    "    source_image = [source[0], -source[1]]\n",
    "    for i, mic in enumerate(mic_positions):\n",
    "        label = f\"mic{i}\" if yaw_deg == 0 else None\n",
    "        ax.scatter(*mic*100, label=label, marker=marker, color=f\"C{i}\")\n",
    "    ax.scatter(*mic*100, label=f\"yaw {yaw_deg}deg\", marker=marker, color=f\"C{i}\")\n",
    "ax.plot([4.8*100, 5.2*100], [0, 0], color=\"k\", label=\"wall\")\n",
    "ax.set_title(f\"setup for distance={distance}cm and different angles\")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "h_mics = {l: h for h, l in zip(handles, labels) if 'mic' in l}\n",
    "l1 = ax.legend(h_mics.values(), h_mics.keys(),loc=\"lower right\", bbox_to_anchor=[.3, 0])\n",
    "\n",
    "h_other = {l: h for h, l in zip(handles, labels) if not 'mic' in l}\n",
    "ax.legend(h_other.values(), h_other.keys(),loc=\"lower left\", bbox_to_anchor=[.3, 0])\n",
    "ax.add_artist(l1)\n",
    "\n",
    "ax.set_xlabel(\"x [cm]\")\n",
    "ax.set_ylabel(\"y [cm]\")\n",
    "ax.axis(\"equal\")\n",
    "\n",
    "fig.savefig(f'plots/setup.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental distance-frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = '2021_02_09_wall_tukey';\n",
    "# exp_name = '2021_02_09_wall';\n",
    "\n",
    "#exp_name = \"2021_02_23_wall\";  # old buzzer\n",
    "exp_name = \"2021_02_25_wall\"; # new buzzer\n",
    "#exp_name = \"2021_03_01_flying\"\n",
    "# exp_name = '2020_12_9_rotating';\n",
    "# exp_name = '2020_11_26_wall';\n",
    "# fname = f'results/{exp_name}_real.pkl'\n",
    "\n",
    "overwrite = False # generate new results\n",
    "mic_type = \"audio_deck\"\n",
    "motors = \"all45000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. amplitude study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas_utils import filter_by_dict\n",
    "from wall_detector import WallDetector\n",
    "from generate_df_results import wall_detector_from_df\n",
    "\n",
    "wall_detector = WallDetector()\n",
    "backup_exists = wall_detector.fill_from_backup(exp_name, mic_type, motors)\n",
    "\n",
    "if (not backup_exists) or overwrite:\n",
    "    fname = f\"../experiments/{exp_name}/all_data.pkl\"\n",
    "    # fname = f'../experiments/{exp_name}/battery_data.pkl' # for 2021_02_09_wall, battery study\n",
    "    try:\n",
    "        df_all = pd.read_pickle(fname)\n",
    "        print(\"read\", fname)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error: run wall_analysis.py to parse experiments.\")\n",
    "    wall_detector = wall_detector_from_df(df_all, exp_name, mic_type, motors)\n",
    "    wall_detector.backup(exp_name, mic_type, motors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_detector.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration import fit_distance_slice\n",
    "from simulation import get_amplitude_function\n",
    "\n",
    "all_distances = wall_detector.df.distance.unique()\n",
    "\n",
    "for mic, df_mic in wall_detector.df.groupby('mic'):\n",
    "    mic_idx = int(mic)\n",
    "    for i, (frequency, df_here) in enumerate(df_mic.groupby('frequency')):\n",
    "        label = f\"{frequency:.0f}Hz\"\n",
    "        \n",
    "        # does not make a difference\n",
    "        # df_here = df_here[df_here.magnitude > 2]\n",
    "        distances = df_here.distance.unique()\n",
    "        if len(distances) < len(all_distances): # only plot distances with \"full coverage\"\n",
    "            continue\n",
    "        \n",
    "        fig, ax_fit = plt.subplots()\n",
    "        fig.set_size_inches(7, 5)\n",
    "        # fit the attenuation for this frequency \n",
    "        for d, series in df_here.groupby('distance').magnitude: \n",
    "            ax_fit.scatter([d]*len(series), series.values, color='C0', s=5.0)\n",
    "        ax_fit.scatter([], [], color='C0', s=2.0, label='raw')\n",
    "        mag_series = df_here.groupby('distance').magnitude.median()\n",
    "        ax_fit.plot(mag_series.index, mag_series.values, color='C1', label='median')\n",
    "        \n",
    "        mags = pd.pivot_table(df_here, values='magnitude', index='distance', columns='counter', \n",
    "                              fill_value=0.0)\n",
    "        distances_raw = np.array(mags.index.values, dtype=float)\n",
    "        coeffs_raw, d_slice_raw, cost_raw = fit_distance_slice(\n",
    "            mags.values[:, None, :], \n",
    "            distances_raw, method='minimize',\n",
    "            yaw_deg=0, frequency=frequency, chosen_mics=[mic_idx], \n",
    "            optimize_absorption=True)\n",
    "        ax_fit.plot(distances_raw, d_slice_raw, color='C2', label='fit to raw')\n",
    "        alpha, phase, gain = coeffs_raw\n",
    "        ax_fit.set_title(label)\n",
    "        print(f'gain at {frequency:.0f}Hz: {gain:.2f}, median: {df_here.magnitude.median():.2f}')\n",
    "        \n",
    "        distances_median = mag_series.index\n",
    "        coeffs_median, d_slice_median, cost_median = fit_distance_slice(\n",
    "            mag_series.values[:, None], \n",
    "            distances_median,method='minimize', optimize_absorption=True,\n",
    "            yaw_deg=0, frequency=frequency, chosen_mics=[mic_idx])\n",
    "        ax_fit.plot(distances_median, d_slice_median, color='C3', ls=':', label='fit to median')\n",
    "        #fit_distance_slice()\n",
    "        ax_fit.legend(loc='upper right')\n",
    "        \n",
    "        # find the sigma for this frequency (per distance, and overall)\n",
    "        std_series = df_here.groupby('distance').magnitude.std()\n",
    "        amps = get_amplitude_function(std_series.index, \n",
    "                                      gain, \n",
    "                                      alpha, mic_idx)\n",
    "        fig, ax_freq = plt.subplots()\n",
    "        ax_freq.semilogy(std_series.index, std_series.values, label=label, color=f'C{i}')\n",
    "        ax_freq.semilogy(std_series.index, amps*0.5, ls=':', color=f'C{i}')\n",
    "        ax_freq.semilogy(std_series.index, amps, ls=':', color=f'C{i}')\n",
    "        ax_freq.semilogy(std_series.index, amps*1.5, ls=':', color=f'C{i}')\n",
    "        ax_freq.legend()\n",
    "        ax_freq.set_xlabel('distance [cm]')\n",
    "        ax_freq.set_ylabel('magnitude vs. std [-]')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_detector import prune_df_matrix\n",
    "df_matrix_raw, df_dist, df_freq_raw = wall_detector.get_df_matrix()\n",
    "df_matrix, df_freq, indices = prune_df_matrix(\n",
    "    df_matrix_raw, df_freq_raw, ratio_missing_allowed=0.5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_tools import add_colorbar\n",
    "\n",
    "fig, ax_all = plt.subplots()\n",
    "for mic_idx in range(4):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.pcolormesh(df_dist, df_freq_raw, df_matrix_raw[mic_idx])\n",
    "    ax.set_title(f\"mic{mic_idx} original\")\n",
    "    add_colorbar(fig, ax, im)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.pcolormesh(df_dist, df_freq, df_matrix[mic_idx])\n",
    "    ax.set_title(f\"mic{mic_idx} pruned\")\n",
    "    ax_all.plot(df_freq, np.nanmean(df_matrix[mic_idx], axis=1), label=f'mic{mic_idx}')\n",
    "    add_colorbar(fig, ax, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. study distance slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from simulation import get_dist_slice_theory\n",
    "from copy import deepcopy\n",
    "from pandas_utils import fill_nans\n",
    "\n",
    "def plot_ffts(slice_exp, slice_the, dist):\n",
    "    fig_f, axs_f = plt.subplots(1, slice_exp.shape[0], squeeze=False, sharey=True)\n",
    "    fig_f.set_size_inches(10, 5)\n",
    "    fig_f.suptitle(f\"FFT of standardized distance slices, at frequency {f:.0f}Hz\")\n",
    "    for m in range(slice_exp.shape[0]):\n",
    "        slice_exp_norm = deepcopy(slice_exp[m])\n",
    "        slice_the_norm = deepcopy(slice_the[m])\n",
    "        slice_exp_norm -= np.mean(slice_exp_norm)\n",
    "        slice_the_norm -= np.mean(slice_the_norm)\n",
    "\n",
    "        n = max(len(slice_exp_norm), 1000)\n",
    "        freqs = np.fft.rfftfreq(n, d=dist[1] - dist[0])  # unit: 1/cm\n",
    "        fft_exp = np.abs(np.fft.rfft(slice_exp_norm, n=n))\n",
    "        fft_exp /= np.sum(fft_exp)\n",
    "        fft_theory = np.abs(np.fft.rfft(slice_the_norm, n=n))\n",
    "        fft_theory /= np.sum(fft_theory)\n",
    "\n",
    "        axs_f[0, m].plot(freqs, fft_theory, label=\"theoretical\")\n",
    "        axs_f[0, m].plot(freqs, fft_exp, label=\"measured\")\n",
    "        axs_f[0, m].set_title(f\"mic{m}\")\n",
    "        axs_f[0, m].legend(loc=\"upper right\")\n",
    "    return fig_f\n",
    "\n",
    "valid_freqs = df_freq\n",
    "plot_freqs = [valid_freqs[0], valid_freqs[len(valid_freqs) // 2], valid_freqs[-2]]\n",
    "for i, f in enumerate(df_freq):\n",
    "    slice_exp = df_matrix[:, i, :]\n",
    "    if np.any(np.isnan(slice_exp)):\n",
    "        slice_exp = fill_nans(slice_exp, df_dist)\n",
    "    slice_the = get_dist_slice_theory(f, df_dist).T\n",
    "    \n",
    "    fig_f = plot_ffts(\n",
    "        slice_exp=slice_exp,\n",
    "        slice_the=slice_the,\n",
    "        dist=df_dist,\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration import fit_distance_slice\n",
    "import time\n",
    "\n",
    "fitting_results = pd.DataFrame(\n",
    "    columns=[\"frequency\", \"mic\", \"absorption\", \"gains\", \"offset\", \"method\"]\n",
    ")\n",
    "\n",
    "chosen_mics = range(4)\n",
    "methods = [\"brute\", \"minimize\"]\n",
    "times = {m: [] for m in methods}\n",
    "\n",
    "for i_f, f in enumerate(df_freq):\n",
    "    fig, axs = plt.subplots(1, len(chosen_mics), sharey=True, squeeze=False)\n",
    "    fig.set_size_inches(5 * len(chosen_mics), 5)\n",
    "    fig.suptitle(f\"{f}Hz\")\n",
    "\n",
    "    slice_exp = df_matrix[:, i_f, :]\n",
    "    if np.any(np.isnan(slice_exp)):\n",
    "        slice_exp = fill_nans(slice_exp, df_dist)\n",
    "\n",
    "    # do one fit\n",
    "    coeffs_glob, slice_calib_glob, cost = fit_distance_slice(\n",
    "        slice_exp.T[:, chosen_mics],\n",
    "        df_dist,\n",
    "        yaw_deg=0,\n",
    "        frequency=f,\n",
    "        chosen_mics=chosen_mics,\n",
    "        method=\"minimize\",\n",
    "        optimize_absorption=True,\n",
    "    )\n",
    "    print(f\"absorption at {f}: {coeffs_glob[0]:.2f}\")\n",
    "    # do separate fits\n",
    "    for i, mic_idx in enumerate(chosen_mics):\n",
    "        axs[0, i].plot(\n",
    "            df_dist, slice_exp[mic_idx, :], label=\"experimental\", color=\"C0\"\n",
    "        )\n",
    "        axs[0, i].plot(\n",
    "            df_dist,\n",
    "            slice_calib_glob[:, i],\n",
    "            ls=\":\",\n",
    "            color=\"C0\",\n",
    "            label=\"calibrated one-shot\",\n",
    "        )\n",
    "        axs[0, i].set_title(f\"mic{mic_idx}\")\n",
    "\n",
    "        fitting_results.loc[len(fitting_results), :] = dict(\n",
    "            frequency=f,\n",
    "            mic=mic_idx,\n",
    "            absorption=coeffs_glob[0],\n",
    "            gains=coeffs_glob[2 + i],\n",
    "            offset=coeffs_glob[1],\n",
    "            method=\"one-shot\",\n",
    "        )\n",
    "\n",
    "        for i_m, method in enumerate(methods):\n",
    "            t0 = time.time()\n",
    "            coeffs, slice_calib, cost = fit_distance_slice(\n",
    "                slice_exp.T[:, [mic_idx]],\n",
    "                df_dist,\n",
    "                yaw_deg=0,\n",
    "                frequency=f,\n",
    "                chosen_mics=[mic_idx],\n",
    "                method=method,\n",
    "                optimize_absorption=True,\n",
    "            )\n",
    "            times[method].append(time.time() - t0)\n",
    "            fitting_results.loc[len(fitting_results), :] = dict(\n",
    "                frequency=f,\n",
    "                mic=mic_idx,\n",
    "                absorption=coeffs[0],\n",
    "                gains=coeffs[2:],\n",
    "                offset=coeffs[1],\n",
    "                method=method,\n",
    "            )\n",
    "            axs[0, i].plot(\n",
    "                df_dist,\n",
    "                slice_calib[:, 0],\n",
    "                label=f\"calibrated {method}\",\n",
    "                color=f\"C{i_m+1}\",\n",
    "            )\n",
    "    axs[0, i].legend()\n",
    "    break\n",
    "print(f\"average time {method}: {np.mean(times[method]):.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "color_palette = \"tab10\"\n",
    "extra_kwargs = {\n",
    "    \"linewidth\": 0,\n",
    "    \"palette\": color_palette,\n",
    "    \"style\": \"method\",\n",
    "    \"hue\": \"mic\",\n",
    "    \"data\": fitting_results,\n",
    "    \"x\": \"frequency\",\n",
    "}\n",
    "palette = sns.palettes.color_palette(color_palette)\n",
    "fitting_results = fitting_results.apply(pd.to_numeric, errors=\"ignore\", axis=0)\n",
    "plt.figure()\n",
    "sns.scatterplot(\n",
    "    y=\"gains\", **extra_kwargs,\n",
    ")\n",
    "for i, mic_idx in enumerate(chosen_mics):\n",
    "    median_per_freq = np.nanmedian(df_matrix[i, :], axis=1)\n",
    "    plt.plot(df_freq, median_per_freq, color=f'C{i}')\n",
    "plt.plot([], [], color='black', label='median')\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=[1, 1])\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(y=\"absorption\", **extra_kwargs)\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(y=\"offset\", **extra_kwargs)\n",
    "plt.ylabel(\"offset [cm]\")\n",
    "\n",
    "ls = {\"brute\": \"-\", \"minimize\": \":\", \"one-shot\": \"--\"}\n",
    "for method, df in fitting_results.groupby(\"method\"):\n",
    "    medians = df.groupby([\"mic\"]).offset.median()\n",
    "    [plt.axhline(m, color=palette[i], ls=ls[method]) for i, m in enumerate(medians)]\n",
    "    plt.plot([], [], color=\"black\", ls=ls[method], label=method)\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=[1, 1])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import factor_distance_to_delta\n",
    "\n",
    "for mic in range(4):\n",
    "    print('mic', mic)\n",
    "    for distance in np.arange(10, 50, step=10):\n",
    "        f = factor_distance_to_delta(distance, mic)\n",
    "        print(distance, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance slice algorithm\n",
    "from inference import get_approach_angle_fft\n",
    "\n",
    "gt_gamma = 90 # in degrees\n",
    "err_dict = {f\"mic{m}\": [np.nan]*len(df_freq) for m in range(df_matrix.shape[0])}\n",
    "for i, f in enumerate(df_freq):\n",
    "    \n",
    "    d_slices = fill_nans(df_matrix[:, i, :], df_dist)\n",
    "    \n",
    "    plt.figure()\n",
    "    for mic_idx in range(df_matrix.shape[0]):\n",
    "        d_slice = d_slices[mic_idx]\n",
    "        gammas, prob, *_ = get_approach_angle_fft(d_slice, f, df_dist, mic_idx,\n",
    "                                              n_max=1000, bayes=False)\n",
    "        gamma = gammas[np.argmax(prob)]\n",
    "        plt.plot(gammas, prob)\n",
    "        plt.axvline(gamma, label=f'mic{mic_idx}: $\\\\gamma$={gamma:.1f}', color=f'C{mic_idx}')\n",
    "        err_dict[f\"mic{mic_idx}\"][i] = gamma - gt_gamma\n",
    "        \n",
    "    plt.title(f'frequency {f:.0f}Hz')\n",
    "    plt.xlabel('angle of approach $\\\\gamma$ [deg]')\n",
    "    plt.ylabel('probability')\n",
    "    plt.legend()\n",
    "        \n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "fig, axs = plot_performance(err_dict, xs=df_freq, \n",
    "           xlabel=\"frequency [Hz]\", ylabel=\"error [deg]\")\n",
    "save_fig(fig, f'plots/{fname}_distance_slice_performance.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. study full matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from calibration import get_calibration_function_matrix\n",
    "from calibration import get_calibration_function, get_calibration_function_dict\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "calib_function_old = get_calibration_function(ax=ax)\n",
    "ax.set_title(\"old calibration\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "filter_dict = {\n",
    "    'exp_name': exp_name, \n",
    "    'motors': 0,\n",
    "    'mic_type': mic_type\n",
    "}\n",
    "calib_function = get_calibration_function_dict(**filter_dict, ax=ax)\n",
    "ax.set_ylim(1, 10)\n",
    "ax.set_yscale(\"linear\")\n",
    "ax.set_title(\"new calibration\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "calib_function_median = wall_detector.get_calib_function(method=\"median\", ax=ax)\n",
    "ax.set_yscale(\"linear\")\n",
    "ax.set_ylim(0, 5)\n",
    "ax.set_title(\"new calibration, median\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "calib_function_fit = wall_detector.get_calib_function(method=\"fit\", ax=ax)\n",
    "ax.set_yscale(\"linear\")\n",
    "ax.set_ylim(0, 3)\n",
    "ax.set_title(\"new calibration, fit\")\n",
    "#\n",
    "fig, ax = plt.subplots()\n",
    "calib_function_fit_one = wall_detector.get_calib_function(method=\"fit-one\", ax=ax)\n",
    "ax.set_yscale(\"linear\")\n",
    "ax.set_ylim(0, 3)\n",
    "ax.set_title(\"new calibration, fit one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import get_df_theory\n",
    "from wall_detector import normalize_df_matrix\n",
    "\n",
    "min_value = np.inf\n",
    "max_value = -np.inf\n",
    "\n",
    "distances_grid = np.arange(0, max(df_dist) + 1)\n",
    "distances_idx = np.argmin(np.abs(distances_grid[:, None] - df_dist[None, :]), axis=0)\n",
    "\n",
    "results = pd.DataFrame(columns=[\"normalization\", \"matrix\", \"values\"])\n",
    "method_dict = {\n",
    "    'raw': \"\",\n",
    "    'theoretical': \"\",\n",
    "    'calibration-median': calib_function_median,\n",
    "    'calibration-fit': calib_function_fit,\n",
    "    'calibration-fit-one': calib_function_fit_one,\n",
    "    #'calibration-online': \"calibration-online\",\n",
    "    #'standardize': \"standardize\",\n",
    "    #'zero_mean': \"zero_mean\",\n",
    "    #'normalize': \"normalize\",\n",
    "    #'calibration-offline-old': calib_function_old,\n",
    "}\n",
    "\n",
    "df_theory_pruned = get_df_theory(df_freq, df_dist, chosen_mics)\n",
    "\n",
    "for j, (key, method) in enumerate(method_dict.items()):\n",
    "    values = None\n",
    "    if key == \"raw\":\n",
    "        df_norm = deepcopy(df_matrix)\n",
    "    elif key == \"theoretical\":\n",
    "        df_norm = deepcopy(df_theory_pruned[:, :, distances_idx])\n",
    "    else:\n",
    "        df_norm, values = normalize_df_matrix(\n",
    "            df_matrix=df_matrix, freqs=df_freq, method=method\n",
    "        )\n",
    "    results.loc[len(results), :] = {\n",
    "        \"normalization\": key,\n",
    "        \"matrix\": df_norm,\n",
    "        \"values\": values,\n",
    "    }\n",
    "    # print(key, data_type, df_norm.shape)\n",
    "    min_value = min(min_value, -abs(np.min(df_norm)))\n",
    "    max_value = max(max_value, abs(np.max(df_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from plotting_tools import plot_df_matrix, save_fig\n",
    "\n",
    "min_freq = min(df_freq)\n",
    "max_freq = max(df_freq)\n",
    "\n",
    "min_value = None\n",
    "max_value = None\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "\n",
    "for normalization, df in results.groupby(\"normalization\", sort=False):\n",
    "\n",
    "    matrix = df.iloc[0].matrix\n",
    "    n_mics = matrix.shape[0]\n",
    "    fig, axs = plt.subplots(1, n_mics, sharey=True)\n",
    "    fig.set_size_inches(n_mics*5, 5)\n",
    "    axs[0].set_ylabel('frequency [Hz]')\n",
    "    for i in range(n_mics):\n",
    "        df_the = df_theory_pruned[i, :, distances_idx].T\n",
    "        df_exp = df.iloc[0].matrix[i]\n",
    "        ax, im = plot_df_matrix(\n",
    "            df_dist,\n",
    "            df_freq,\n",
    "            df_exp,\n",
    "            ax=axs[i],\n",
    "            min_freq=min_freq,\n",
    "            max_freq=max_freq,\n",
    "            vmin=min_value,\n",
    "            vmax=max_value,\n",
    "        )\n",
    "        ax.set_title(f\"mic{i} {normalization}\")\n",
    "        ax.set_xlabel('distance [cm]')\n",
    "    add_colorbar(fig, ax, im)\n",
    "    save_fig(fig, f\"plots/{fname}_matrices_{normalization}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate algorithm performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import get_probability_cost, get_probability_bayes\n",
    "from simulation import get_freq_slice_theory\n",
    "import progressbar\n",
    "\n",
    "err_df = pd.DataFrame(columns=['method', 'mic', 'distance', 'error', 'algorithm'])\n",
    "\n",
    "distances_grid = np.arange(50)\n",
    "distances = df_dist\n",
    "mic_indices = range(4)\n",
    "n_mics = len(mic_indices)\n",
    "\n",
    "with progressbar.ProgressBar(max_value=len(distances)) as p:\n",
    "    for i_d, distance in enumerate(distances):\n",
    "        p.update(i_d)\n",
    "        for i_mic, mic_idx in enumerate(mic_indices):\n",
    "            for method, normalize_method in method_dict.items():\n",
    "                df = results.loc[results.normalization == method]\n",
    "\n",
    "                if method == \"theoretical\": \n",
    "                    freqs = wall_detector.df[wall_detector.df.distance==distance].frequency.unique()\n",
    "                    slice_exp = get_freq_slice_theory(freqs, distance)\n",
    "                    slice_exp = slice_exp.T\n",
    "                    stds = [1]*slice_exp.shape[0]\n",
    "                else:\n",
    "                    slice_exp, freqs, stds = wall_detector.get_frequency_slice(\n",
    "                        distance, normalize_method=normalize_method)\n",
    "\n",
    "                slice_exp = fill_nans(slice_exp, freqs)\n",
    "                slice_exp = slice_exp[mic_idx]\n",
    "\n",
    "                proba_cost = get_probability_cost(\n",
    "                    slice_exp, freqs, \n",
    "                    distances_grid, mic_idx=mic_idx\n",
    "                )\n",
    "                distances_bayes, proba_bayes = get_probability_bayes(\n",
    "                    slice_exp,\n",
    "                    freqs, \n",
    "                    mic_idx=mic_idx,\n",
    "                    distance_range=[min(distances_grid), max(distances_grid)],\n",
    "                    sigma=stds[mic_idx]\n",
    "                )\n",
    "\n",
    "                for algo, proba, distances_here in zip(\n",
    "                    [\"cost\", \"bayes\"],\n",
    "                    [proba_cost, proba_bayes],\n",
    "                    [distances_grid, distances_bayes],\n",
    "                ):\n",
    "                    d_idx = np.argmax(proba)\n",
    "                    d = distances_here[d_idx]\n",
    "                    err_df.loc[len(err_df), :] = {\n",
    "                        'error': d - distance,\n",
    "                        'mic': mic_idx,\n",
    "                        'distance': distance,\n",
    "                        'method': method, \n",
    "                        'algorithm': algo\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_tools import plot_performance\n",
    "titles = {\n",
    "    'cost': 'optimization-based method',\n",
    "    'bayes': 'FFT-based method'\n",
    "}\n",
    "err_df = err_df.apply(pd.to_numeric, axis=0, errors='ignore')\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "for key, df in err_df.groupby(\"algorithm\"):\n",
    "    for mic, df_mic in df.groupby(\"mic\"):\n",
    "        absolute_err = pd.pivot_table(df_mic, index=\"distance\", values=\"error\", columns=\"method\")\n",
    "        fig, axs = plot_performance(absolute_err, xs=distances, xlabel=\"distance [cm]\", ylabel=\"absolute error [cm]\")\n",
    "        axs[0, 1].set_xlim(-1, max(distances))\n",
    "        axs[0, 0].set_title(f'mic{mic}, {titles[key]}')\n",
    "        axs[0, 0].grid()\n",
    "        \n",
    "        fname_here = f\"plots/{fname}_{key}_mic{mic}_frequency_performance.png\"\n",
    "        save_fig(fig, fname_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import get_probability_cost, get_probability_bayes\n",
    "from simulation import get_freq_slice_theory\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "mic_idx = 1\n",
    "\n",
    "chosen_methods = [\"raw\", \"calibration-median\", \"theoretical\"]\n",
    "plot_combis = [{\n",
    "    'distance': 11,\n",
    "    'algorithms': [\"cost\", \"bayes\"]\n",
    "}]\n",
    "    \n",
    "for plot_combi in plot_combis: \n",
    "    distance = plot_combi.get('distance')\n",
    "    algorithms = plot_combi.get('algorithms')\n",
    "    fname = f\"{exp_name}_{motors}_{distance:.0f}cm\"\n",
    "    \n",
    "    fig_slice, axs_slice = plt.subplots(len(chosen_methods), n_mics, sharex=True, sharey=True)\n",
    "    fig_slice.set_size_inches(3*n_mics, 2*len(chosen_methods))\n",
    "    \n",
    "    fig_algos = {}\n",
    "    axs_algos = {}\n",
    "    for algo in algorithms:\n",
    "        fig_algo, axs_algo = plt.subplots(len(chosen_methods), n_mics, sharex=True, sharey='row')\n",
    "        fig_algo.set_size_inches(3*n_mics, 2*len(chosen_methods))\n",
    "        fig_algos[algo] = fig_algo\n",
    "        axs_algos[algo] = axs_algo\n",
    "    \n",
    "    for i_mic, mic_idx in enumerate(mic_indices):\n",
    "        for i_method, method in enumerate(chosen_methods):\n",
    "            df = results.loc[results.normalization == method]\n",
    "            if method == \"theoretical\": \n",
    "                freqs = np.sort(wall_detector.df[wall_detector.df.distance==distance].frequency.unique())\n",
    "                slice_exp = get_freq_slice_theory(freqs, distance)\n",
    "                slice_exp = slice_exp.T\n",
    "                stds = [1]*slice_exp.shape[0]\n",
    "            else:\n",
    "                normalize_method = method_dict[method]\n",
    "                slice_exp, freqs, stds = wall_detector.get_frequency_slice(\n",
    "                    distance, normalize_method=normalize_method)\n",
    "\n",
    "            slice_exp = fill_nans(slice_exp, freqs)\n",
    "            slice_exp = slice_exp[mic_idx]\n",
    "\n",
    "            # doing this here for plotting reasons. Doesn't change performance as\n",
    "            # this is done again in get_probability_cost\n",
    "            slice_exp -= np.nanmean(slice_exp)\n",
    "            slice_exp /= np.nanstd(slice_exp)\n",
    "\n",
    "            axs_slice[i_method, i_mic].plot(freqs, slice_exp, label=method, color=f\"C{i_method}\")\n",
    "            axs_slice[i_method, i_mic].set_xlim(min_freq, max_freq)\n",
    "            axs_slice[i_method, 0].set_ylabel(f'{method}')\n",
    "            axs_slice[0, i_mic].set_title(f\"mic{mic_idx}\")\n",
    "            \n",
    "            for algo in algorithms:\n",
    "                axs_algo = axs_algos[algo]\n",
    "                \n",
    "                if algo == \"cost\":\n",
    "                    proba = get_probability_cost(\n",
    "                        slice_exp, freqs, \n",
    "                        distances_grid, mic_idx=mic_idx\n",
    "                    )\n",
    "                    distances_here = distances_grid\n",
    "                elif algo == \"bayes\":\n",
    "                    distances_here, proba = get_probability_bayes(\n",
    "                        slice_exp,\n",
    "                        freqs, \n",
    "                        mic_idx=mic_idx,\n",
    "                        distance_range=[min(distances_grid), max(distances_grid)],\n",
    "                        sigma=stds[mic_idx]\n",
    "                    )\n",
    "\n",
    "                d_idx = np.argmax(proba)\n",
    "                d = distances_here[d_idx]\n",
    "\n",
    "                axs_algo[i_method, i_mic].semilogy(distances_here, proba, color=f\"C{i_method}\")\n",
    "                axs_algo[i_method, i_mic].axvline(x=d, color=f\"C{i_method}\", label=f'estimate')\n",
    "                axs_algo[i_method, i_mic].axvline(x=distance, color=\"black\", ls=\":\", label=f'real: {distance:.0f}cm')\n",
    "                axs_algo[i_method, i_mic].set_xlim(min(distances_here)-1, max(distances_here)+1)\n",
    "\n",
    "                axs_algo[0, i_mic].set_title(f\"mic{mic_idx}\")\n",
    "                axs_algo[i_method, 0].set_ylabel(f'{method}')\n",
    "\n",
    "    fname_here = f'plots/{fname}_slice.png'\n",
    "    save_fig(fig_slice, fname_here)\n",
    "\n",
    "    for algo in algorithms:\n",
    "        axs_algos[algo][-1, -1].legend(loc='upper right')\n",
    "        fname_here = f'plots/{fname}_{algo}.png'\n",
    "        save_fig(fig_algos[algo], fname_here)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# old stuff"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.interpolate import UnivariateSpline, LSQUnivariateSpline\n",
    "from numpy.polynomial import Chebyshev, Legendre, Polynomial, Laguerre\n",
    "\n",
    "spline_k = 2\n",
    "spline_ext = 3\n",
    "\n",
    "for mic_idx in range(row.df_matrix.shape[0]):\n",
    "    df_norm, values = normalize_df_matrix(\n",
    "        df_matrix=row.df_matrix, freqs=row.df_freq, method=\"calibration-online\"\n",
    "    )\n",
    "\n",
    "    df_norm, df_freq, indices = prune_df_matrix(df_norm, row.df_freq)\n",
    "    values = values[:, indices]\n",
    "\n",
    "    xvalues = df_freq\n",
    "    yvalues = np.log10(values[mic_idx, :, 0])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(xvalues, yvalues, label=\"raw\", color=\"C0\", marker=\"*\")\n",
    "    for i, poly in enumerate([Legendre]):  \n",
    "        c = poly.fit(xvalues, yvalues, deg=10)\n",
    "        x, y = c.linspace()\n",
    "        plt.plot(x, y, label=poly.__name__, color=f\"C{i+1}\")\n",
    "\n",
    "    # spline = UnivariateSpline(xvalues, yvalues, k=2)\n",
    "    # plt.plot(xvalues, spline(xvalues), label='Spline', color='C5')\n",
    "\n",
    "    knots = np.linspace(min(df_freq), max(df_freq), 7)[1:-1]\n",
    "    spline = LSQUnivariateSpline(xvalues, yvalues, t=knots, k=spline_k, ext=spline_ext)\n",
    "    plt.plot(xvalues, spline(xvalues), label=\"LSQSpline\", color=f\"C{i+2}\", marker=\"o\")\n",
    "    [plt.axvline(k, color=f\"C{i+2}\") for k in knots]\n",
    "    plt.legend()\n",
    "    plt.title(f\"mic{mic_idx}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def spline_interpolation(xvalues, df_matrix):\n",
    "    \"\"\" Generate spline interpolation for all distances.\n",
    "    \n",
    "    :return calib_values: mics x freqs x distances, interpolated spline curve\n",
    "    \"\"\"\n",
    "    knots = np.linspace(min(df_freq), max(df_freq), 6)[1:-1]\n",
    "    calib_values = np.empty_like(df_matrix)\n",
    "    for i, dist in enumerate(row.df_dist):\n",
    "        for m in range(df_matrix.shape[0]):\n",
    "\n",
    "            slice_f = np.log10(df_matrix[m, :, i])\n",
    "            mask = ~np.isnan(slice_f)\n",
    "\n",
    "            spline = LSQUnivariateSpline(\n",
    "                xvalues[mask], slice_f[mask], t=knots, k=spline_k, ext=spline_ext\n",
    "            )\n",
    "            calib_values[m, :, i] = 10 ** spline(xvalues)\n",
    "    return calib_values\n",
    "\n",
    "\n",
    "df_matrix, df_freq, __ = prune_df_matrix(row.df_matrix, row.df_freq)\n",
    "calib_values = spline_interpolation(df_freq, df_matrix)\n",
    "\n",
    "fig, axs = plt.subplots(1, calib_values.shape[0], squeeze=False, sharey=True)\n",
    "fig.set_size_inches(10, 5)\n",
    "cmap = plt.get_cmap(\"inferno\")\n",
    "for m in range(calib_values.shape[0]):\n",
    "    for i, dist in enumerate(row.df_dist):\n",
    "        axs[0, m].semilogy(\n",
    "            df_freq, calib_values[m, :, i], color=cmap(i / len(row.df_dist))\n",
    "        )\n",
    "    axs[0, m].semilogy(\n",
    "        df_freq, calib_values[m, :, 0], color=cmap(0), label=f\"{row.df_dist[0]}cm\"\n",
    "    )\n",
    "    axs[0, m].semilogy(\n",
    "        df_freq,\n",
    "        calib_values[m, :, i],\n",
    "        color=cmap(i / len(row.df_dist)),\n",
    "        label=f\"{row.df_dist[-1]}cm\",\n",
    "    )\n",
    "    axs[0, m].set_title(f\"mic{m}\")\n",
    "    axs[0, m].legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from wall_analysis import get_df_matrices, FILTERS\n",
    "\n",
    "#exp_name = \"2021_02_25_wall\"\n",
    "exp_name = \"2021_02_23_wall\"\n",
    "\n",
    "fname = \"results/wall_analysis.pkl\"\n",
    "# method = 'dryrun'\n",
    "# method = 'new'\n",
    "#method = 'replace'\n",
    "method = \"read\"\n",
    "\n",
    "if method == \"read\":\n",
    "    results_df = pd.read_pickle(fname)\n",
    "elif method == \"replace\":\n",
    "    from pandas_utils import fill_df\n",
    "\n",
    "    results_df = pd.read_pickle(fname)\n",
    "\n",
    "    print(\"read\", fname)\n",
    "    results_df_new = get_df_matrices(exp_name)\n",
    "\n",
    "    for chosen_tuple, df in results_df_new.groupby(FILTERS):\n",
    "        assert len(df) == 1\n",
    "        row = df.iloc[0]\n",
    "\n",
    "        filter_dict = dict(zip(FILTERS, chosen_tuple))\n",
    "        filter_dict.update({\"exp_name\": exp_name})\n",
    "        fill_dict = {\n",
    "            \"df_dist\": row.df_dist,\n",
    "            \"df_freq\": row.df_freq,\n",
    "            \"df_matrix\": row.df_matrix,\n",
    "        }\n",
    "        print(\"filling results_df_old...\")\n",
    "        results_df = fill_df(results_df, filter_dict, fill_dict)\n",
    "    pd.to_pickle(results_df, fname)\n",
    "    print(\"saved as\", fname)\n",
    "elif method == \"new\":\n",
    "    results_df = get_df_matrices(exp_name)\n",
    "    pd.to_pickle(results_df, fname)\n",
    "    print(\"saved as\", fname)\n",
    "elif method == \"dryrun\":\n",
    "    results_df = get_df_matrices(exp_name, max_distance=10, plot=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.883px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
