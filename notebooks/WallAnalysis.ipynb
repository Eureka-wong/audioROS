{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"figure.max_open_warning\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_tools import *\n",
    "from wall_analysis import load_params\n",
    "\n",
    "def init_results_df():\n",
    "    return pd.DataFrame(columns=['mic_type', 'snr', 'motors', 'exp_name', 'df_matrix', 'df_dist', 'df_freq'])\n",
    "\n",
    "def cost_period(slice_the, slice_exp):\n",
    "    cost = 0\n",
    "    assert slice_the.shape[1] == slice_exp.shape[1]\n",
    "    for i in range(slice_exp.shape[0]):\n",
    "        slice_exper = slice_exp[i] - np.mean(slice_exp[i])\n",
    "        f_exp = np.fft.rfftfreq(len(slice_exper), d=1/len(slice_exper))\n",
    "        fft_exp = np.abs(np.fft.rfft(slice_exper))\n",
    "        max_exp = f_exp[np.argmax(fft_exp)]\n",
    "\n",
    "        slice_theory = slice_the[i] - np.mean(slice_the[i])\n",
    "        f_theory = np.fft.rfftfreq(len(slice_theory), d=1/len(slice_exper))\n",
    "        fft_theory = np.abs(np.fft.rfft(slice_theory))\n",
    "        max_theory = f_theory[np.argmax(fft_theory)]\n",
    "        \n",
    "        cost += np.abs(max_exp - max_theory)\n",
    "    return cost / slice_exp.shape[0]\n",
    "    \n",
    "def cost_function(arr1, arr2, freq, min_freq, max_freq):\n",
    "    freq = np.array(list(freq))\n",
    "    mask_invalid = np.isnan(arr1) | np.isnan(arr2) | (freq < min_freq) | (freq > max_freq)\n",
    "    return np.linalg.norm(arr1[~mask_invalid] - arr2[~mask_invalid], ord=2)\n",
    "    \n",
    "def normalize_slice(slice_f, method_slice='zero_to_one'):\n",
    "    mask = ~np.isnan(slice_f)\n",
    "    if not np.any(mask):\n",
    "        print('Warning: no valid entries')\n",
    "        return slice_f\n",
    "    \n",
    "    if method_slice == 'zero_to_one':\n",
    "        slice_f[mask] -= np.min(slice_f[mask])\n",
    "        slice_f[mask] /= (np.max(slice_f[mask]) - np.min(slice_f[mask]))\n",
    "        slice_f[mask] += 1\n",
    "    elif method_slice == 'standardize':\n",
    "        slice_f[mask] -= np.mean(slice_f[mask])\n",
    "        slice_f[mask] /= np.std(slice_f[mask])\n",
    "    elif method_slice == 'calibrate':\n",
    "        if np.mean(slice_f[mask]) > 0:\n",
    "            slice_f[mask] /= np.mean(slice_f[mask])\n",
    "        else:\n",
    "            print('warning:', np.mean(slice_f[mask]))\n",
    "    elif method_slice == '':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(method_slice)\n",
    "    return slice_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_wall_experiments(df_freq, max_distance=None, plot=False):\n",
    "    import progressbar\n",
    "    from pandas_utils import fill_df\n",
    "    from wall_detector import WallDetector\n",
    "    \n",
    "    results_df = init_results_df()\n",
    "    for chosen_tuple, df_mic in df_freq.groupby(FILTERS, sort=False):\n",
    "        #if chosen_tuple[0] == 'audio_deck':\n",
    "        #    continue\n",
    "        filter_dict = dict(zip(FILTERS, chosen_tuple))\n",
    "\n",
    "        wall_detector = WallDetector(exp_name=exp_name, mic_type=filter_dict['mic_type'])\n",
    "\n",
    "        if filter_dict['mic_type'] == 'measurement' and filter_dict['snr'] == 1:\n",
    "            continue\n",
    "        elif filter_dict['motors'] != 0:\n",
    "            continue\n",
    "\n",
    "        d_idx = 0\n",
    "        max_value = max_distance if max_distance is not None else len(df_mic)\n",
    "        with progressbar.ProgressBar(max_value=max_value) as p:\n",
    "            for distance, df_this in df_mic.groupby('distance'):\n",
    "                if len(df_this) != 1: \n",
    "                    print(f\"{len(df_this)} findings for {distance, filter_dict}\")\n",
    "                    continue\n",
    "                if max_distance is not None and (distance > max_distance):\n",
    "                    continue\n",
    "\n",
    "                row = df_this.iloc[0]\n",
    "                try:\n",
    "                    spec_masked_all, freqs_masked = wall_detector.fill_from_row(row)\n",
    "                except Exception as e:\n",
    "                    print('error with row', row)\n",
    "                    print(e)\n",
    "                    continue\n",
    "                p.update(d_idx); d_idx += 1\n",
    "                \n",
    "                if plot:\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.pcolorfast(range(spec_masked_all.shape[-1]), freqs_masked, np.log10(spec_masked_all[:, 0, :]))\n",
    "                    ax.set_title(f'distance={distance}cm')\n",
    "                \n",
    "        wall_detector.remove_bad_freqs(verbose=False, dryrun=False)\n",
    "        wall_detector.remove_spurious_freqs(verbose=False)\n",
    "        wall_detector.merge_close_freqs()\n",
    "\n",
    "        df_amp, distances, frequencies = wall_detector.get_df_matrix()\n",
    "        #df_std, *_ = wall_detector.get_df_matrix(method=normalized_std)\n",
    "        \n",
    "        assert df_amp.shape[1:] == (len(frequencies), len(distances)), df_amp.shape\n",
    "\n",
    "        filter_dict.update({'exp_name': exp_name})\n",
    "        fill_dict = {'df_dist':distances, \n",
    "                     'df_freq': frequencies,\n",
    "                     'df_matrix': df_amp}\n",
    "        print('filling results_df...')\n",
    "        results_df = fill_df(results_df, filter_dict, fill_dict)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental distance-frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import get_setup\n",
    "\n",
    "distance = 0\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(5, 5)\n",
    "for yaw_deg, marker in zip([0, 30], ['o', 'x']):\n",
    "    source, mic_positions = get_setup(distance_cm=distance, yaw_deg=yaw_deg)\n",
    "    source_image = [source[0], -source[1]]\n",
    "    for i, mic in enumerate(mic_positions):\n",
    "        plt.scatter(*mic, label=f'mic{i}, {yaw_deg}deg', marker=marker, color=f'C{i}')\n",
    "plt.plot([4.8, 5.4], [0, 0], color='k', label='wall')\n",
    "plt.title(f'setup for distance={distance}cm')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('x [m]')\n",
    "plt.ylabel('y [m]')\n",
    "plt.axis('equal')\n",
    "\n",
    "#fig.savefig(f'plots/setup_{distance}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#exp_name = '2021_02_09_wall_tukey'; \n",
    "#exp_name = '2021_02_09_wall'; \n",
    "exp_name = '2021_02_23_wall'; \n",
    "#exp_name = '2021_02_19_windows'; \n",
    "#exp_name = '2020_12_9_rotating'; \n",
    "#exp_name = '2020_11_26_wall'; \n",
    "#fname = f'results/{exp_name}_real.pkl'\n",
    "fname = f'../experiments/{exp_name}/all_data.pkl'\n",
    "#fname = f'../experiments/{exp_name}/battery_data.pkl' # for 2021_02_09_wall, battery study\n",
    "\n",
    "try:\n",
    "    df_all = pd.read_pickle(fname)\n",
    "    print('read', fname)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('Error: run wall_analysis.py to parse experiments.')\n",
    "df_all.iloc[:, :8]\n",
    "\n",
    "#plot_spectrograms(df_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Debug parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pandas_utils import filter_by_dicts\n",
    "from wall_detector import WallDetector, normalized_std, kwargs_datasets\n",
    "from bin_selection import generate_sweep\n",
    "from crazyflie_description_py.parameters import N_BUFFER, FS\n",
    "\n",
    "\n",
    "if len(df_all.distance.unique()) > 1:\n",
    "    distance = 20\n",
    "else:\n",
    "    distance = df_all.iloc[0].distance\n",
    "degree = 0\n",
    "#motors = 0 #\"all45000\"\n",
    "\n",
    "chosen_dicts = [{\"degree\": degree, \"distance\":distance}]\n",
    "\n",
    "df_filtered = filter_by_dicts(df_all, chosen_dicts)\n",
    "print('plotting\\n', df_filtered.iloc[:, :8])\n",
    "\n",
    "fig_bins, ax_bins = plt.subplots()\n",
    "\n",
    "for mic_type, df_mic_types in df_filtered.groupby('mic_type'):\n",
    "    \n",
    "    ymin = 1e-4\n",
    "    ymax = 3e2\n",
    "    if mic_type == 'measurement':\n",
    "        mic = 0\n",
    "    else:\n",
    "        mic = 1\n",
    "    \n",
    "    for j, (i_row, row) in enumerate(df_mic_types.iterrows()):\n",
    "        if (row.mic_type == 'measurement') and (row.snr == 1): # this is no \"real snr\"\n",
    "            continue\n",
    "            \n",
    "        title = f'{row.mic_type} {row.motors} {row.appendix.replace(\"_\", \"\")} {row.distance} mic{mic}'\n",
    "\n",
    "        # processing\n",
    "        wall_detector = WallDetector(exp_name=exp_name, mic_type=row.mic_type)\n",
    "        try:\n",
    "            spec_masked_all, freqs_masked = wall_detector.fill_from_row(row)\n",
    "        except:\n",
    "            print('skipping', row)\n",
    "            continue\n",
    "        wall_detector.remove_bad_freqs(verbose=False, dryrun=False)\n",
    "        wall_detector.remove_spurious_freqs(verbose=False)\n",
    "        wall_detector.merge_close_freqs(verbose=True)\n",
    "\n",
    "        # plotting\n",
    "        spec_masked = np.mean(spec_masked_all, axis=1)\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(5, 5)\n",
    "        ax.pcolorfast(row.seconds, freqs_masked, np.log10(spec_masked[:-1, :-1]))\n",
    "        ax.set_xlim(kwargs_datasets[exp_name][row.mic_type]['min_time'],\n",
    "                    kwargs_datasets[exp_name][row.mic_type]['max_time'])\n",
    "        ax.set_ylim(kwargs_datasets[exp_name][row.mic_type]['min_freq'],\n",
    "                    kwargs_datasets[exp_name][row.mic_type]['max_freq'])\n",
    "        ax.set_xlabel('time [s]')\n",
    "        ax.set_ylabel('frequency [Hz]')\n",
    "        save_fig(fig, f'plots/{exp_name}_{row.mic_type}_{row.motors}{row.appendix}_spec.png')\n",
    "        \n",
    "        df_mic = wall_detector.df[wall_detector.df.mic==mic]\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(5, 5)\n",
    "        sns.scatterplot(data=df_mic, \n",
    "                        x='frequency', y='magnitude', \n",
    "                        hue='counter', ax=ax,\n",
    "                        linewidth=0)\n",
    "        ax.set_xlabel('frequency [Hz]')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylim(1e-1, 1e2)\n",
    "        ax.grid(which='both')\n",
    "        ax.set_title(title)\n",
    "        save_fig(fig, f'plots/{exp_name}_{row.mic_type}_{row.motors}{row.appendix}.png')\n",
    "\n",
    "        freqs_psd = wall_detector.df.frequency.unique()\n",
    "        [ax_bins.plot([f, f], [j, j+1], color=f'C{j+1}', ls='-') for f in freqs_psd]\n",
    "\n",
    "        label = f'{row.mic_type}, motors={row.motors}, snr={row.snr}'\n",
    "        ax_bins.plot([], [], color=f'C{j+1}', ls='-', label=label)\n",
    "\n",
    "        fig, ax = plot_raw_signals(spec_masked_all, freqs_masked, mic_idx=mic)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_title(title)\n",
    "        save_fig(fig, f'plots/{exp_name}_{row.mic_type}_{row.motors}{row.appendix}_raw.png')\n",
    "        break\n",
    "\n",
    "    bins, t_sec = generate_sweep(row.source)\n",
    "    freqs_sweep = np.fft.rfftfreq(N_BUFFER, 1/FS)\n",
    "    [ax_bins.plot([f, f], [0, j+1], color=f'C0', ls='-') for f in freqs_sweep[bins]]\n",
    "    ax_bins.plot([], [], color=f'C0', ls='-', label='sweep')\n",
    "    ax_bins.set_xlabel('frequency [Hz]')\n",
    "    ax_bins.legend(loc='lower left', bbox_to_anchor=[1.0, 0.0])\n",
    "    ax_bins.set_yticks([])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full analysis\n",
    "\n",
    "\n",
    "- [x] fix calibration_offline scheme: here we should compare to a different theoretical distribution! \n",
    "- [x] add cosine cost function to calibrations\n",
    "- [x] implement parametric calibration\n",
    "- [ ] choose frequency bins based on std or distance slice performance\n",
    "- [ ] add plots of \"ambiguous\" distances\n",
    "- [ ] implement \"offline calibration\" for measurement mics\n",
    "\n",
    "\n",
    "# 1. Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'results/wall_analysis.pkl'\n",
    "#method = 'dryrun'\n",
    "#method = 'new'\n",
    "#method = 'replace'\n",
    "method = 'read'\n",
    "\n",
    "if method == 'read': \n",
    "    results_df = pd.read_pickle(fname)\n",
    "elif method == 'replace':\n",
    "    from pandas_utils import fill_df\n",
    "    FILTERS = ['mic_type', 'snr', 'motors']\n",
    "    results_df = pd.read_pickle(fname)\n",
    "    \n",
    "    print('read', fname)\n",
    "    results_df_new = parse_wall_experiments(df_all)\n",
    "    \n",
    "    for chosen_tuple, df in results_df_new.groupby(FILTERS):\n",
    "        assert len(df) == 1\n",
    "        row = df.iloc[0]\n",
    "        \n",
    "        filter_dict = dict(zip(FILTERS, chosen_tuple))\n",
    "        filter_dict.update({'exp_name': exp_name})\n",
    "        fill_dict = {'df_dist': row.df_dist, \n",
    "                     'df_freq': row.df_freq,\n",
    "                     'df_matrix': row.df_matrix}\n",
    "        print('filling results_df_old...')\n",
    "        results_df = fill_df(results_df, filter_dict, fill_dict)\n",
    "    pd.to_pickle(results_df, fname)\n",
    "    print('saved as', fname)\n",
    "elif method == 'new':\n",
    "    results_df = parse_wall_experiments(df_all)\n",
    "    pd.to_pickle(results_df, fname)\n",
    "    print('saved as', fname)\n",
    "elif method == 'dryrun':\n",
    "    results_df = parse_wall_experiments(df_all, max_distance=10, plot=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_utils import filter_by_dicts\n",
    "\n",
    "#mic_type = 'measurement'\n",
    "mic_type = 'audio_deck'\n",
    "\n",
    "#exp_name = '2020_11_26_wall'; snr = 0\n",
    "#exp_name = '2021_02_09_wall_tukey'; snr = 3\n",
    "#exp_name = '2021_02_09_wall'; snr = 3\n",
    "exp_name = '2021_02_23_wall'; snr = 3\n",
    "#exp_name = '2020_12_9_rotating'; snr = 1\n",
    "\n",
    "filter_dict = dict(\n",
    "    exp_name = exp_name,\n",
    "    motors = 0,\n",
    "    snr = snr,\n",
    "    mic_type = mic_type,\n",
    ")\n",
    "row = filter_by_dicts(results_df, [filter_dict]).iloc[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choose normalization scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration import get_calibration_function\n",
    "from wall_detector import normalize_df_matrix\n",
    "from copy import deepcopy\n",
    "from simulation import get_df_theory\n",
    "\n",
    "calib_function = get_calibration_function(plot=False)\n",
    "\n",
    "max_distance = 50\n",
    "distances_grid = np.arange(0, max_distance+1)\n",
    "distances_idx = np.where(distances_grid[:, None] == row.df_dist[None, :])[0]\n",
    "\n",
    "np.testing.assert_allclose(distances_grid[distances_idx], row.df_dist)\n",
    "\n",
    "if row.mic_type == 'measurement':\n",
    "    df_theory = get_df_theory(row.df_freq, distances_grid, chosen_mics=[1]) \n",
    "else:\n",
    "    df_theory = get_df_theory(row.df_freq, distances_grid, chosen_mics=range(4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_detector import prune_df_matrix\n",
    "df_matrix, df_freq, indices = prune_df_matrix(row.df_matrix, row.df_freq, \n",
    "                                              ratio_missing_allowed=0.5, verbose=True)\n",
    "df_theory_pruned = df_theory[:, indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cost_period_all(i, plot_d=False, plot_f=True):\n",
    "    if np.any(np.isnan(df_matrix[:, i, :])):\n",
    "        print('skipping', df_freq[i])\n",
    "        return [np.nan] * df_matrix.shape[0]\n",
    "        \n",
    "    if plot_d:\n",
    "        fig, axs = plt.subplots(1, df_matrix.shape[0], squeeze=False, sharey=True)\n",
    "        fig.set_size_inches(15, 5)\n",
    "        fig.suptitle(f'frequency {f:.0f}Hz')\n",
    "    if plot_f:\n",
    "        fig_f, axs_f = plt.subplots(1, df_matrix.shape[0], squeeze=False, sharey=True)\n",
    "        fig_f.set_size_inches(15, 5)\n",
    "        fig_f.suptitle(f'frequency {f:.0f}Hz')\n",
    "        \n",
    "    costs = []\n",
    "    for m in range(df_matrix.shape[0]):\n",
    "        slice_exp = deepcopy(df_matrix[m, i, :])\n",
    "        slice_the_norm = deepcopy(df_theory_pruned[m, i, :])\n",
    "        \n",
    "        slice_the_norm -= np.min(slice_the_norm)\n",
    "        slice_the_norm /= (np.max(slice_the_norm) - np.min(slice_the_norm))\n",
    "        slice_the_norm *= (np.max(slice_exp) - np.min(slice_exp))\n",
    "        slice_the_norm += np.min(slice_exp)\n",
    "        \n",
    "        if plot_d:\n",
    "            axs[0, m].plot(row.df_dist, slice_exp)\n",
    "            axs[0, m].plot(distances_grid, slice_the_norm)\n",
    "            axs[0, m].set_title(f'mic{m}')\n",
    "        \n",
    "        f_exp = np.fft.rfftfreq(len(slice_exp), d=1/len(slice_exp))\n",
    "        slice_exp -= np.mean(slice_exp)\n",
    "        fft_exp = np.abs(np.fft.rfft(slice_exp))\n",
    "        max_exp = f_exp[np.argmax(fft_exp)]\n",
    "        \n",
    "        f_theory = np.fft.rfftfreq(len(slice_the_norm), d=1/len(slice_exp))\n",
    "        slice_the_norm -= np.mean(slice_the_norm)\n",
    "        fft_theory = np.abs(np.fft.rfft(slice_the_norm))\n",
    "        max_theory = f_theory[np.argmax(fft_theory)]\n",
    "        \n",
    "        costs.append(np.abs(max_exp - max_theory))\n",
    "        \n",
    "        if plot_f: \n",
    "            axs_f[0, m].plot(f_exp, fft_exp)\n",
    "            axs_f[0, m].plot(f_theory, fft_theory)\n",
    "            axs_f[0, m].set_title(f'mic{m}')\n",
    "    return costs\n",
    "\n",
    "cost_list = []\n",
    "for i, f in enumerate(df_freq):\n",
    "    cost_list.append(cost_period_all(i, plot_d=True, plot_f=True))\n",
    "cost_arr = np.array(cost_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_mics = cost_arr.shape[1]\n",
    "\n",
    "fig, axs = plt.subplots(1, n_mics, sharey=True, squeeze=False)\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "fig, ax_cdf = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "for m in range(n_mics):\n",
    "    axs[0, m].plot(df_freq, cost_arr[:, m], label=f'mic{m}', marker='o', color=f'C{m}')\n",
    "    axs[0, m].legend()\n",
    "    ax_cdf.plot(np.sort(cost_arr[:, m]), np.linspace(0, 1, cost_arr.shape[0]), label=f'mic{m}', color=f'C{m}')\n",
    "axs[0, 0].set_ylabel('cost')\n",
    "ax_cdf.legend()\n",
    "ax_cdf.set_ylabel('cdf')\n",
    "ax_cdf.set_xlabel('absolute peak error')\n",
    "ax_cdf.grid(which='both')\n",
    "\n",
    "good_frequencies = df_freq[np.all(cost_arr < 2, axis=1)]\n",
    "bad_frequencies = df_freq[np.any(cost_arr >= 2, axis=1)]\n",
    "print('good frequencies:', good_frequencies)\n",
    "print('bad frequencies:', bad_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline, LSQUnivariateSpline\n",
    "from numpy.polynomial import Chebyshev, Legendre, Polynomial, Laguerre\n",
    "\n",
    "spline_k = 2\n",
    "spline_ext = 3\n",
    "\n",
    "for mic_idx in range(row.df_matrix.shape[0]):\n",
    "    df_norm, values = normalize_df_matrix(df_matrix=row.df_matrix, \n",
    "                                          freqs=row.df_freq, method='calibration-online')\n",
    "    \n",
    "    df_norm, df_freq, indices = prune_df_matrix(df_norm, row.df_freq)\n",
    "    values = values[:, indices]\n",
    "\n",
    "    xvalues = df_freq\n",
    "    yvalues = np.log10(values[mic_idx, :, 0])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(xvalues, yvalues, label='raw', color='C0', marker='*')\n",
    "    for i, poly in enumerate([Legendre]): #Laguerre, Chebyshev]):#, Legendre, Polynomial]):\n",
    "        c = poly.fit(xvalues, yvalues, deg=10)\n",
    "        x, y = c.linspace()\n",
    "        plt.plot(x, y, label=poly.__name__, color=f'C{i+1}')\n",
    "\n",
    "    #spline = UnivariateSpline(xvalues, yvalues, k=2) \n",
    "    #plt.plot(xvalues, spline(xvalues), label='Spline', color='C5')\n",
    "\n",
    "    knots = np.linspace(min(df_freq), max(df_freq), 7)[1:-1]\n",
    "    spline = LSQUnivariateSpline(xvalues, yvalues, t=knots, k=spline_k, ext=spline_ext) \n",
    "    plt.plot(xvalues, spline(xvalues), label='LSQSpline', color=f'C{i+2}', marker='o')\n",
    "    [plt.axvline(k, color=f'C{i+2}') for k in knots]\n",
    "    plt.legend()\n",
    "    plt.title(f'mic{mic_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spline_interpolation(xvalues, df_matrix):\n",
    "    \n",
    "    knots = np.linspace(min(df_freq), max(df_freq), 6)[1:-1]\n",
    "    calib_values = np.empty_like(df_matrix)\n",
    "    for i, dist in enumerate(row.df_dist):\n",
    "        for m in range(df_matrix.shape[0]):\n",
    "            \n",
    "            slice_f = np.log10(df_matrix[m, :, i])\n",
    "            mask = ~np.isnan(slice_f)\n",
    "            \n",
    "            spline = LSQUnivariateSpline(xvalues[mask], slice_f[mask], t=knots, k=spline_k, ext=spline_ext) \n",
    "            calib_values[m, :, i] = 10**spline(xvalues) \n",
    "    return calib_values\n",
    "\n",
    "df_matrix, df_freq, __ = prune_df_matrix(row.df_matrix, row.df_freq)\n",
    "\n",
    "calib_values = spline_interpolation(df_freq, df_matrix)\n",
    "fig, axs = plt.subplots(1, calib_values.shape[0], squeeze=False, sharey=True)\n",
    "fig.set_size_inches(10, 5)\n",
    "cmap = plt.get_cmap('inferno')\n",
    "for m in range(calib_values.shape[0]):\n",
    "    for i, dist in enumerate(row.df_dist):\n",
    "        axs[0, m].semilogy(df_freq, calib_values[m, :, i], color=cmap(i/len(row.df_dist)))\n",
    "    axs[0, m].semilogy(df_freq, calib_values[m, :, 0], color=cmap(0), label=f'{row.df_dist[0]}cm')\n",
    "    axs[0, m].semilogy(df_freq, calib_values[m, :, i], color=cmap(i/len(row.df_dist)), label=f'{row.df_dist[-1]}cm')\n",
    "    axs[0, m].set_title(f'mic{m}')\n",
    "    axs[0, m].legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = np.inf\n",
    "max_value = -np.inf\n",
    "\n",
    "results = pd.DataFrame(columns=['normalization', 'matrix', 'values'])\n",
    "method_dict = dict(zip(['raw', 'normalize', 'calibration-offline', 'spline', 'calibration-online', 'standardize', 'zero_mean', 'theoretical'], \n",
    "                       ['', 'normalize', calib_function, calib_values, 'calibration-online', 'standardize', 'zero_mean', 'theoretical']))\n",
    "\n",
    "if row.mic_type == 'measurement':\n",
    "    plot_channel_idx = 0 # only choice \n",
    "else:\n",
    "    plot_channel_idx = 1 # corresponds to mic below measurement mic\n",
    "\n",
    "__, df_freq, indices = prune_df_matrix(row.df_matrix, row.df_freq)\n",
    "df_theory_pruned = df_theory[:, indices, :]\n",
    "\n",
    "for j, (key, method) in enumerate(method_dict.items()):\n",
    "    df_matrix = row.df_matrix\n",
    "        \n",
    "    values = None\n",
    "    df_matrix = df_matrix[:, indices, :]\n",
    "    \n",
    "    if key == 'raw':\n",
    "        df_norm = deepcopy(df_matrix)\n",
    "    elif key == 'theoretical':\n",
    "        df_norm = deepcopy(df_theory_pruned[:, :, distances_idx])\n",
    "    else:\n",
    "        df_norm, values = normalize_df_matrix(df_matrix=df_matrix, \n",
    "                                              freqs=df_freq, method=method)\n",
    "    results.loc[len(results), :] = {\n",
    "        'normalization': key,\n",
    "        'matrix': df_norm,\n",
    "        'values': values\n",
    "    }\n",
    "    #print(key, data_type, df_norm.shape)\n",
    "    min_value = min(min_value, abs(np.min(df_norm)))\n",
    "    max_value = max(max_value, abs(np.max(df_norm)))\n",
    "print('range:', min_value, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_freq = min(df_freq)\n",
    "max_freq = max(df_freq)\n",
    "\n",
    "df_the = df_theory_pruned[plot_channel_idx] \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 5)\n",
    "ax, im = plot_df_matrix(row.df_dist, df_freq, df_the[:, distances_idx], ax=ax,\n",
    "                   min_freq=min_freq, max_freq=max_freq, vmin=min_value, vmax=max_value)\n",
    "add_colorbar(fig, ax, im)\n",
    "ax.set_title(f'theoretical')\n",
    "\n",
    "for normalization, df in results.groupby('normalization', sort=False):\n",
    "    if normalization == 'raw':\n",
    "        continue\n",
    "        \n",
    "    df_exp = df.iloc[0].matrix[plot_channel_idx]\n",
    "    \n",
    "    min_value = np.min(df_the)\n",
    "    max_value = 2*np.max(df_the)\n",
    "    \n",
    "    #print(np.all(np.isnan(df_exp), axis=1))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(5, 5)\n",
    "    #plot_df_matrix(row.df_dist, row.df_freq, df_norm[i], ax=axs[0, i], min_freq=min_freq, max_freq=max_freq, vmin=1e-3, vmax=3)\n",
    "    ax, im = plot_df_matrix(row.df_dist, df_freq, df_exp, ax=ax, \n",
    "                   min_freq=min_freq, max_freq=max_freq, vmin=min_value, vmax=max_value)\n",
    "    add_colorbar(fig, ax, im)\n",
    "    ax.set_title(f'{normalization}, experimental')\n",
    "    \n",
    "#print(np.nanmin(row.df_matrix), np.nanmax(row.df_matrix))\n",
    "#print(row.df_matrix.shape)\n",
    "#print(row.df_matrix[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theoretical vs. measured: matrices\n",
    "df_exp = results.loc[results.normalization=='raw'].iloc[0].matrix[plot_channel_idx]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, squeeze=False, sharey=True)\n",
    "[ax.set_xlabel('distance [cm]') for ax in axs.flatten()]\n",
    "axs[0, 0].set_title(row.mic_type + ' mic')\n",
    "axs[0, 1].set_title('theoretical')\n",
    "\n",
    "min_freq = min(df_freq)\n",
    "max_freq = max(df_freq)\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "    #plot_df_matrix(row.df_dist, row.df_freq, df_norm[i], ax=axs[0, i], min_freq=min_freq, max_freq=max_freq, vmin=1e-3, vmax=3)\n",
    "ax, im = plot_df_matrix(\n",
    "    row.df_dist, df_freq, df_exp, ax=axs[0, 0], \n",
    "    min_freq=min_freq, max_freq=max_freq)\n",
    "add_colorbar(fig, ax, im)\n",
    "ax, im = plot_df_matrix(\n",
    "    row.df_dist, df_freq, df_the[:, distances_idx], ax=axs[0, 1], \n",
    "    min_freq=min_freq, max_freq=max_freq)\n",
    "add_colorbar(fig, ax, im)\n",
    "save_fig(fig, f'plots/{exp_name}_{row.mic_type}_matrices.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration plots \n",
    "\n",
    "distance = 6\n",
    "distance_idx = np.where(row.df_dist == distance)[0]\n",
    "\n",
    "df_exp = results.loc[results.normalization=='raw'].iloc[0].matrix[plot_channel_idx]\n",
    "\n",
    "slice_exp = df_exp[:, distance_idx]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, squeeze=False)\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "axs[0, 0].plot(df_freq, slice_exp, label='raw')\n",
    "\n",
    "axs[0, 1].plot(df_freq, slice_exp, label='raw')\n",
    "\n",
    "#plot_list = ['calibration-online', 'calibration-offline', 'spline', 'standardize']\n",
    "plot_list = ['calibration-online', 'standardize']\n",
    "\n",
    "for normalization, df in results.groupby('normalization', sort=False):\n",
    "    if not normalization in plot_list:\n",
    "        continue\n",
    "    row_exp = df.iloc[0]\n",
    "    print(normalization, row_exp['values'].shape, len(df_freq))\n",
    "    \n",
    "    if normalization == 'spline':\n",
    "        # choose one of the spline calibration curves\n",
    "        values = row_exp['values'][plot_channel_idx, :, distance_idx[0]]\n",
    "    else:\n",
    "        # otherwise there is only one calibration curve\n",
    "        values = row_exp['values'][plot_channel_idx, :, 0]\n",
    "    axs[0, 0].plot(df_freq, values, label=normalization)\n",
    "    \n",
    "    df_exp = row_exp.matrix[plot_channel_idx]\n",
    "    slice_exp = df_exp[:, distance_idx]\n",
    "    axs[0, 1].plot(df_freq, slice_exp, label=normalization)\n",
    "    \n",
    "slice_the = df_the[:, distances_idx][:, distance_idx]\n",
    "axs[0, 1].plot(df_freq, slice_the, label='theoretial') \n",
    "\n",
    "axs[0, 0].legend(loc='lower right')\n",
    "axs[0, 1].legend(loc='lower right')\n",
    "\n",
    "axs[0, 0].set_title('$|Y(f)|^2$')\n",
    "axs[0, 1].set_title('$|H(f)|^2$')\n",
    "\n",
    "axs[0, 0].set_xlabel('frequency [Hz]')\n",
    "axs[0, 1].set_xlabel('frequency [Hz]')\n",
    "    \n",
    "#axs[0, 0].set_yscale('log')\n",
    "#axs[0, 1].set_yscale('log')\n",
    "#axs[0, 0].set_ylim(1e-2, 1e2)\n",
    "#axs[0, 1].set_ylim(1e-2, 1e2)\n",
    "\n",
    "axs[0, 0].grid()\n",
    "axs[0, 1].grid()\n",
    "save_fig(fig, f'plots/{exp_name}_{row.mic_type}_calibration.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualize cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from simulation import get_freq_slice_theory\n",
    "from wall_detector import get_probability_cost, get_probability_fft\n",
    "\n",
    "mic_idx = 1\n",
    "\n",
    "#chosen_methods = results.normalization.unique()\n",
    "chosen_methods = ['raw'] +  plot_list + ['theoretical']\n",
    "\n",
    "chosen_frequencies = df_freq\n",
    "#chosen_frequencies = good_frequencies\n",
    "\n",
    "freq_indices = np.where(chosen_frequencies[None, :] == df_freq[:, None])[0]\n",
    "np.testing.assert_allclose(df_freq[freq_indices], chosen_frequencies)\n",
    "\n",
    "absolute_err_dict = {key: {method: [] for method in chosen_methods} for key in ['cost', 'fft']}\n",
    "\n",
    "distances = row.df_dist[row.df_dist <= max_distance]\n",
    "for i_d, distance in enumerate(distances):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig_cost, ax_cost = plt.subplots()\n",
    "    \n",
    "    for i_method, method in enumerate(chosen_methods):\n",
    "        df = results.loc[results.normalization==method]\n",
    "        slice_exp = df.iloc[0].matrix[[mic_idx], freq_indices, i_d]\n",
    "        \n",
    "        # doing this here for plotting reasons. Doesn't change performance as \n",
    "        # this is done again in get_probability_cost\n",
    "        slice_exp -= np.mean(slice_exp)\n",
    "        slice_exp /= np.std(slice_exp)\n",
    "\n",
    "        proba_cost = get_probability_cost(slice_exp, df_freq[freq_indices], \n",
    "                                          distances_grid, mic_idx=mic_idx)\n",
    "        distances_fft, proba_fft = get_probability_fft(slice_exp, df_freq[freq_indices])\n",
    "\n",
    "        # algorithm\n",
    "        d_cost_idx = np.argmax(proba_cost)\n",
    "        d_cost = distances_grid[d_cost_idx]\n",
    "        absolute_err_dict['cost'][method].append(abs(d_cost - distance))\n",
    "        \n",
    "        d_fft_idx = np.argmax(proba_fft)\n",
    "        d_fft = distances_fft[d_fft_idx]\n",
    "        absolute_err_dict['fft'][method].append(abs(d_fft - distance))\n",
    "\n",
    "        # plotting\n",
    "        ax.plot(chosen_frequencies, slice_exp, label=method, color=f'C{i_method}')\n",
    "        ax.set_xlim(min_freq, max_freq)\n",
    "        ax.set_ylim(-3, 3)\n",
    "        ax.set_xlabel('frequency [Hz]')\n",
    "        ax.set_ylabel('amplitude')\n",
    "        ax.set_title(f'slices for distance {distance:.0f}cm')\n",
    "\n",
    "        ax_cost.semilogy(distances_grid, proba_cost, color=f'C{i_method}', label=method)\n",
    "        ax_cost.semilogy(distances_fft, proba_fft, color=f'C{i_method}', ls=':')\n",
    "        ax_cost.axvline(x=d_cost, color=f'C{i_method}')\n",
    "        ax_cost.axvline(x=d_fft, color=f'C{i_method}', ls=':')\n",
    "        \n",
    "        ax_cost.axvline(x=distance, color='black', ls=':')\n",
    "        ax_cost.set_xlabel('distance sweep [cm]')\n",
    "        ax_cost.set_ylabel('probability')\n",
    "        ax_cost.set_xlim(min(distances_grid), max(distances_grid))\n",
    "        ax_cost.set_ylim(1e-5, 1)\n",
    "        ax_cost.set_title(f'probability for distance {distance:.0f}cm')\n",
    "        \n",
    "    ax.legend(loc='upper left')\n",
    "    ax_cost.legend(loc='lower right')\n",
    "\n",
    "    #fname = f'results/{exp_name}/slice_{mic_type}_{distance:.0f}_snr{snr}.png'\n",
    "    #save_fig(fig, fname)\n",
    "    #\n",
    "    #fname = f'results/{exp_name}/cost_{mic_type}_{distance:.0f}_snr{snr}.png'\n",
    "    #save_fig(fig_cost, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate algorithm performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "markers = [m for m in list(Line2D.markers.keys()) if m not in ['.', '', ',']]\n",
    "\n",
    "for key, absolute_err in absolute_err_dict.items():\n",
    "    i = 0\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, squeeze=False)\n",
    "    fig.set_size_inches(15, 5)\n",
    "    for method, absolute_errors in absolute_err.items():\n",
    "        markersize = 8-i\n",
    "        axs[0, 0].plot(distances, absolute_errors, label=method, marker=markers[i], ls=':', markersize=markersize)\n",
    "\n",
    "        xvals = sorted(absolute_errors)\n",
    "        yvals = np.linspace(0, 1, len(xvals))\n",
    "        axs[0, 1].plot(xvals, yvals, label=method, marker=markers[i], ls=':', markersize=markersize)\n",
    "        i += 1\n",
    "\n",
    "    #axs[0, 0].set_yscale('log')\n",
    "    axs[0, 0].set_ylabel('absolute error [cm]')\n",
    "    axs[0, 0].set_xlabel('distance [cm]')\n",
    "    axs[0, 0].legend(loc='upper right')\n",
    "\n",
    "    axs[0, 1].set_ylabel('pdf')\n",
    "    axs[0, 1].set_xlabel('absolute error [cm]')\n",
    "    axs[0, 1].set_xlim(-1, max(distances))\n",
    "    axs[0, 1].grid(which='both')\n",
    "    axs[0, 1].legend(loc='lower right')\n",
    "\n",
    "    #fname = f'results/{exp_name}/performance_{mic_type}_snr{snr}_subset.png'\n",
    "    #fname = f'results/{exp_name}/performance_{mic_type}_snr{snr}_all.png'\n",
    "    fname = f'plots/{exp_name}_{mic_type}_{key}_performance.png'\n",
    "    save_fig(fig, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.883px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
