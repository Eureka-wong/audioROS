{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"figure.max_open_warning\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_analysis import load_params\n",
    "\n",
    "def plot_square(x_indices, y_indices, ax):\n",
    "    ax.plot([x_indices[0], x_indices[-1]], [y_indices[-1],y_indices[-1]], color='red', linewidth=1)\n",
    "    ax.plot([x_indices[0], x_indices[-1]], [y_indices[0], y_indices[0]], color='red', linewidth=1)\n",
    "    ax.plot([x_indices[0], x_indices[0]], [y_indices[0],  y_indices[-1]], color='red', linewidth=1)\n",
    "    ax.plot([x_indices[-1],x_indices[-1]], [y_indices[0], y_indices[-1]], color='red', linewidth=1)\n",
    "\n",
    "def plot_df_matrix(dist, freq, df_matrix, ax=None, min_freq=None, max_freq=None, **kwargs):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    mask = np.ones(freq.shape, dtype=np.bool)\n",
    "    if min_freq is not None:\n",
    "        mask &= (freq > min_freq)\n",
    "    if max_freq is not None:\n",
    "        mask &= (freq < max_freq)\n",
    "    im = ax.pcolorfast(dist, freq[mask], df_matrix[mask][:-1, :-1], **kwargs)\n",
    "    return ax, im\n",
    "\n",
    "def init_results_df():\n",
    "    return pd.DataFrame(columns=['mic_type', 'snr', 'motors', 'exp_name', 'df_matrix', 'df_dist', 'df_freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs(fname):\n",
    "    import os\n",
    "    dirname = os.path.dirname(fname)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "        \n",
    "def save_fig(fig, fname):\n",
    "    make_dirs(fname)\n",
    "    fig.savefig(fname, bbox_inches='tight')\n",
    "    print('saved as', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_spectrograms(df_freq):\n",
    "    from frequency_analysis import get_spectrogram_raw\n",
    "    mic_type = 'measurement'\n",
    "    cut_x = range(0, 20)\n",
    "    cut_y = range(1000, 3000)\n",
    "\n",
    "    filters = ['mic_type', 'snr', 'source', 'degree', 'distance']\n",
    "    for chosen_tuple, df_source in df_freq.groupby(filters):\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, squeeze=False)\n",
    "        fig.set_size_inches(15, 5)\n",
    "        fig.suptitle(dict(zip(filters, chosen_tuple)))\n",
    "\n",
    "        for j, motors in enumerate([0, \"all43000\"]):\n",
    "            df_this = df_source[df_source.motors==motors]\n",
    "            if len(df_this) != 1:\n",
    "                print(df_this)\n",
    "                continue\n",
    "            row = df_this.iloc[0]\n",
    "\n",
    "            spec_all, freqs = get_spectrogram_raw(row.frequencies_matrix, row.stft)\n",
    "            spec = np.mean(spec_all, axis=1) # n_times x n_mics x n_freqs\n",
    "\n",
    "            axs[0, j].pcolorfast(row.seconds, freqs, np.log10(spec[:-1, :-1]))\n",
    "            axs[0, j].set_title(f'motors {motors}')\n",
    "            \n",
    "        #spec_cut = spec[:, cut_x]\n",
    "        #spec_cut = spec_cut[cut_y, :]\n",
    "        #axs[0, 2].pcolorfast(row.seconds[cut_x], row.frequencies[cut_y], np.log10(spec_cut))\n",
    "        #plot_square(cut_x, cut_y, ax=axs[0, 1])\n",
    "        #fig.savefig(f'/home/duembgen/Desktop/spec-{chosen_source}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental distance-frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import get_setup\n",
    "\n",
    "distance = 0\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(5, 5)\n",
    "for yaw_deg, marker in zip([0, 30], ['o', 'x']):\n",
    "    source, mic_positions = get_setup(distance_cm=distance, yaw_deg=yaw_deg)\n",
    "    source_image = [source[0], -source[1]]\n",
    "    for i, mic in enumerate(mic_positions):\n",
    "        plt.scatter(*mic, label=f'mic{i}, {yaw_deg}deg', marker=marker, color=f'C{i}')\n",
    "plt.plot([4.8, 5.4], [0, 0], color='k', label='wall')\n",
    "plt.title(f'setup for distance={distance}cm')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('x [m]')\n",
    "plt.ylabel('y [m]')\n",
    "plt.axis('equal')\n",
    "\n",
    "#fig.savefig(f'plots/setup_{distance}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#exp_name = '2020_12_9_rotating'; \n",
    "exp_name = '2020_11_26_wall'; \n",
    "fname = f'results/{exp_name}_real.pkl'\n",
    "\n",
    "try:\n",
    "    df_freq = pd.read_pickle(fname)\n",
    "    print('read', fname)\n",
    "except:\n",
    "    print('Error: run wall_analysis.py to parse experiments.')\n",
    "df_freq.iloc[:, :8]\n",
    "\n",
    "#plot_spectrograms(df_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# frequency slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas_utils import filter_by_dicts\n",
    "from wall_detector import WallDetector, normalized_std\n",
    "from frequency_analysis import apply_linear_mask, apply_box_mask\n",
    "from frequency_analysis import psd_df_from_spec, get_index_matrix, extract_psd\n",
    "\n",
    "chosen_dicts = [{\"appendix\":\"\", \"degree\": 0, \"distance\":10, \"motors\":0}]\n",
    "#chosen_dicts = [{\"appendix\":\"\", \"snr\": 1, \"degree\": 0, \"distance\":10, \"motors\":0}]\n",
    "df_mic_types = filter_by_dicts(df_freq, chosen_dicts)\n",
    "n_spurious = 2\n",
    "\n",
    "fig_bins, ax_bins = plt.subplots()\n",
    "\n",
    "for j, (i_row, row) in enumerate(df_mic_types.iterrows()):\n",
    "    if (row.mic_type == 'measurement') and (row.snr == 1): # this is no \"real snr\"\n",
    "        continue\n",
    "        \n",
    "    # processing\n",
    "    wall_detector = WallDetector(exp_name=exp_name, mic_type=row.mic_type)\n",
    "    spec_masked_all, freqs_masked = wall_detector.fill_from_row(row)\n",
    "    wall_detector.remove_spurious_freqs(n_spurious, verbose=False)\n",
    "    psd, freqs_psd = wall_detector.get_frequency_slice()\n",
    "    std_psd, __ = wall_detector.get_frequency_slice(method=normalized_std)\n",
    "    \n",
    "    # plotting\n",
    "    label = f'{row.mic_type}, snr={row.snr}'\n",
    "    spec_masked = np.mean(spec_masked_all, axis=1)\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 5)\n",
    "    ax.pcolorfast(row.seconds, freqs_masked, np.log10(spec_masked[:-1, :-1]))\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(psd.shape[0]):\n",
    "        plt.errorbar(freqs_psd, psd[i, :], std_psd[i, :], label=f'mic{i}')\n",
    "    plt.title(label)\n",
    "    [plt.axvline(f, color='black', ls=':') for f in freqs_psd]\n",
    "    \n",
    "    [ax_bins.plot([f, f], [j, j+1], color=f'C{j+1}', ls='-') for f in freqs_psd]\n",
    "    ax_bins.plot([], [], color=f'C{j+1}', ls='-', label=label)\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(1e-3, )\n",
    "    plt.legend()\n",
    "\n",
    "from bin_selection import generate_sweep\n",
    "from crazyflie_description_py.parameters import N_BUFFER, FS\n",
    "bins, t_sec = generate_sweep('sweep')\n",
    "freqs_sweep = np.fft.rfftfreq(N_BUFFER, 1/FS)\n",
    "[ax_bins.plot([f, f], [0, j+1], color=f'C0', ls='-') for f in freqs_sweep[bins]]\n",
    "ax_bins.plot([], [], color=f'C0', ls='-', label='sweep')\n",
    "ax_bins.set_xlabel('frequency [Hz]')\n",
    "ax_bins.legend(loc='lower left', bbox_to_anchor=[1.0, 0.0])\n",
    "ax_bins.set_xlim(1500, 5000)\n",
    "ax_bins.set_yticks([])\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Debug parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_distances = 3; i = 0\n",
    "#filter_dict = {'mic_type':'audio_deck', 'snr':1, 'motors':0}; mic_idx = 3\n",
    "#filter_dict = {'mic_type':'audio_deck', 'snr':0, 'motors':0}; mic_idx = 3\n",
    "filter_dict = {'mic_type':'measurement', 'snr':0, 'motors':0}; mic_idx = 0\n",
    "df_mic = filter_by_dicts(df_freq, [filter_dict])\n",
    "\n",
    "wall_detector = WallDetector(exp_name=exp_name, mic_type=filter_dict['mic_type'])\n",
    "\n",
    "for distance, df_this in df_mic.groupby('distance'):\n",
    "    if len(df_this) != 1: \n",
    "        print(f\"{len(df_this)} findings for {distance, filter_dict}\")\n",
    "        continue\n",
    "\n",
    "    row = df_this.iloc[0]\n",
    "    spec_masked_all, freqs_masked = wall_detector.fill_from_row(row)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolorfast(row.seconds, freqs_masked, np.log10(spec_masked_all[:-1, mic_idx, :-1]))\n",
    "    ax.set_title(f'distance={distance}cm')\n",
    "    \n",
    "    i += 1\n",
    "    if i >= n_distances:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "n_spurious = 2\n",
    "wall_detector.remove_spurious_freqs(n_spurious, verbose=False, dryrun=False)\n",
    "wall_detector.remove_bad_freqs(mag_thresh=1e-3, std_thresh=1, verbose=False, dryrun=False)\n",
    "\n",
    "df_matrix, distances, frequencies = wall_detector.get_df_matrix()\n",
    "df_matrix_std, distances, frequencies = wall_detector.get_df_matrix(method=np.nanstd)\n",
    "\n",
    "print(distances)\n",
    "\n",
    "# was only here to test that both give the same\n",
    "#df_matrix_old, distances_old, frequencies_old = wall_detector.get_df_matrix_old()\n",
    "\n",
    "df_sub = wall_detector.df\n",
    "df_sub = df_sub[(df_sub.mic==mic_idx)]\n",
    "\n",
    "fig_all, ax_all = plt.subplots()\n",
    "fig_all.set_size_inches(10, 5)\n",
    "print(df_matrix.shape)\n",
    "for i, distance in enumerate(distances):\n",
    "    df_plot = df_sub.loc[df_sub.distance==distance]\n",
    "    if len(df_plot) == 0:\n",
    "        continue\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(10, 5)\n",
    "    sns.scatterplot(data=df_plot, x='frequency', y='magnitude', hue='counter', linewidth=0, palette='inferno')\n",
    "    plt.errorbar(frequencies, df_matrix[mic_idx, :, i], df_matrix_std[mic_idx, :, i])\n",
    "    plt.xlim(1500, 4500)\n",
    "    plt.title(f'distance {distance:.0f}cm, mic{mic_idx}')\n",
    "    plt.yscale('log')\n",
    "    #plt.ylim(1e-3, 50)\n",
    "    plt.xlabel('frequency [Hz]')\n",
    "    plt.ylabel('amplitude')\n",
    "    \n",
    "    fname = f'results/{exp_name}/{filter_dict[\"mic_type\"]}_{distance:.0f}_snr{filter_dict[\"snr\"]}.png'\n",
    "    save_fig(fig, fname)\n",
    "    \n",
    "    ax_all.errorbar(frequencies, df_matrix[mic_idx, :, i], df_matrix_std[mic_idx, :, i], label=f'{distance}cm')\n",
    "ax_all.legend()\n",
    "ax_all.set_yscale('log')\n",
    "ax_all.set_ylim(1e-3, 50)\n",
    "ax_all.set_xlim(1500, 4500)\n",
    "ax_all.set_xlabel('frequency [Hz]')\n",
    "ax_all.set_ylabel('amplitude')\n",
    "fname = f'results/{exp_name}/{filter_dict[\"mic_type\"]}_snr{filter_dict[\"snr\"]}.png'\n",
    "save_fig(fig_all, fname)\n",
    "#wall_detector.remove_spurious_freqs(n_spurious, verbose=True)\n",
    "#df_amp, distances, frequencies = wall_detector.get_df_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from pandas_utils import fill_df\n",
    "    \n",
    "FILTERS = ['mic_type', 'snr', 'motors']\n",
    "\n",
    "def parse_wall_experiments(df_freq, max_distance=None, plot=False):\n",
    "    results_df = init_results_df()\n",
    "    for chosen_tuple, df_mic in df_freq.groupby(FILTERS, sort=False):\n",
    "        filter_dict = dict(zip(FILTERS, chosen_tuple))\n",
    "\n",
    "        wall_detector = WallDetector(exp_name=exp_name, mic_type=filter_dict['mic_type'])\n",
    "\n",
    "        if filter_dict['mic_type'] == 'measurement' and filter_dict['snr'] == 1:\n",
    "            continue\n",
    "        elif filter_dict['motors'] != 0:\n",
    "            continue\n",
    "\n",
    "        d_idx = 0\n",
    "        max_value = max_distance if max_distance is not None else len(df_mic)\n",
    "        with progressbar.ProgressBar(max_value=max_value) as p:\n",
    "            for distance, df_this in df_mic.groupby('distance'):\n",
    "                if len(df_this) != 1: \n",
    "                    print(f\"{len(df_this)} findings for {distance, filter_dict}\")\n",
    "                    continue\n",
    "                if max_distance is not None and (distance > max_distance):\n",
    "                    continue\n",
    "\n",
    "                row = df_this.iloc[0]\n",
    "                spec_masked_all, freqs_masked = wall_detector.fill_from_row(row)\n",
    "                p.update(d_idx); d_idx += 1\n",
    "                \n",
    "                if plot:\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.pcolorfast(range(spec_masked_all.shape[-1]), freqs_masked, np.log10(spec_masked_all[:, 0, :]))\n",
    "                    ax.set_title(f'distance={distance}cm')\n",
    "                \n",
    "        wall_detector.remove_spurious_freqs(n_spurious, verbose=False)\n",
    "        wall_detector.remove_bad_freqs(mag_thresh=1e-3, std_thresh=1, verbose=False, dryrun=False)\n",
    "\n",
    "        df_amp, distances, frequencies = wall_detector.get_df_matrix()\n",
    "        #df_std, *_ = wall_detector.get_df_matrix(method=normalized_std)\n",
    "        \n",
    "        assert df_amp.shape[1:] == (len(frequencies), len(distances)), df_amp.shape\n",
    "\n",
    "        filter_dict.update({'exp_name': exp_name})\n",
    "        fill_dict = {'df_dist':distances, \n",
    "                     'df_freq': frequencies,\n",
    "                     'df_matrix': df_amp}\n",
    "        print('filling results_df...')\n",
    "        results_df = fill_df(results_df, filter_dict, fill_dict)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'results/wall_analysis.pkl'\n",
    "#method = 'dryrun'\n",
    "#method = 'new'\n",
    "#method = 'replace'\n",
    "method = 'read'\n",
    "\n",
    "if method == 'read': \n",
    "    results_df = pd.read_pickle(fname)\n",
    "elif method == 'replace':\n",
    "    results_df = pd.read_pickle(fname)\n",
    "    \n",
    "    print('read', fname)\n",
    "    results_df_new = parse_wall_experiments(df_freq)\n",
    "    \n",
    "    for chosen_tuple, df in results_df_new.groupby(FILTERS):\n",
    "        assert len(df) == 1\n",
    "        row = df.iloc[0]\n",
    "        \n",
    "        filter_dict = dict(zip(FILTERS, chosen_tuple))\n",
    "        filter_dict.update({'exp_name': exp_name})\n",
    "        fill_dict = {'df_dist': row.df_dist, \n",
    "                     'df_freq': row.df_freq,\n",
    "                     'df_matrix': row.df_matrix}\n",
    "        print('filling results_df_old...')\n",
    "        results_df = fill_df(results_df, filter_dict, fill_dict)\n",
    "    pd.to_pickle(results_df, fname)\n",
    "    print('saved as', fname)\n",
    "elif method == 'new':\n",
    "    results_df = parse_wall_experiments(df_freq)\n",
    "    pd.to_pickle(results_df, fname)\n",
    "    print('saved as', fname)\n",
    "elif method == 'dryrun':\n",
    "    results_df = parse_wall_experiments(df_freq, max_distance=10, plot=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dict = dict(\n",
    "    exp_name = '2020_11_26_wall',\n",
    "    motors = 0,\n",
    "    snr = 0,\n",
    "    mic_type = 'measurement'\n",
    ")\n",
    "if (filter_dict['mic_type'] == 'measurement'):\n",
    "    # only one channel: chosen_mics = [1]\n",
    "    channel_to_mic_mapping = {0: 1}\n",
    "    chosen_mics = [0]\n",
    "else:\n",
    "    channel_to_mic_mapping = {i:i for i in range(4)}\n",
    "    chosen_mics = [3, 4]\n",
    "row = filter_by_dicts(results_df, [filter_dict]).iloc[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choose normalization scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_colorbar(ax, im):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical');\n",
    "    \n",
    "from calibration import get_calibration_function\n",
    "from wall_detector import normalize_df_matrix\n",
    "from copy import deepcopy\n",
    "from simulation import get_df_theory\n",
    "min_freq = 2000\n",
    "max_freq = 4800\n",
    "\n",
    "plot_channel_idx = 0\n",
    "\n",
    "calib_function = get_calibration_function(plot=True)\n",
    "\n",
    "mics = list(channel_to_mic_mapping.values())\n",
    "df_theory = get_df_theory(row.df_freq, row.df_dist, chosen_mics=mics) \n",
    "\n",
    "results = pd.DataFrame(columns=['normalization', 'data_type', 'matrix'])\n",
    "\n",
    "method_dict = dict(zip(['raw', 'calibration-offline', 'calibration-online', 'standardize', 'zero_mean', 'theoretical'], \n",
    "                       ['', calib_function, 'calibration-online', 'standardize', 'zero_mean', 'theoretical']))\n",
    "normalize_dict = {}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "for j, (key, method) in enumerate(method_dict.items()):\n",
    "    \n",
    "    for df_matrix, data_type in zip([row.df_matrix, df_theory], ['experimental', 'theoretical']): \n",
    "        \n",
    "        df_matrix = df_matrix[chosen_mics]\n",
    "        if key not in ['raw', 'theoretical']:\n",
    "            df_norm, values = normalize_df_matrix(df_matrix=df_matrix, \n",
    "                                          freqs=row.df_freq, method=method)\n",
    "            label = f'{key}, {data_type}'\n",
    "            \n",
    "            if data_type == 'theoretical':\n",
    "                ax.plot(row.df_freq, values[plot_channel_idx], color=f'C{j}', ls=':')\n",
    "            else:\n",
    "                ax.plot(row.df_freq, values[plot_channel_idx], label=label, color=f'C{j}')\n",
    "            \n",
    "        elif key == 'raw':\n",
    "            df_norm = deepcopy(df_matrix)\n",
    "        elif key == 'theoretical':\n",
    "            df_norm = deepcopy(df_theory[chosen_mics])\n",
    "\n",
    "        normalize_dict[key] = df_norm\n",
    "\n",
    "        results.loc[len(results), :] = {\n",
    "            'normalization': key,\n",
    "            'data_type': data_type,\n",
    "            'matrix': df_norm\n",
    "        }\n",
    "        \n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim(1e-3, 1e2)\n",
    "ax.set_xlim(min_freq, max_freq)\n",
    "ax.set_title(f'calibration values for mic {chosen_mics[plot_channel_idx]}')\n",
    "ax.legend()\n",
    "\n",
    "min_value = None\n",
    "max_value = 3 #None\n",
    "\n",
    "for normalization, df in results.groupby('normalization', sort=False):\n",
    "    assert len(df) == 2\n",
    "    df_exp = df.loc[df.data_type=='experimental'].iloc[0].matrix[plot_channel_idx]\n",
    "    df_the = df.loc[df.data_type=='theoretical'].iloc[0].matrix[plot_channel_idx]\n",
    "    rel_error = np.log10(np.abs(df_exp - df_the) / np.abs(df_the)) \n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, squeeze=False, sharey=True)\n",
    "    fig.set_size_inches(15, 5)\n",
    "    #plot_df_matrix(row.df_dist, row.df_freq, df_norm[i], ax=axs[0, i], min_freq=min_freq, max_freq=max_freq, vmin=1e-3, vmax=3)\n",
    "    ax, im = plot_df_matrix(row.df_dist, row.df_freq, df_exp, ax=axs[0, 0], \n",
    "                   min_freq=min_freq, max_freq=max_freq, vmin=min_value, vmax=max_value)\n",
    "    add_colorbar(ax, im)\n",
    "    ax, im = plot_df_matrix(row.df_dist, row.df_freq, df_the, ax=axs[0, 1], \n",
    "                   min_freq=min_freq, max_freq=max_freq, vmin=min_value, vmax=max_value)\n",
    "    add_colorbar(ax, im)\n",
    "    ax, im = plot_df_matrix(row.df_dist, row.df_freq, rel_error, ax=axs[0, 2], \n",
    "                   min_freq=min_freq, max_freq=max_freq, vmin=-3, vmax=np.log10(3))\n",
    "    add_colorbar(ax, im)\n",
    "    axs[0, 0].set_title(f'{normalization}, experimental')\n",
    "    axs[0, 1].set_title(f'{normalization}, theoretical')\n",
    "    axs[0, 2].set_title(f'{normalization}, log of relative error')\n",
    "    \n",
    "#print(np.nanmin(row.df_matrix), np.nanmax(row.df_matrix))\n",
    "#print(row.df_matrix.shape)\n",
    "#print(row.df_matrix[0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualize cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(arr1, arr2, freq, min_freq, max_freq):\n",
    "    #freq = np.array(list(freq))\n",
    "    mask_invalid = np.isnan(arr1) | np.isnan(arr2) | (freq < min_freq) | (freq > max_freq)\n",
    "    return np.linalg.norm(arr1[~mask_invalid] - arr2[~mask_invalid], ord=1)\n",
    "    \n",
    "    # cosine similarity\n",
    "    #return arr1[~mask_invalid].dot(arr2[~mask_invalid])/np.linalg.norm(arr1[~mask_invalid])/np.linalg.norm(arr2[~mask_invalid])\n",
    "\n",
    "def normalize_slice(slice_f, method_slice='zero_to_one'):\n",
    "    mask = ~np.isnan(slice_f)\n",
    "    if not np.any(mask):\n",
    "        print('Warning: no valid entries')\n",
    "        return slice_f\n",
    "    \n",
    "    if method_slice == 'zero_to_one':\n",
    "        slice_f[mask] -= np.min(slice_f[mask])\n",
    "        slice_f[mask] /= (np.max(slice_f[mask]) - np.min(slice_f[mask]))\n",
    "        slice_f[mask] += 1\n",
    "    elif method_slice == 'standardize':\n",
    "        slice_f[mask] -= np.mean(slice_f[mask])\n",
    "        slice_f[mask] /= np.std(slice_f[mask])\n",
    "    elif method_slice == 'calibrate':\n",
    "        if np.mean(slice_f[mask]) > 0:\n",
    "            slice_f[mask] /= np.mean(slice_f[mask])\n",
    "        else:\n",
    "            print('warning:', np.mean(slice_f[mask]))\n",
    "    elif method_slice == '':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(method_slice)\n",
    "    return slice_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from simulation import get_freq_slice_theory\n",
    "\n",
    "distances_grid = range(20)\n",
    "#method_slice = ''\n",
    "method_slice = 'standardize' \n",
    "\n",
    "chosen_methods = ['raw', 'calibration-online', 'standardize', 'theoretical'] \n",
    "#chosen_methods = ['raw', 'standardize', 'theoretical'] \n",
    "#chosen_methods = results.normalization.unique() \n",
    "\n",
    "absolute_err_dict = {method:[] for method in chosen_methods}\n",
    "\n",
    "distances = row.df_dist[row.df_dist < max(distances_grid)]\n",
    "for i_d, distance in enumerate(distances):\n",
    "    fig, axs = plt.subplots(1, len(chosen_mics), squeeze=False)\n",
    "        \n",
    "    fig_cost, ax_cost = plt.subplots()\n",
    "    \n",
    "    for i_method, (method, df) in enumerate(results.groupby('normalization', sort=False)):\n",
    "        if not method in chosen_methods:\n",
    "            continue\n",
    "        assert len(df) == 2\n",
    "\n",
    "        matrix_exp = df.loc[df.data_type=='experimental', 'matrix'].iloc[0]\n",
    "        matrix_the = df.loc[df.data_type=='theoretical', 'matrix'].iloc[0]\n",
    "        \n",
    "        slice_exp = matrix_exp[..., i_d]\n",
    "        slice_the = matrix_the[..., i_d]\n",
    "        \n",
    "        slice_exp = normalize_slice(slice_exp, method_slice)\n",
    "        slice_the = normalize_slice(slice_the, method_slice)\n",
    "        \n",
    "        costs = []\n",
    "        for d in distances_grid:\n",
    "            err = np.abs(d - row.df_dist)\n",
    "            d_idx = np.argmin(err)\n",
    "            if err[d_idx] > 1:\n",
    "                print(f'Warning: big error {err[d_idx]}')\n",
    "            \n",
    "            slice_the_here = matrix_the[..., d_idx]\n",
    "            \n",
    "            # TODO(FD)can normalize slices here if we want...\n",
    "            slice_the_here = normalize_slice(slice_the_here, method_slice)\n",
    "            \n",
    "            assert slice_the_here.shape == slice_exp.shape, (slice_the_here.shape, slice_exp.shape)\n",
    "            cost = cost_function(slice_the_here, slice_exp, row.df_freq, min_freq=min_freq, max_freq=max_freq)\n",
    "            costs.append(cost)\n",
    "            \n",
    "            \n",
    "        # algorithm\n",
    "        d_est_idx = np.argmin(costs)\n",
    "        d_est = distances_grid[d_est_idx]\n",
    "        absolute_err_dict[method].append(abs(d_est - distance))\n",
    "        \n",
    "        # plotting\n",
    "        for i_mic, mic in enumerate(chosen_mics): \n",
    "            axs[0, i_mic].plot(row.df_freq, slice_exp[mic], label=method, color=f'C{i_method}')\n",
    "            axs[0, i_mic].plot(row.df_freq, slice_the[mic], color=f'C{i_method}', ls=':')\n",
    "            axs[0, i_mic].set_xlim(min_freq, max_freq)\n",
    "            #axs[0, i_mic].set_yscale('log')\n",
    "            axs[0, i_mic].set_ylim(None, 4)\n",
    "            axs[0, i_mic].set_xlabel('frequency [Hz]')\n",
    "            axs[0, i_mic].set_ylabel('amplitude')\n",
    "            axs[0, i_mic].set_title(f'slices for distance {distance:.0f}cm, mic{mic}')\n",
    "            \n",
    "        ax_cost.plot(distances_grid, costs, color=f'C{i_method}', label=method)\n",
    "        ax_cost.axvline(x=distance, color='black', ls=':')\n",
    "        ax_cost.axvline(x=d_est, color=f'C{i_method}', ls=':')\n",
    "        ax_cost.set_xlabel('distance sweep [cm]')\n",
    "        ax_cost.set_ylabel('cost')\n",
    "        ax_cost.set_title(f'cost for distance {distance:.0f}cm')\n",
    "        \n",
    "    [axs[0, i_mic].legend(loc='upper left') for i_mic in range(len(chosen_mics))]\n",
    "    ax_cost.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate algorithm performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, squeeze=False)\n",
    "fig.set_size_inches(15, 5)\n",
    "for method, absolute_errors in absolute_err_dict.items():\n",
    "    axs[0, 0].plot(distances, absolute_errors, label=method, marker='o')\n",
    "    \n",
    "    xvals = sorted(absolute_errors)\n",
    "    yvals = np.linspace(0, 1, len(xvals))\n",
    "    axs[0, 1].plot(xvals, yvals, label=method, marker='o')\n",
    "    \n",
    "#axs[0, 0].set_yscale('log')\n",
    "axs[0, 0].set_ylabel('absolute error [cm]')\n",
    "axs[0, 0].set_xlabel('distance [cm]')\n",
    "axs[0, 0].legend(loc='upper right')\n",
    "\n",
    "axs[0, 1].set_ylabel('pdf')\n",
    "axs[0, 1].set_xlabel('absolute error [cm]')\n",
    "axs[0, 1].set_xlim(-1, max(distances))\n",
    "axs[0, 1].grid(which='both')\n",
    "axs[0, 1].legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#exp_name = '2020_12_7_moving'; \n",
    "exp_name = '2020_12_18_stepper'; \n",
    "fname = f'results/{exp_name}_real.pkl'\n",
    "\n",
    "params_dist = load_params(exp_name)\n",
    "\n",
    "try:\n",
    "    df_dist = pd.read_pickle(fname)\n",
    "    print('read', fname)\n",
    "except:\n",
    "    print('Error: run wall_analysis.py to parse experiments.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_analysis import add_distance_estimates\n",
    "from frequency_analysis import add_spectrogram\n",
    "\n",
    "df_dist = df_dist.assign(d_estimate=None)\n",
    "df_dist = df_dist.apply(add_distance_estimates, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from wall_analysis import filter_by_dicts\n",
    "labels = ['motors', 'source']\n",
    "vals_dict = {l:df_dist[l].unique() for l in labels}\n",
    "vals_dict['source'] = sorted(vals_dict['source'])\n",
    "vals_dict['motors'] = sorted([m for m in vals_dict['motors'] if type(m) is int]) + sorted([m for m in vals_dict['motors'] if not type(m) is int])\n",
    "print(vals_dict)\n",
    "\n",
    "fig, axs = plt.subplots(1, len(df_dist.mic_type.unique()))\n",
    "fig.set_size_inches(10, 5)\n",
    "axs = dict(zip(df_dist.mic_type.unique(), axs))\n",
    "fig.suptitle('timestamps for different datasets')\n",
    "for mic_type, df_mic in df_dist.groupby('mic_type'):\n",
    "    for i, val_tuple in enumerate(itertools.product(*vals_dict.values())):\n",
    "        filter_dict = dict(zip(labels, val_tuple))\n",
    "        df_here = filter_by_dicts(df_mic, [filter_dict])\n",
    "        \n",
    "        label = f\"{list(filter_dict.values())}\"\n",
    "        if len(df_here) != 1:\n",
    "            axs[mic_type].plot([], [], color=f'C{i%10}', label=label + ': missing')\n",
    "            continue\n",
    "        row = df_here.iloc[0]\n",
    "        axs[mic_type].plot(row.seconds, row.seconds+i*10, color=f'C{i%10}', label=label)\n",
    "    axs[mic_type].set_title(mic_type)\n",
    "    axs[mic_type].legend(bbox_to_anchor=[1.0, -0.1], loc='upper right')\n",
    "    \n",
    "fig, axs = plt.subplots(1, len(df_dist.mic_type.unique()))\n",
    "fig.set_size_inches(10, 5)\n",
    "axs = dict(zip(df_dist.mic_type.unique(), axs))\n",
    "fig.suptitle('distance estimates for different datasets')\n",
    "for mic_type, df_mic in df_dist.groupby('mic_type'):\n",
    "    for i, val_tuple in enumerate(itertools.product(*vals_dict.values())):\n",
    "        filter_dict = dict(zip(labels, val_tuple))\n",
    "        df_here = filter_by_dicts(df_mic, [filter_dict])\n",
    "        \n",
    "        label = f\"{list(filter_dict.values())}\"\n",
    "        if not len(df_here):\n",
    "            axs[mic_type].plot([], [], color=f'C{i%10}', label=label + ': missing')\n",
    "            continue\n",
    "        elif len(df_here) > 2:\n",
    "            raise ValueError(len(df_here))\n",
    "        row = df_here.iloc[0]\n",
    "        axs[mic_type].plot(row.seconds, row.d_estimate+i/100, color=f'C{i%10}', label=label)\n",
    "    axs[mic_type].set_title(mic_type)\n",
    "    axs[mic_type].legend(bbox_to_anchor=[1.0, -0.1], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_analysis import filter_by_dicts\n",
    "print(exp_name)\n",
    "if exp_name == \"2020_12_7_moving\":\n",
    "    motors = \"all43000\"\n",
    "    chosen_dicts = [\n",
    "        {\"source\": \"mono3125\", \"motors\": 0, \"appendix\":\"\"},\n",
    "        {\"source\": \"mono3125\", \"motors\": motors, \"appendix\":\"_new\"},\n",
    "        {\"source\": \"mono4156\", \"motors\": 0, \"appendix\":\"\"},\n",
    "        {\"source\": \"mono4156\", \"motors\": motors, \"appendix\":\"_new\"},\n",
    "        {\"source\": \"mono8000\", \"motors\": 0, \"appendix\":\"_new\"},\n",
    "        {\"source\": \"mono8000\", \"motors\": motors, \"appendix\":\"\"},\n",
    "        {\"source\": \"None\", \"motors\": motors, \"appendix\":\"_new\"},\n",
    "    ]\n",
    "    df_chosen = filter_by_dicts(df_dist, chosen_dicts)\n",
    "else: \n",
    "    chosen_dicts = [\n",
    "        {}\n",
    "    ]\n",
    "    df_chosen = filter_by_dicts(df_dist, chosen_dicts)\n",
    "print(df_chosen.source.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from frequency_analysis import get_spectrogram_raw\n",
    "\n",
    "filters = ['source', 'degree', 'mic_type', 'snr']\n",
    "for chosen_tuple, df_source in df_chosen.groupby(filters):\n",
    "    filter_dict = dict(zip(filters, chosen_tuple))\n",
    "    fig, axs = plt.subplots(1, 3, squeeze=False)\n",
    "    fig.set_size_inches(15, 5)\n",
    "    title = ''\n",
    "    for key, val in filter_dict.items():\n",
    "        title += f'{key}: {val}, '\n",
    "        break\n",
    "    title = title[:-2]\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    j_square = None\n",
    "    for j, motors in enumerate(params_dist.MOTORS_LIST):\n",
    "        df_this = df_source[df_source.motors==motors]\n",
    "        if len(df_this) != 1:\n",
    "            continue\n",
    "        row = df_this.iloc[0]\n",
    "        \n",
    "        spec_all, freqs = get_spectrogram_raw(row.frequencies_matrix, row.stft)\n",
    "        spec = np.mean(spec_all, axis=1)\n",
    "\n",
    "        axs[0, j].pcolorfast(row.seconds, freqs, np.log10(spec[:-1, :-1]))\n",
    "        axs[0, j].set_title(f'motors {motors}')\n",
    "        axs[0, j].set_ylim(100, 5000)\n",
    "        j_square = j\n",
    "        \n",
    "    #if j_square is not None:\n",
    "        #plot_square(row.seconds, row.frequencies, cut_x, cut_y, axs[0, j_square]) \n",
    "        #spec_square  = spec[:, cut_x]\n",
    "        #spec_square = spec_square[cut_y, :]\n",
    "        #axs[0, 2].pcolormesh(row.seconds[cut_x], row.frequencies[cut_y], np.log10(spec_square))\n",
    "    axs[0, 0].set_xlabel('time idx')\n",
    "    axs[0, 0].set_ylabel('frequency [Hz]')\n",
    "    axs[0, 1].set_xlabel('time idx')\n",
    "    axs[0, 1].set_ylabel('frequency [Hz]')\n",
    "    axs[0, 2].set_xlabel('time idx')\n",
    "    axs[0, 2].set_ylabel('frequency [Hz]')\n",
    "    \n",
    "    #fname = f'plots/spec_{filter_dict[\"source\"]}.pdf' \n",
    "    #fig.savefig(fname, bbox_inches='tight')\n",
    "    #print('saved as', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frequency selection for propeller noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = df_chosen.loc[df_chosen.source==\"None\"]\n",
    "df_mic = df_source.loc[df_source.mic_type == \"audio_deck\"]\n",
    "assert len(df_mic) == 1, df_mic\n",
    "row = df_mic.iloc[0]\n",
    "\n",
    "f_matrix = row.frequencies_matrix[:, 1:]\n",
    "print(f_matrix.shape)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "for i, col in enumerate(f_matrix.T):\n",
    "    if i < 3:\n",
    "        plt.scatter(row.seconds, col, color=f'C{i}', s=2)\n",
    "    else:\n",
    "        plt.scatter(row.seconds, col, color='C1', s=1, alpha=0.5)\n",
    "plt.ylim(100, 2000)\n",
    "\n",
    "levels = list(range(5))\n",
    "num_levels = len(levels)\n",
    "f_matrix\n",
    "fig, axs = plt.subplots(num_levels, sharey=False, sharex=True, squeeze=False)\n",
    "fig.set_size_inches(10, 10)\n",
    "for j, level in enumerate(levels):\n",
    "    axs[j, 0].plot(f_matrix[:, level], color=f\"C{j}\", marker='o')\n",
    "    axs[j, 0].set_title(f'level {level}')\n",
    "axs[j, 0].set_xlabel(f'time [idx]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_freqs = np.sort(f_matrix[:, :10].flatten())\n",
    "count, bins = np.histogram(all_freqs, bins=np.unique(all_freqs))\n",
    "plt.plot(bins[:-1], count, marker='x')\n",
    "plt.title('histogram strongest 10 frequency bins')\n",
    "print(bins[np.argsort(count)[::-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distance-slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#mic_indices = range(4)\n",
    "from constants import SPEED_OF_SOUND\n",
    "from frequency_analysis import get_bin\n",
    "\n",
    "filters = ['snr', 'motors', 'mic_type', 'distance']\n",
    "frequency_slice_df = pd.DataFrame(columns=filters+['psd', 'freqs', 'psd_std'])\n",
    "\n",
    "CHOSEN_MICS = [0, 1, 2, 3] #[3]\n",
    "CUT_LAST = 3\n",
    "CUT_FIRST = 3\n",
    "\n",
    "#CHOSEN_PROP_FREQ = 781 #\n",
    "CHOSEN_PROP_FREQ = 671 #\n",
    "#CHOSEN_PROP_FREQ = 2187 #1\n",
    "#CHOSEN_PROP_FREQ = 1453 \n",
    "\n",
    "for (chosen_source, mic_type), df_this in df_chosen.groupby(['source', 'mic_type']):\n",
    "    fig, axs = plt.subplots(1, 2, squeeze=False)\n",
    "    fig.set_size_inches(15, 5)\n",
    "    fig.suptitle(chosen_source)\n",
    "\n",
    "    for j, motors in enumerate(params_dist.MOTORS_LIST):\n",
    "        df_motors = df_this.loc[df_this.motors==motors]\n",
    "\n",
    "        if len(df_motors) != 1: \n",
    "            print(f\"{len(df_motors)} findings for {chosen_source, motors, mic_type}\")\n",
    "            continue\n",
    "            \n",
    "        row = df_motors.iloc[0]\n",
    "        if (chosen_source == \"None\"):\n",
    "            freq = CHOSEN_PROP_FREQ\n",
    "        elif \"mono\" in chosen_source:\n",
    "            freq = int(chosen_source.strip('mono'))\n",
    "        else:\n",
    "            print('warning: using 1000Hz', chosen_source)\n",
    "            freq = 1000\n",
    "\n",
    "        spec, freqs = get_spectrogram_raw(row.frequencies_matrix, row.stft)\n",
    "        bin_ = get_bin(freqs, freq)\n",
    "\n",
    "        #seconds = row.seconds[CUT_FIRST:-CUT_LAST]\n",
    "        #distances = seconds * 50 / 165.0\n",
    "        distances = row.d_estimate[CUT_FIRST:-CUT_LAST] * 100\n",
    "        for mic_idx in range(spec.shape[1]):\n",
    "            spec_bin = spec[bin_, mic_idx, CUT_FIRST:-CUT_LAST]\n",
    "            axs[0, j].plot(distances, spec_bin, label=f'mic{mic_idx}', color=f'C{mic_idx}')\n",
    "            axs[0, j].set_title(f'motors {motors}')\n",
    "\n",
    "        axs[0, j].set_ylim(min(spec_bin), max(spec_bin))\n",
    "        axs[0, j].legend(loc='upper right')\n",
    "        axs[0, j].set_xlim(10,60)\n",
    "        #axs[0, j].set_ylim(0,min(1, np.max(spec)))\n",
    "        continue\n",
    "\n",
    "        mean_d = np.median(distances[5:]-distances[4:-1])\n",
    "        #print(mean_d)\n",
    "        expected_period = SPEED_OF_SOUND / freq * 100 / 2 #\n",
    "        for mic_idx in mic_indices:\n",
    "            spec_fft = np.fft.rfft(spec)[1:]\n",
    "            freqs = np.fft.rfftfreq(len(spec), mean_d)[1:]\n",
    "            period = 1/freqs\n",
    "            axs[1, j].semilogx(period, np.abs(spec_fft), color=f'C{mic_idx}')\n",
    "            axs[1, j].axvline(expected_period, color=f'C{mic_idx}', ls=\":\") # cm\n",
    "        axs[1, j].set_xlim(1e-1,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## study chosen datasets more carefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 1750 \n",
    "#frequency = 3125 \n",
    "#frequency = 2375\n",
    "filter_dict = {\n",
    "    'source': f'mono{frequency}',\n",
    "    #'motors': 0,\n",
    "    'motors': 'all45000',\n",
    "    'mic_type': 'audio_deck',\n",
    "    #'mic_type': 'measurement'\n",
    "}\n",
    "df_chosen = filter_by_dicts(df_dist, [filter_dict])\n",
    "assert len(df_chosen) == 1, len(df_chosen)\n",
    "row = df_chosen.iloc[0]\n",
    "n_mics = row.stft.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import get_dist_slice_pyroom, get_dist_slice_theory\n",
    "\n",
    "spec, freqs = get_spectrogram_raw(row.frequencies_matrix, row.stft)\n",
    "n_mics = spec.shape[1]\n",
    "\n",
    "bin_ = get_bin(freqs, frequency) \n",
    "\n",
    "distances_cm = np.linspace(10, 60)\n",
    "slices_theory = get_dist_slice_theory(frequency, distances_cm=distances_cm)\n",
    "slices_pyroom = get_dist_slice_pyroom(frequency, distances_cm=distances_cm)\n",
    "\n",
    "fig1, axs1 = plt.subplots(1, n_mics, squeeze=False, sharey=True)\n",
    "fig2, axs2 = plt.subplots(1, n_mics, squeeze=False, sharey=True)\n",
    "fig1.set_size_inches(10, 5)\n",
    "fig2.set_size_inches(10, 5)\n",
    "\n",
    "for mic_idx in range(n_mics):\n",
    "    mask = ~np.isnan(row.d_estimate)\n",
    "    axs1[0, mic_idx].set_title(f'mic{mic_idx}')\n",
    "    axs1[0, mic_idx].semilogy(row.d_estimate[mask], spec[bin_, mic_idx, mask], \n",
    "                      color=f'C{mic_idx}', label='|Y(d)|')\n",
    "    axs1[0, mic_idx].grid(which='both')\n",
    "    axs1[0, mic_idx].legend(loc='upper left')\n",
    "    axs1[0, mic_idx].set_xlabel('distance [m]')\n",
    "    \n",
    "    axs2[0, mic_idx].semilogy(distances_cm / 100, slices_theory[:, mic_idx], color='black', label='theory')\n",
    "    axs2[0, mic_idx].semilogy(distances_cm / 100, slices_pyroom[:, mic_idx], color='gray', label='pyroom')\n",
    "    axs2[0, mic_idx].grid(which='both')\n",
    "    axs2[0, mic_idx].set_xlabel('distance [m]')\n",
    "    axs2[0, mic_idx].legend(loc='upper left')\n",
    "    axs2[0, mic_idx].set_ylim(2, 20)\n",
    "    \n",
    "    # custom stuff\n",
    "    if frequency == 1750:\n",
    "        if row.mic_type == 'measurement':\n",
    "            #axs1[0, mic_idx].set_ylim(1e-3, 1e-1)\n",
    "            #axs1[0, mic_idx].set_xlim(0.2, 0.4)\n",
    "            #axs2[0, mic_idx].set_xlim(0.2, 0.4)\n",
    "            pass\n",
    "        elif row.mic_type == 'audio_deck':\n",
    "            #axs1[0, mic_idx].set_ylim(1e-3, 5)\n",
    "            axs1[0, mic_idx].set_xlim(0.1, 0.25)\n",
    "            axs2[0, mic_idx].set_xlim(0.1, 0.25)\n",
    "            pass\n",
    "    if frequency == 2375:\n",
    "        if row.mic_type == 'measurement':\n",
    "            #axs1[0, mic_idx].set_ylim(1e-3, 1e-1)\n",
    "            axs1[0, mic_idx].set_xlim(0.2, 0.4)\n",
    "            axs2[0, mic_idx].set_xlim(0.2, 0.4)\n",
    "        elif row.mic_type == 'audio_deck':\n",
    "            #axs1[0, mic_idx].set_ylim(1e-3, 5)\n",
    "            axs1[0, mic_idx].set_xlim(0.3, 0.5)\n",
    "            axs2[0, mic_idx].set_xlim(0.3, 0.5)\n",
    "    elif frequency == 3125:\n",
    "        if row.mic_type == 'measurement':\n",
    "            #axs1[0, mic_idx].set_ylim(1e-3, 1e-1)\n",
    "            axs1[0, mic_idx].set_xlim(0.1, 0.3)\n",
    "            axs2[0, mic_idx].set_xlim(0.1, 0.3)\n",
    "        elif row.mic_type == 'audio_deck':\n",
    "            #axs1[0, mic_idx].set_ylim(1e-3, 5)\n",
    "            axs1[0, mic_idx].set_xlim(0.3, 0.5)\n",
    "            axs2[0, mic_idx].set_xlim(0.3, 0.5)\n",
    "    \n",
    "fig1.suptitle(f'{frequency} Hz, {row.mic_type} mic, motors:{row.motors}')\n",
    "fname = f'plots/d_slice_{frequency}_{row.mic_type}_{row.motors}.pdf'\n",
    "fig1.savefig(fname, bbox_inches='tight')\n",
    "\n",
    "fname = f'plots/d_slice_{frequency}_{row.mic_type}_{row.motors}_theory.pdf'\n",
    "fig2.savefig(fname, bbox_inches='tight')\n",
    "print('saved as', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. study the spectrum, frequency selection\n",
    "min_freq = 100\n",
    "max_freq = 5000\n",
    "\n",
    "spec_all, all_frequencies = get_spectrogram_raw(row.frequencies_matrix, row.stft)\n",
    "spec = np.nanmean(spec_all, axis=1)\n",
    "\n",
    "mask = (all_frequencies > min_freq) & (all_frequencies < max_freq)\n",
    "freqs = all_frequencies[mask]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_spec = np.full(spec.shape, np.nan)\n",
    "plot_spec[spec>0] = np.log10(spec[spec>0])\n",
    "ax.pcolorfast(range(len(row.seconds)), freqs, plot_spec[mask][:-1, :-1])\n",
    "ax.axhline(frequency, color='black', ls=':')\n",
    "\n",
    "fig, axs = plt.subplots(1, n_mics, squeeze=False)\n",
    "fig.set_size_inches(10, 5)\n",
    "for mic_idx in range(n_mics):\n",
    "    spec_avg = np.nanmean(spec_all[mask, mic_idx, :], axis=-1)\n",
    "    axs[0, mic_idx].plot(freqs, spec_avg, color=f'C{mic_idx}')\n",
    "    axs[0, mic_idx].axvline(frequency, color='black', ls=':')\n",
    "    freq_max = freqs[np.argmax(spec_avg)]\n",
    "    print(f'max bin vs. played bin: {freq_max}, {frequency}, difference: {freq_max - frequency}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from evaluate_data import read_df, integrate_yaw\n",
    "from dynamic_analysis import add_pose_to_df\n",
    "\n",
    "exp_name = '2020_11_26_wall'; \n",
    "#exp_name = '2020_12_9_rotating'; \n",
    "\n",
    "fname = f'results/{exp_name}_real.pkl'\n",
    "\n",
    "try:\n",
    "    df_total = pd.read_pickle(fname)\n",
    "    frequencies = df_total.iloc[0].frequencies\n",
    "    print('read', fname)\n",
    "except:\n",
    "    print('could not read', fname)\n",
    "    print('run wall_analysis.py')\n",
    "df_total.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_detector import WallDetector\n",
    "import progressbar\n",
    "\n",
    "mic_type = 'measurement'; \n",
    "#mic_type = 'audio_deck'; \n",
    "motors = 0\n",
    "snr = 0\n",
    "\n",
    "wall_detector = WallDetector(exp_name=exp_name, mic_type=mic_type)\n",
    "\n",
    "try: \n",
    "    wall_detector.fill_from_backup(exp_name, mic_type)\n",
    "except:\n",
    "    verbose = False\n",
    "    df_here = df_total[(df_total.mic_type==mic_type) & \n",
    "                       (df_total.motors==motors)&\n",
    "                       (df_total.snr==snr)]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    with progressbar.ProgressBar(max_value = len(df_total)) as p:\n",
    "        for i, row in df_here.iterrows():\n",
    "            spec, freqs = wall_detector.fill_from_row(row, verbose=verbose)\n",
    "            if ax is not None:\n",
    "                spec_avg = np.mean(spec, axis=1) \n",
    "                ax.pcolorfast(row.seconds, freqs, np.log10(spec_avg[:-1, :-1]))\n",
    "                ax = None\n",
    "\n",
    "            p.update(i)\n",
    "    wall_detector.backup(exp_name, mic_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_detector.remove_spurious_freqs(n_spurious=2, verbose=True)\n",
    "\n",
    "mic_idx = 0\n",
    "f_slices, freqs = wall_detector.get_frequency_slice(distance=1, max_freq=4500, min_freq=2000)\n",
    "plt.figure()\n",
    "plt.semilogy(freqs, f_slices[mic_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_slices, distances = wall_detector.get_distance_slice(frequency=1125)\n",
    "plt.figure()\n",
    "plt.plot(distances, d_slices[mic_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_mics, distances, frequencies = wall_detector.get_df_matrix(min_freq=1000, max_freq=4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = lambda x: np.nanstd(x) / np.mean(x)\n",
    "std_matrix_mics, distances, frequencies = wall_detector.get_df_matrix(min_freq=1000, max_freq=4500, method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in np.arange(len(frequencies))[::3]:\n",
    "    plt.semilogy(df_matrix_mics[0, index, :], label=frequencies[index])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from audio_stack.beam_former import normalize_rows\n",
    "\n",
    "df_matrix_norm = np.zeros_like(df_matrix_mics)\n",
    "for row in range(df_matrix_mics.shape[1]):\n",
    "    for mic in range(df_matrix_mics.shape[0]):\n",
    "        sub = df_matrix_mics[mic, row, :] \n",
    "        \n",
    "        # divide by mean\n",
    "        median = np.nanmedian(sub)\n",
    "        sub_norm = sub / median\n",
    "        df_matrix_norm[mic, row, :] = sub_norm\n",
    "        \n",
    "        # 0 to 1\n",
    "        #range_ = np.max(sub) - np.min(sub)\n",
    "        #sub_norm = (sub - np.min(sub)) / range_ \n",
    "        #df_matrix_norm[mic, row, :] = sub_norm\n",
    "\n",
    "        # sum to 1\n",
    "        #sub_norm = sub / np.sum(sub)\n",
    "        #df_matrix_norm[mic, row, :] = sub_norm\n",
    "        \n",
    "#mat = np.transpose(df_matrix_mics, (1, 2, 0))\n",
    "#mat_norm = normalize_rows(mat, method='sum_to_one')\n",
    "#df_matrix_norm = np.transpose(mat_norm, (2, 0, 1))\n",
    "\n",
    "for i in [0]: #range(df_matrix_mics.shape[0]):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolorfast(distances, frequencies, np.log10(df_matrix_mics[i, :-1, :-1]))\n",
    "    ax.set_title(f'mic{i}')\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolorfast(distances, frequencies, np.log10(std_matrix_mics[i, :-1, :-1]))\n",
    "    ax.set_title(f'std{i} normalized')\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolorfast(distances, frequencies, np.log10(df_matrix_norm[i, :-1, :-1]))\n",
    "    ax.set_title(f'mic{i} normalized')\n",
    "    \n",
    "    std_median = np.median(std_matrix_mics[i], axis=1) \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(frequencies, std_median)\n",
    "    thresh = np.median(std_median)\n",
    "    plt.axhline(thresh)\n",
    "    \n",
    "    df_matrix_norm_masked = np.copy(df_matrix_norm)\n",
    "    df_matrix_norm_masked[i, std_median > thresh] = 0\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolorfast(distances, frequencies, np.log10(df_matrix_norm_masked[i, :-1, :-1]))\n",
    "    ax.set_title(f'mic{i} normalized')\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolorfast(distances, frequencies, np.log10(df_matrix_mics[i, :-1, :-1]))\n",
    "    ax.set_title(f'mic{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distance slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from constants import SPEED_OF_SOUND\n",
    "\n",
    "for slice_f in range(df_matrix_norm.shape[1]):\n",
    "    fig, axs1 = plt.subplots(1, wall_detector.n_mics, sharey=False, squeeze=False)\n",
    "    fig.set_size_inches(15, 2)\n",
    "    fig, axs2 = plt.subplots(1, wall_detector.n_mics, sharey=True, squeeze=False)\n",
    "    fig.set_size_inches(15, 2)\n",
    "    axs = np.r_[axs1, axs2]\n",
    "    \n",
    "    f = frequencies[slice_f]\n",
    "    expected_period = SPEED_OF_SOUND / f * 1e2 / 2\n",
    "    \n",
    "    for mic_idx in range(wall_detector.n_mics):\n",
    "        distance_response = df_matrix_norm[mic_idx, slice_f, :]\n",
    "        axs[0, mic_idx].semilogy(distances, distance_response, label=f'{f:.0f}Hz')\n",
    "        axs[0, mic_idx].set_xlabel('distance [cm]')\n",
    "        axs[0, mic_idx].set_title(f'mic{mic_idx}')\n",
    "        axs[0, mic_idx].legend(loc='lower left')\n",
    "\n",
    "        distance_fft = np.fft.rfft(distance_response)[1:]\n",
    "        distance_freq = 1 / np.fft.rfftfreq(len(distances), 1)[1:] # cm \n",
    "        axs[1, mic_idx].loglog(distance_freq, np.abs(distance_fft))\n",
    "        axs[1, mic_idx].axvline(expected_period, ls=\":\")\n",
    "        axs[1, mic_idx].set_xlabel('period [cm]')\n",
    "    \n",
    "    axs[0, 0].set_ylabel('PSD')\n",
    "    axs[1, 0].set_ylabel('mag. of FFT of PSD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frequency slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from constants import SPEED_OF_SOUND\n",
    "\n",
    "for slice_d in range(1, df_matrix_norm.shape[2]):\n",
    "    fig, axs1 = plt.subplots(1, wall_detector.n_mics, sharey=False, squeeze=False)\n",
    "    fig.set_size_inches(15, 2)\n",
    "    fig, axs2 = plt.subplots(1, wall_detector.n_mics, sharey=True, squeeze=False)\n",
    "    fig.set_size_inches(15, 2)\n",
    "    axs = np.r_[axs1, axs2]\n",
    "    \n",
    "    d = distances[slice_d]\n",
    "    \n",
    "    expected_period = SPEED_OF_SOUND / (d * 1e-2) / 2\n",
    "    \n",
    "    for mic_idx in range(wall_detector.n_mics):\n",
    "        frequency_response = df_matrix_norm[mic_idx, :, slice_d]\n",
    "        mask = ~np.isnan(frequency_response)\n",
    "        frequency_response = frequency_response[mask]\n",
    "        \n",
    "        axs[0, mic_idx].semilogy(frequencies[mask], frequency_response, label=f'{d:.0f}cm')\n",
    "        axs[0, mic_idx].set_xlabel('frequency [Hz]')\n",
    "        axs[0, mic_idx].set_title(f'mic{mic_idx}')\n",
    "        axs[0, mic_idx].legend(loc='lower left')\n",
    "\n",
    "        frequency_fft = np.fft.rfft(frequency_response)[1:]\n",
    "        mean_df = np.mean(frequencies[mask][1:]-frequencies[mask][:-1])\n",
    "        frequency_freq = 1 / np.fft.rfftfreq(len(frequencies[mask]), mean_df)[1:] # cm \n",
    "        axs[1, mic_idx].loglog(frequency_freq, np.abs(frequency_fft))\n",
    "        axs[1, mic_idx].axvline(expected_period, ls=\":\")\n",
    "        axs[1, mic_idx].set_xlabel('period [Hz]')\n",
    "    \n",
    "    axs[0, 0].set_ylabel('PSD')\n",
    "    axs[1, 0].set_ylabel('mag. of FFT of PSD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angle analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_analysis import filter_by_dicts\n",
    "try:\n",
    "    filter_dict = dict(\n",
    "        distance=40,\n",
    "        degree=0,\n",
    "        source='sweep'\n",
    "    )\n",
    "    df = filter_by_dicts(df_total, [filter_dict])\n",
    "    row = df.iloc[0]\n",
    "    \n",
    "    spec = np.sum(np.abs(row.stft), axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    times = np.arange(spec.shape[0])\n",
    "    plt.pcolormesh(times, frequencies, np.log10(spec.T))\n",
    "\n",
    "    psd = get_psd(row.stft, frequencies, ax=plt.gca(), fname='real')\n",
    "\n",
    "    plt.figure()\n",
    "    for i_mic in range(psd.shape[0]):\n",
    "        plt.semilogy(frequencies, np.abs(psd[i_mic, :]), label=f\"mic{i_mic}\")\n",
    "    plt.xlabel('frequency [Hz]')\n",
    "    plt.ylabel('PSD')\n",
    "    plt.title(filter_dict)\n",
    "except ValueError:\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f'did not find {filter_dict} in')\n",
    "    print(df_total.distance.unique())\n",
    "    print(df_total.degree.unique())\n",
    "    print(df_total.source.unique())\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "degrees = [d for d in df_total.degree.unique() if d != 360][:2]\n",
    "distances = df_total.distance.unique()[:3]\n",
    "source = 'sweep'\n",
    "print(distances, degrees)\n",
    "\n",
    "fig, axs = plt.subplots(len(distances), len(degrees), sharex=True, sharey=True, squeeze=False)\n",
    "fig.set_size_inches(10, 10*axs.shape[0]/axs.shape[1])\n",
    "\n",
    "fig_psd, axs_psd = plt.subplots(len(distances), len(degrees), sharex=True, sharey=True, squeeze=False)\n",
    "fig_psd.set_size_inches(10, 10*axs.shape[0]/axs.shape[1])\n",
    "for i, distance in enumerate(distances):\n",
    "    for j, degree in enumerate(degrees):\n",
    "        df_this = df_total.loc[(df_total.distance == distance)\n",
    "                               & (df_total.degree == degree)\n",
    "                               & (df_total.source == source)]\n",
    "        \n",
    "        if not len(df_this) == 1:\n",
    "            print('skipping', distance, degree, source)\n",
    "            continue\n",
    "        row = df_this.iloc[0]\n",
    "        spec = row.spec #np.mean(row.spec, axis=1)\n",
    "        psd = row.psd\n",
    "        if psd is None:\n",
    "            psd = get_psd(row.stft)\n",
    "        \n",
    "        axs[i, j].pcolorfast(range(spec.shape[0]), frequencies, np.log10(spec.T))\n",
    "        for i_mic in range(psd.shape[0]):\n",
    "            axs_psd[i, j].semilogy(frequencies, np.abs(psd[i_mic, :]), label=f\"mic{i_mic}\")\n",
    "        axs[0, j].set_title(f'{degree} deg')\n",
    "        axs_psd[0, j].set_title(f'{degree} deg')\n",
    "    axs[i, 0].set_ylabel(f'{distance} cm')\n",
    "    axs_psd[i, 0].set_ylabel(f'{distance} cm')\n",
    "    \n",
    "[axs[-1, j].set_xlabel(f'time idx') for j in range(len(degrees))]\n",
    "[axs_psd[-1, j].set_xlabel(f'frequency [Hz]') for j in range(len(degrees))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import SPEED_OF_SOUND\n",
    "\n",
    "distances = df_total.distance.unique()[:3]\n",
    "distance_ref = sorted(df_total.distance.unique())[-1]\n",
    "source = 'sweep'\n",
    "n_mics = df_total.iloc[0].stft.shape[1]\n",
    "print('n_mics:', n_mics)\n",
    "    \n",
    "for degree in [0, 27, 54, 81][:2]:\n",
    "    \n",
    "    df_ref = df_total.loc[(df_total.distance == distance_ref)\n",
    "                           & (df_total.degree == degree)\n",
    "                           & (df_total.source == source)]\n",
    "    if len(df_ref) == 0:\n",
    "        continue\n",
    "\n",
    "    fig, axs = plt.subplots(1, n_mics, sharex=True, sharey=True)\n",
    "    fig.set_size_inches(15, 5)\n",
    "    \n",
    "    for mic in range(n_mics):\n",
    "        psd_ref = df_ref.iloc[0].psd[mic] \n",
    "        for i, distance in enumerate(distances):\n",
    "            df_this = df_total.loc[(df_total.distance == distance)\n",
    "                                   & (df_total.degree == degree)\n",
    "                                   & (df_total.source == source)]\n",
    "            axs[mic].semilogy(frequencies, df_this.iloc[0].psd[mic], label=distance, color=f\"C{i}\")\n",
    "            #axs[mic].semilogy(frequencies, df_this.iloc[0].psd[mic] / psd_ref, label=distance, color=f\"C{i}\")\n",
    "            #axs[mic].plot(frequencies, df_this.iloc[0].psd[mic] - psd_ref, label=distance, color=f\"C{i}\")\n",
    "\n",
    "        #axs[mic].set_xlim(min(frequencies), max(frequencies))\n",
    "        axs[mic].set_xlim(2000,  max(frequencies))\n",
    "        axs[mic].set_title(f\"mic{mic}\")\n",
    "    \n",
    "    fig.suptitle(degree)\n",
    "    axs[mic].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chosen_frequencies = frequencies[[10, 20, 30]]\n",
    "chosen_frequencies = frequencies[[30]]\n",
    "print(chosen_frequencies)\n",
    "\n",
    "distances = df_total.distance.unique()\n",
    "\n",
    "mic = 0\n",
    "\n",
    "for degree, df in df_total.groupby('degree'):\n",
    "    source = 'sweep'\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(15, 5)\n",
    "    for i, distance in enumerate(distances):\n",
    "        df_this = df.loc[(df.distance == distance)\n",
    "                       & (df.source == source)]\n",
    "        if len(df_this) == 0:\n",
    "            continue\n",
    "        row = df_this.iloc[0]\n",
    "        for f, freq in enumerate(chosen_frequencies):\n",
    "            chosen_idx = np.where(frequencies == freq)[0][0]\n",
    "            ax.scatter(distance, row.psd[mic, chosen_idx], color=f\"C{f}\")\n",
    "    ax.set_title(degree)\n",
    "    #ax.set_yscale('log')\n",
    "    ax.legend(chosen_frequencies)\n",
    "    ax.set_xlabel('distance [cm]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving angle analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#freq = 4125\n",
    "#source = 'None'\n",
    "source = 'mono4125'\n",
    "degree = 360\n",
    "\n",
    "if not degree in df_total.degree.unique():\n",
    "    raise ValueError('cannot do moving angle analysis on this dataset')\n",
    "\n",
    "distances = df_total.distance.unique()[:3]\n",
    "chosen_idx = np.where(frequencies == freq)[0][0]\n",
    "\n",
    "averages = []\n",
    "for i, distance in enumerate(distances):\n",
    "    fig, axs = plt.subplots(2)\n",
    "    fig.set_size_inches(15, 5)\n",
    "    \n",
    "    ax = axs[0]\n",
    "    df_this = df_total.loc[(df_total.distance == distance)\n",
    "                           & (df_total.degree == degree)]\n",
    "    df_this = df_this.loc[df_this.source == source]\n",
    "                           \n",
    "    stft = df_this.iloc[0].stft\n",
    "    yaw =  df_this.iloc[0].yaw\n",
    "    spec = df_this.iloc[0].spec\n",
    "\n",
    "    for j in range(stft.shape[1]):\n",
    "        ax.semilogy(range(stft.shape[0]), np.abs(stft[:, j, chosen_idx]), color=f\"C{j}\", label=f\"mic{j}\")\n",
    "\n",
    "    yaw[np.isnan(yaw)] = 0\n",
    "    axs[1].plot(range(stft.shape[0]), yaw)\n",
    "    for deg in -np.arange(1, 5)*90:\n",
    "        index = np.nanargmin(np.abs(yaw-deg))\n",
    "        axs[1].axvline(x=index, color='C1')\n",
    "        ax.axvline(x=index, color='C1')\n",
    "        \n",
    "    min_avg = 200\n",
    "    max_avg = 300\n",
    "    averages.append(np.sum(spec[min_avg:max_avg, chosen_idx], axis=0))\n",
    "        \n",
    "    ax.set_title(distance)\n",
    "    ax.set_ylim(0.05, 10)\n",
    "    ax.legend()\n",
    "    [ax.grid() for ax in axs]\n",
    "    \n",
    "    \n",
    "plt.figure()\n",
    "plt.scatter(distances, averages)\n",
    "plt.xlabel('distance [cm]')\n",
    "plt.title(f'average PSD at {freq} Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.883px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
