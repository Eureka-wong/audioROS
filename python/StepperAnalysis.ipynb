{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"figure.max_open_warning\"] = False\n",
    "rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "rcParams[\"font.size\"] = 14\n",
    "rcParams[\"text.usetex\"] = True\n",
    "import matplotlib\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.simulation import get_setup\n",
    "from utils.plotting_tools import save_fig, FIGSIZE\n",
    "from utils.geometry import Context\n",
    "from utils.constants import PLATFORM\n",
    "\n",
    "if PLATFORM == \"crazyflie\":\n",
    "    from crazyflie_description_py.experiments import WALL_ANGLE_DEG_STEPPER\n",
    "else:\n",
    "    from epuck_description_py.experiments import WALL_ANGLE_DEG_STEPPER\n",
    "\n",
    "plot_dir = 'plots/experiments'\n",
    "\n",
    "distance = 15\n",
    "#azimuth_deg = WALL_ANGLE_DEG_STEPPER #- 180\n",
    "azimuth_deg = WALL_ANGLE_DEG_STEPPER #- 180\n",
    "\n",
    "context = Context.get_platform_setup()\n",
    "context.plot()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(FIGSIZE, FIGSIZE)\n",
    "source, mic_positions = get_setup(distance_cm=distance, azimuth_deg=azimuth_deg)\n",
    "[ax.scatter(*mic[:2], label=f'mic{i}, $\\\\theta=${azimuth_deg}$^\\\\circ$') for i, mic in enumerate(mic_positions)]\n",
    "\n",
    "source, mic_positions = get_setup(distance_cm=distance, azimuth_deg=azimuth_deg, ax=ax)\n",
    "ax.set_title(f\"wall distance $d=${distance}cm \\n and angle $\\\\theta=${azimuth_deg}degrees\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "h_mics = {l.split(', $\\\\theta')[0]: h for h, l in zip(handles, labels) if '\\\\theta' in l}\n",
    "l1 = ax.legend(h_mics.values(), h_mics.keys(),loc=\"lower left\", bbox_to_anchor=[0.6, 0])\n",
    "\n",
    "h_other = {l: h for h, l in zip(handles, labels) if not 'mic' in l}\n",
    "ax.legend(h_other.values(), h_other.keys(),loc=\"lower right\", bbox_to_anchor=[0.6, 0])\n",
    "ax.add_artist(l1)\n",
    "ax.set_xlabel(\"x [m]\")\n",
    "ax.set_ylabel(\"y [m]\")\n",
    "#save_fig(fig, f'{plot_dir}/setup_{PLATFORM}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLATFORM == \"crazyflie\":\n",
    "    exp_name = \"2021_07_08_stepper_fast\"; # thesis\n",
    "    #exp_name = \"2021_10_07_stepper\"\n",
    "    motors = \"all45000\"\n",
    "    snr = 5\n",
    "else:\n",
    "    exp_name = \"2021_07_27_epuck_wall\"; # new sweep, better pipeline\n",
    "    motors = \"sweep_and_move\" \n",
    "    snr = 0\n",
    "mic_type = \"audio_deck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.data_collector import DataCollector\n",
    "\n",
    "data_collector = DataCollector()\n",
    "backup_exists = data_collector.fill_from_backup(exp_name, mic_type, motors, snr)\n",
    "if not backup_exists: \n",
    "    print('generate data using script generate_df_results.')\n",
    "df_matrix, df_dist, df_freq = data_collector.get_df_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Distance slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_slices(slice_exp, slice_the, dist):\n",
    "    fig_f, axs_f = plt.subplots(1, slice_exp.shape[0], squeeze=False, sharey=True)\n",
    "    fig_f.set_size_inches(2*FIGSIZE, FIGSIZE)\n",
    "    fig_f.suptitle(f\"Standardized distance slices, at frequency {f:.0f}Hz\")\n",
    "    for m in range(slice_exp.shape[0]):\n",
    "        slice_exp_norm = deepcopy(slice_exp[m])\n",
    "        slice_the_norm = deepcopy(slice_the[m])\n",
    "        slice_exp_norm -= np.mean(slice_exp_norm)\n",
    "        slice_the_norm -= np.mean(slice_the_norm)\n",
    "        slice_exp_norm /= np.std(slice_exp_norm)\n",
    "        slice_the_norm /= np.std(slice_the_norm)\n",
    "        \n",
    "        axs_f[0, m].plot(dist, slice_the_norm, label=\"theoretical\")\n",
    "        axs_f[0, m].plot(dist, slice_exp_norm, label=\"measured\")\n",
    "        axs_f[0, m].set_title(f\"mic{m}\")\n",
    "        axs_f[0, m].legend(loc=\"upper right\")\n",
    "        axs_f[0, m].set_xlabel(\"distance [cm]\")\n",
    "        axs_f[0, m].grid()\n",
    "    axs_f[0, 0].set_ylabel(\"amplitude\")\n",
    "    return fig_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pandas_utils import fill_nans\n",
    "from utils.simulation import get_dist_slice_theory\n",
    "from copy import deepcopy\n",
    "\n",
    "for i, f in enumerate(df_freq):\n",
    "        \n",
    "    slice_exp = df_matrix[:, i, :]\n",
    "    if np.any(np.isnan(slice_exp)):\n",
    "        slice_exp = fill_nans(slice_exp, df_dist)\n",
    "    slice_the = get_dist_slice_theory(f, df_dist, azimuth_deg=azimuth_deg).T\n",
    "    \n",
    "    fig_d = plot_slices(\n",
    "        slice_exp=slice_exp,\n",
    "        slice_the=slice_the,\n",
    "        dist=df_dist,\n",
    "    )\n",
    "    fname = f\"{exp_name}_{motors}\"\n",
    "    if f in [2562, 3375, 4500]: # manually picked these\n",
    "        save_fig(fig_d, f'{plot_dir}/{fname}_distance_slice_{f:.0f}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.simulation import factor_distance_to_delta\n",
    "\n",
    "d1 = df_dist[-1] # starting distance of distance slice. \n",
    "rel_movement_cm = df_dist[1]-df_dist[0]\n",
    "factors_max = {mic:factor_distance_to_delta(d1, \n",
    "                                        rel_movement_cm, \n",
    "                                        mic, azimuth_deg=azimuth_deg) \n",
    "           for mic in range(4)}\n",
    "print('factors_max:\\n', factors_max)\n",
    "dN = df_dist[0] # ending distance of distance slice. \n",
    "factors_min = {mic:factor_distance_to_delta(dN, \n",
    "                                        rel_movement_cm, \n",
    "                                        mic, azimuth_deg=azimuth_deg) \n",
    "               for mic in range(4)}\n",
    "print('factors_min:\\n', factors_min)\n",
    "print('average', np.mean(list(factors_max.values())+list(factors_min.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.inference import get_approach_angle_fft, get_approach_angle_cost\n",
    "from utils.plotting_tools import plot_performance, save_fig, titles, linestyles\n",
    "from utils.estimators import get_estimate, AngleEstimator\n",
    "from utils.inference import BAD_FREQ_RANGES, PLATFORM\n",
    "\n",
    "plot_slices = True\n",
    "gamma_min = 10\n",
    "\n",
    "start_distances_grid = [max(df_dist)+10] #[max(df_dist) + i for i in [0, 10, 20]]\n",
    "gammas_grid = np.arange(gamma_min, 91, step=1)\n",
    "\n",
    "factor = 2.0 # correction factor, 2 means we assume colocated\n",
    "gt_gamma = 90 # in degrees\n",
    "\n",
    "fig, ax_total = plt.subplots()\n",
    "ax_total.set_xlabel('approach angle $\\\\gamma$')\n",
    "ax_total.set_ylabel('probability')\n",
    "ax_total.set_title('combined distribution across mics and frequencies')\n",
    "\n",
    "#for algo in [\"bayes\"]#[\"cost\", \"bayes\"]:\n",
    "#algo = \"cost\" #\"bayes\"\n",
    "algo = \"bayes\" #\"bayes\"\n",
    "    \n",
    "estimator_all = AngleEstimator()\n",
    "\n",
    "labels = [\"all mics\"] + [f\"mic{m}\" for m in range(df_matrix.shape[0])] \n",
    "err_dict = {l: [np.nan]*len(df_freq) for l in labels}\n",
    "\n",
    "print(df_freq)\n",
    "for i, f in enumerate(df_freq):\n",
    "    if np.any([r[0] <= f <= r[1] for r in BAD_FREQ_RANGES]):\n",
    "        print('skipping', f)\n",
    "        continue\n",
    "    estimator = AngleEstimator()\n",
    "\n",
    "    d_slices = fill_nans(df_matrix[:, i, :], df_dist)\n",
    "\n",
    "    if plot_slices:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(7, 5)\n",
    "    for mic_idx in range(df_matrix.shape[0]):\n",
    "        d_slice = d_slices[mic_idx] ** 2\n",
    "\n",
    "        if algo == \"bayes\":\n",
    "            gammas, prob = get_approach_angle_fft(d_slice, f, df_dist,\n",
    "                                                         n_max=1000, bayes=True, \n",
    "                                                         reduced=False, \n",
    "                                                         factor=factor)\n",
    "        elif algo == \"cost\":\n",
    "            prob = get_approach_angle_cost(\n",
    "                d_slice,\n",
    "                f,\n",
    "                df_dist,\n",
    "                start_distances_grid,\n",
    "                gammas_grid,\n",
    "                mic_idx=mic_idx,\n",
    "                azimuth_deg=azimuth_deg\n",
    "            )  # is of shape n_start_distances x n_gammas_grid\n",
    "            gammas = gammas_grid\n",
    "            \n",
    "        prob = prob[gammas > gamma_min]\n",
    "        gammas = gammas[gammas > gamma_min]\n",
    "        \n",
    "        estimator_all.add_distribution(gammas, prob, mic_idx, f)\n",
    "        estimator.add_distribution(gammas, prob, mic_idx, f)\n",
    "\n",
    "        gamma = get_estimate(gammas, prob)\n",
    "        \n",
    "        err_dict[f\"mic{mic_idx}\"][i] = gamma - gt_gamma\n",
    "\n",
    "        if plot_slices:\n",
    "            ax.plot(gammas, prob)\n",
    "            ax.axvline(gamma, label=f'mic{mic_idx}, {algo}', color=f'C{mic_idx}', ls=linestyles[algo])\n",
    "\n",
    "    if plot_slices:\n",
    "        ax.set_title(f'frequency {f:.0f}Hz')\n",
    "        ax.set_xlabel('angle of approach $\\\\gamma$ [$^\\\\circ$]')\n",
    "        ax.set_ylabel('probability')\n",
    "        ax.legend()\n",
    "\n",
    "    #angles, prob = estimator.get_angle_distribution(mics_left_right=[[1, 2], [0, 3]])\n",
    "    angles, prob = estimator.get_angle_distribution(mics_left_right=None)\n",
    "    \n",
    "    gamma = get_estimate(angles, prob)\n",
    "    err_dict[\"all mics\"][i] = gamma - gt_gamma\n",
    "\n",
    "#angles, prob = estimator_all.get_angle_distribution(mics_left_right=[[1, 2], [0, 3]])\n",
    "angles, prob = estimator_all.get_angle_distribution(mics_left_right=None)\n",
    "ax_total.plot(angles, prob, label=algo)\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "fig, axs = plot_performance(err_dict, xs=df_freq, \n",
    "           xlabel=\"frequency [Hz]\", ylabel=\"error [$^\\\\circ$]\")\n",
    "max_err = 90 #45\n",
    "axs[1].set_xlim(0,  max_err)\n",
    "axs[0].set_ylim(-max_err, max_err)\n",
    "save_fig(fig, f'{plot_dir}/{fname}_{algo}_distance_slice_performance.pdf')\n",
    "\n",
    "ax_total.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Matrix analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.calibration import get_calibration_function_median\n",
    "from utils.constants import PLATFORM\n",
    "\n",
    "if PLATFORM == \"epuck\":\n",
    "    motors_list = [\"sweep_and_move\"]\n",
    "else:\n",
    "    motors_list = [\"all45000\", 0]\n",
    "\n",
    "for motors_here in motors_list:\n",
    "    fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    calib_function_median, freqs = get_calibration_function_median(\n",
    "        exp_name, mic_type, snr=snr, ax=axs[0], motors=motors_here\n",
    "    )\n",
    "    axs[0].legend(loc='lower right')\n",
    "    axs[0].set_title(\"calibration-individual\")\n",
    "\n",
    "    calib_function_median_one, freqs = get_calibration_function_median(\n",
    "        exp_name, mic_type, ax=axs[1], fit_one_gain=True, snr=snr, motors=motors_here\n",
    "    )\n",
    "    axs[1].set_title(\"calibration-global\")\n",
    "    axs[1].set_ylabel('')\n",
    "    axs[1].legend().set_visible(False)\n",
    "    save_fig(fig, f'{plot_dir}/{exp_name}_calibration_median_{motors_here}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.simulation import get_df_theory\n",
    "from utils.data_collector import normalize_df_matrix\n",
    "\n",
    "results = pd.DataFrame(columns=[\"normalization\", \"matrix\", \"values\"])\n",
    "method_dict = {\n",
    "    'raw': \"\",\n",
    "    'calibrated': calib_function_median,\n",
    "    'theoretical': \"\",\n",
    "    #'calibration-global': calib_function_median_one,\n",
    "}\n",
    "\n",
    "for j, (key, method) in enumerate(method_dict.items()):\n",
    "    values = None\n",
    "    if key == \"raw\":\n",
    "        df_norm = deepcopy(df_matrix)\n",
    "    elif key == \"theoretical\":\n",
    "        df_theory_pruned = get_df_theory(df_freq, df_dist)\n",
    "        df_norm = deepcopy(df_theory_pruned)\n",
    "    else:\n",
    "        df_norm, values = normalize_df_matrix(\n",
    "            df_matrix=df_matrix, freqs=df_freq, method=method\n",
    "        )\n",
    "    results.loc[len(results), :] = {\n",
    "        \"normalization\": key,\n",
    "        \"matrix\": df_norm,\n",
    "        \"values\": values,\n",
    "    }\n",
    "    # print(key, data_type, df_norm.shape)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.plotting_tools import plot_df_matrix, save_fig, titles, add_colorbar\n",
    "\n",
    "min_freq = min(df_freq) #3100 #min(df_freq)\n",
    "max_freq = max(df_freq) #5000 #max(df_freq)\n",
    "\n",
    "min_value = None\n",
    "max_value = None\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "\n",
    "figsize = 4\n",
    "\n",
    "for normalization, df in results.groupby(\"normalization\", sort=False):\n",
    "    matrix = df.iloc[0].matrix\n",
    "    n_mics = matrix.shape[0]\n",
    "    fig, axs = plt.subplots(1, n_mics, sharey=True)\n",
    "    fig.set_size_inches(n_mics*figsize, figsize)\n",
    "    axs[0].set_ylabel('frequency [Hz]')\n",
    "    for i in range(n_mics):\n",
    "        df_exp = df.iloc[0].matrix[i]\n",
    "        ax, im = plot_df_matrix(\n",
    "            df_dist,\n",
    "            df_freq,\n",
    "            df_exp,\n",
    "            ax=axs[i],\n",
    "            min_freq=min_freq,\n",
    "            max_freq=max_freq,\n",
    "            vmin=min_value,\n",
    "            vmax=max_value,\n",
    "        )\n",
    "        ax.set_title(f\"mic{i} {normalization}\")\n",
    "        ax.set_xlabel('distance [cm]')\n",
    "    add_colorbar(fig, ax, im)\n",
    "    #save_fig(fig, f\"plots/{fname}_matrices_{normalization}.png\")\n",
    "    \n",
    "for mic_idx in [1, 2]:\n",
    "    fig, axs = plt.subplots(1, len(method_dict), sharey=True)\n",
    "    fig.set_size_inches(len(method_dict)*figsize, figsize) \n",
    "    axs[0].set_ylabel('frequency [Hz]')\n",
    "    for i, (normalization, df) in enumerate(results.groupby(\"normalization\", sort=False)):\n",
    "        matrix = df.iloc[0].matrix\n",
    "        print(np.min(matrix), np.max(matrix))\n",
    "        n_mics = matrix.shape[0]\n",
    "        df_exp = df.iloc[0].matrix[mic_idx]\n",
    "        ax, im = plot_df_matrix(\n",
    "            df_dist,\n",
    "            df_freq,\n",
    "            df_exp,\n",
    "            ax=axs[i],\n",
    "            min_freq=min_freq,\n",
    "            max_freq=max_freq,\n",
    "            vmin=min_value,\n",
    "            vmax=max_value,\n",
    "        )\n",
    "        ax.set_title(f\"{normalization}\")\n",
    "        ax.set_xlabel('distance [cm]')\n",
    "    add_colorbar(fig, ax, im)\n",
    "    save_fig(fig, f\"{plot_dir}/{fname}_matrices_mic{mic_idx}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Frequency slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def angle_error(a1_deg, a2_deg):\n",
    "    return np.diff(np.unwrap([a1_deg / 180 * np.pi, a2_deg / 180 * np.pi]))[0] * 180 / np.pi\n",
    "\n",
    "def fill_distance(err_df, probs_dist, method):\n",
    "    d = get_estimate(distances_cm, probs_dist)\n",
    "    err_df.loc[len(err_df), :] = {\n",
    "        'error': d - distance,\n",
    "        'mic': 'all',\n",
    "        'distance': distance,\n",
    "        'method': method,\n",
    "        'algorithm': algo + ' distance',\n",
    "        'runtime': runtime,\n",
    "        'discretization':discretization\n",
    "    }\n",
    "\n",
    "def fill_angle(err_df, probs_angles, method):\n",
    "    a = get_estimate(angles_deg, probs_angles)\n",
    "    error_deg = angle_error(a, azimuth_deg)\n",
    "    runtime = time.time() - t1\n",
    "    err_df.loc[len(err_df), :] = {\n",
    "        'error': error_deg,\n",
    "        'mic': 'all',\n",
    "        'distance': distance,\n",
    "        'method': method,\n",
    "        'algorithm': algo + ' angle',\n",
    "        'runtime': runtime,\n",
    "        'discretization':discretization\n",
    "    }\n",
    "    \n",
    "import time\n",
    "from utils.calibration import get_calibration_function_median\n",
    "from utils.estimators import DistanceEstimator, get_estimate\n",
    "from utils.inference import Inference\n",
    "from utils.simulation import get_freq_slice_theory\n",
    "\n",
    "from utils.moving_estimators import MovingEstimator\n",
    "from utils.particle_estimators import ParticleEstimator\n",
    "import progressbar\n",
    "\n",
    "EPS = 1e-10  # clip probability distribution at this value\n",
    "err_df = pd.DataFrame(\n",
    "    columns=['method', 'mic', 'distance', 'error', 'algorithm', 'runtime', 'discretization'])\n",
    "algo = \"bayes\" # could do cost to\n",
    "\n",
    "distance_range = [min(df_dist), max(df_dist)]\n",
    "inf_machine = Inference()\n",
    "\n",
    "inf_machine.add_geometry(distance_range, azimuth_deg)\n",
    "\n",
    "chosen_mics = range(4) #[0, 1, 3] #range(4)\n",
    "n_mics = len(chosen_mics)\n",
    "\n",
    "use_uniform_prior = True\n",
    "\n",
    "discretizations = {\n",
    "    \"superfine\": (1.0, 5),\n",
    "    \"fine\": (2.0, 10),\n",
    "    \"medium\": (3.0, 20),\n",
    "    \"coarse\": (5.0, 30),\n",
    "    \"supercoarse\": (10.0, 90)\n",
    "}\n",
    "\n",
    "for discretization, (step_cm, step_deg) in discretizations.items():\n",
    "    print(f\"----------------- discretization {discretization} -------------------\")\n",
    "    \n",
    "    distances_cm = np.arange(7, 100, step=step_cm)\n",
    "    angles_deg = np.arange(360, step=step_deg)\n",
    "    n_particles = len(distances_cm) * len(angles_deg) // 2\n",
    "    print(f\"Nd = {len(distances_cm)}, Na = {len(angles_deg)} -> Np = {n_particles}\")\n",
    "    \n",
    "    for d in df_dist:\n",
    "        err_df.loc[len(err_df), :] = dict(\n",
    "            method='random',\n",
    "            mic='all',\n",
    "            distance=d, \n",
    "            error=np.random.choice(distances_cm) - d,\n",
    "            algorithm=f'{algo} distance',\n",
    "            runtime=0,\n",
    "            discretization=discretization\n",
    "        )\n",
    "        err_df.loc[len(err_df), :] = dict(\n",
    "            method='random',\n",
    "            mic='all',\n",
    "            distance=d, \n",
    "            error=np.random.choice(angles_deg) - azimuth_deg,\n",
    "            algorithm=f'{algo} angle',\n",
    "            runtime=0,\n",
    "            discretization=discretization\n",
    "        )\n",
    "        \n",
    "    \n",
    "    for method, normalize_method in method_dict.items():\n",
    "        print(\"running\", method)\n",
    "        \n",
    "        estimator_dict = {f\"histogram {n_window}\": MovingEstimator(\n",
    "                            n_window=n_window,\n",
    "                            distances_cm=distances_cm,\n",
    "                            angles_deg=angles_deg\n",
    "                        ) for n_window in [1, 3, 5]\n",
    "        }\n",
    "        estimator_dict[f\"particle {n_particles}\"] = ParticleEstimator(\n",
    "            n_particles=n_particles, \n",
    "            global_=False,\n",
    "            distances_cm=distances_cm, \n",
    "            angles_deg=angles_deg,\n",
    "        )\n",
    "\n",
    "        p = progressbar.ProgressBar(maxval=len(df_dist))\n",
    "        p.start()\n",
    "        for i_d, distance in enumerate(df_dist):\n",
    "        # do below for theoretical, uncalibrated and calibrated. \n",
    "\n",
    "            if method == \"theoretical\":\n",
    "                # squared:\n",
    "                slice_exp = get_freq_slice_theory(df_freq,\n",
    "                                                  distance,\n",
    "                                                  azimuth_deg=azimuth_deg, \n",
    "                                                  chosen_mics=chosen_mics)\n",
    "                slice_exp = np.sqrt(slice_exp.T) # now it's 4x32\n",
    "                freqs = df_freq\n",
    "            else:\n",
    "                # non-squared:\n",
    "                slice_exp, freqs, stds = data_collector.get_frequency_slice_fixed(df_freq,\n",
    "                    distance,\n",
    "                    mics=chosen_mics\n",
    "                                                                                 )\n",
    "            inf_machine.add_data(slice_exp, df_freq, mics=chosen_mics)\n",
    "            inf_machine.filter_out_freqs()\n",
    "            inf_machine.add_calibration_function(normalize_method)\n",
    "\n",
    "            distance_estimator = DistanceEstimator(distances_cm=distances_cm, angles_deg=angles_deg)\n",
    "            diff_dict = {}\n",
    "            for i_mic, mic_idx in enumerate(chosen_mics):\n",
    "                distances_cm_here, proba, diff_cm = inf_machine.do_inference(\n",
    "                    algorithm=algo, \n",
    "                    mic_idx=i_mic\n",
    "                )\n",
    "                diff_dict[mic_idx] = (diff_cm, proba)\n",
    "                distance_estimator.add_distribution(diff_cm * 1e-2, proba, mic_idx)\n",
    "                # uncomment to add individual mics.\n",
    "                #d = get_estimate(distances_cm_here, proba)\n",
    "                #err_df.loc[len(err_df), :] = {\n",
    "                #    'error': d - distance,\n",
    "                #    'mic': mic_idx, \n",
    "                #    'distance': distance,\n",
    "                #    'method': method,\n",
    "                #    'algorithm': algo\n",
    "                #}\n",
    "            for estimator in estimator_dict.values():\n",
    "                estimator.add_distributions(diff_dict, position_cm=[0, -distance])\n",
    "\n",
    "            angle_deg_here = None if use_uniform_prior else azimuth_deg\n",
    "\n",
    "            t1 = time.time()\n",
    "            __, proba = distance_estimator.get_distance_distribution(angle_deg=angle_deg_here)\n",
    "            runtime = time.time() - t1\n",
    "            fill_distance(err_df, proba, method=f\"{method} single\")\n",
    "\n",
    "            # angle distribution doesn't work with uniform prior!\n",
    "            # this is normal, there is no information on angle without some distance information.\n",
    "            t1 = time.time()\n",
    "            __, proba = distance_estimator.get_angle_distribution(distance_estimate_cm=distance)\n",
    "            runtime = time.time() - t1\n",
    "            fill_angle(err_df, proba, method=f\"{method} single\")\n",
    "\n",
    "            for name, estimator in estimator_dict.items():\n",
    "                t1 = time.time()\n",
    "                __, probs_dist, __, probs_angles = estimator.get_distributions(simplify_angles=False)\n",
    "                runtime = time.time() - t1\n",
    "                fill_distance(err_df, probs_dist, method=f'{method} {name}')\n",
    "                fill_angle(err_df, probs_angles, method=f'{method} {name}')\n",
    "    \n",
    "            p.update(i_d)\n",
    "\n",
    "err_df = err_df.apply(pd.to_numeric, axis=0, errors='ignore')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabel = \"runtime\"; sharey=True\n",
    "fig, axs = plt.subplots(1, len(err_df.algorithm.unique()), sharey=sharey)\n",
    "fig.set_size_inches(15, 5)\n",
    "for i, (type_, df_algo) in enumerate(err_df.groupby(\"algorithm\")):\n",
    "    df_algo = df_algo.loc[df_algo.method.str.startswith(\"theoretical\")]\n",
    "    df = pd.pivot_table(df_algo, values=ylabel, index=\"distance\", columns=\"method\")\n",
    "    #df.columns = ['_'.join(col) for col in df.columns.values]\n",
    "    df.reset_index(inplace=True)\n",
    "    df.plot(ax=axs[i], x=\"distance\")\n",
    "    \n",
    "    axs[i].set_ylabel(ylabel)\n",
    "    axs[i].set_xlabel(\"distance [cm]\")\n",
    "    axs[i].set_title(type_)\n",
    "    axs[i].grid(True, which='major')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = {\n",
    "    \"theoretical\": \"black\",\n",
    "    \"calibrated\": \"C2\",\n",
    "    \"raw\": \"C3\",\n",
    "    \"random\":\"C4\"\n",
    "}\n",
    "ls = {\n",
    "   \"histogram 1\": ':',\n",
    "   \"histogram 3\": '-.',\n",
    "   \"histogram 5\": '--',\n",
    "   \"particle 114\": '-',\n",
    "   \"particle 1674\": '-',\n",
    "   \"single\": (0, (1, 4)),\n",
    "   \"\": (0, (5, 7)), # random\n",
    "}\n",
    "units = {\n",
    "    \"bayes angle\": \"deg\",\n",
    "    \"bayes distance\": \"cm\",\n",
    "}\n",
    "\n",
    "# add extra columns for plots\n",
    "plot_df = err_df.loc[err_df.method.str.startswith(\"calibrated\"), :]\n",
    "for discretization, (step_cm, step_deg) in discretizations.items():\n",
    "    distances_cm = np.arange(7, 100, step=step_cm)\n",
    "    angles_deg = np.arange(360, step=step_deg)\n",
    "    n_particles = len(distances_cm) * len(angles_deg) // 2\n",
    "    plot_df.loc[plot_df.discretization == discretization, [\"number angles\", \"number distances\", \"number particles\"]] = (len(angles_deg), len(distances_cm), n_particles)\n",
    "    \n",
    "    \n",
    "for (algorithm), df_dis in plot_df.groupby([\"algorithm\"]):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax_time = ax.twinx()\n",
    "    for method, df in df_dis.groupby(\"method\"):\n",
    "        print(method)\n",
    "        color_name  = method.split(' ')[0]\n",
    "        ls_name = method.split(color_name)[1].strip()\n",
    "        \n",
    "        df.error = df.error.abs()\n",
    "        median = df.groupby(\"number angles\").median()\n",
    "        \n",
    "        ax.plot(np.arange(len(median)), median.error, ls=ls[ls_name], color='C0', label=ls_name)\n",
    "        ax_time.plot(np.arange(len(median)), median.runtime, ls=ls[ls_name], color='C1')\n",
    "        \n",
    "    xticklabels = [f\"{n_a}\\n{n_d}\\n{n_p}\" for (n_a, n_d, n_p) in zip(median.index, median[\"number distances\"], median[\"number particles\"])]\n",
    "    ax.set_xticks(np.arange(len(median)), labels=xticklabels)\n",
    "    \n",
    "    leg = ax.legend(loc='upper left', bbox_to_anchor=[1.2, 1.0])\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel(\"number of angles, distances, particles\")\n",
    "    ax.set_ylabel(f\"error [{units[algorithm]}]\", color=\"C0\")\n",
    "    ax_time.set_ylabel(\"runtime [s]\", color=\"C1\")\n",
    "    ax.set_title(f\"{algorithm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MAX = {\n",
    "    \"bayes angle\": err_df[err_df.algorithm==\"bayes angle\"].error.max(),\n",
    "    \"bayes distance\": 30 #err_df[err_df.algorithm==\"bayes distance\"].error.max()\n",
    "}#err_df.distance.max()\n",
    "for (discretization, algorithm), df_dis in err_df.groupby([\"discretization\", \"algorithm\"]):\n",
    "    fig, ax = plt.subplots()\n",
    "    for method, df in df_dis.groupby(\"method\"):\n",
    "        color_name  = method.split(' ')[0]\n",
    "        ls_name = method.split(color_name)[1].strip()\n",
    "        \n",
    "        cdf = sorted(np.abs(df.error))\n",
    "        if color_name == \"calibrated\":\n",
    "            label = ls_name\n",
    "        else:\n",
    "            label = None\n",
    "        ax.plot(cdf, np.linspace(0, 1, len(cdf)), color=color[color_name], linestyle=ls[ls_name], label=label)\n",
    "        \n",
    "    for name, c in color.items():\n",
    "        ax.plot([], [], color=c, label=name)\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(0, X_MAX[algorithm])\n",
    "    ax.set_title(f\"{discretization} discretization, {algorithm}\")\n",
    "    leg = ax.legend(loc='upper left', bbox_to_anchor=[1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.plotting_tools import plot_performance\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "if use_uniform_prior:\n",
    "    fname += \"_uniform\"\n",
    "    \n",
    "for key, df in err_df.groupby(\"algorithm\"):\n",
    "    if \"angle\" in key:\n",
    "        continue\n",
    "    for mic, df_mic in df.groupby(\"mic\"):\n",
    "        absolute_err = pd.pivot_table(df_mic, index=\"distance\", values=\"error\", columns=\"method\")\n",
    "        \n",
    "        # TODO: need to figure out if we need to replace df_dist below by distance again.\n",
    "        # that's what it was for stepper motor results\n",
    "        fig, axs = plot_performance(absolute_err, xs=df_dist, xlabel=\"distance [cm]\", ylabel=\"error [cm]\")\n",
    "        axs[0].grid()\n",
    "        #fig.suptitle(f'microphone: {mic}') #', {titles[key]}')\n",
    "        axs[1].set_xlim(-1, max(distances_cm))\n",
    "        \n",
    "        fname_here = f\"{plot_dir}/{fname}_{key}_mic{mic}_frequency_performance.png\"\n",
    "        #save_fig(fig, fname_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in err_df.groupby(\"algorithm\"):\n",
    "    if not \"angle\" in key:\n",
    "        continue\n",
    "    for mic, df_mic in df.groupby(\"mic\"):\n",
    "        absolute_err = pd.pivot_table(df_mic, index=\"distance\", values=\"error\", columns=\"method\")\n",
    "        \n",
    "        fig, axs = plot_performance(absolute_err, \n",
    "                                    xs=df_dist, xlabel=\"distance [cm]\", ylabel=\"error [deg]\")\n",
    "        axs[0].grid()\n",
    "        \n",
    "        fname_here = f\"{plot_dir}/{fname}_{key}_mic{mic}_frequency_performance.png\"\n",
    "        #save_fig(fig, fname_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.inference import eps_normalize\n",
    "from utils.simulation import get_freq_slice_theory\n",
    "from utils.plotting_tools import all_linestyles\n",
    "\n",
    "mic_idx = 1\n",
    "eps = 1e-5\n",
    "\n",
    "plot_combis = [\n",
    "    #{\"distance\": 15, \"algorithm\": \"cost\"},\n",
    "    {\"distance\": 15, \"algorithm\": \"bayes\"},\n",
    "    #{\"distance\": 17, \"algorithm\": \"bayes\"},\n",
    "    #{\"distance\": 28, \"algorithm\": \"bayes\"},\n",
    "]\n",
    "print(\"using uniform prior:\", use_uniform_prior)\n",
    "\n",
    "for plot_combi in plot_combis:\n",
    "    distance = plot_combi.get(\"distance\")\n",
    "    algorithm = plot_combi.get(\"algorithm\")\n",
    "\n",
    "    shape = (1, n_mics)\n",
    "    # plot the slices\n",
    "    fig_slice, axs_slice = plt.subplots(*shape, sharex=True, sharey=True)\n",
    "    fig_slice.set_size_inches(3 * shape[1], 2 * shape[0])\n",
    "    # plot the results \n",
    "    fig_algo, axs_algo = plt.subplots(*shape, sharex=True, sharey=True)\n",
    "    fig_algo.set_size_inches(3 * shape[1], 2 * shape[0])\n",
    "\n",
    "    distance_estimators = {k: DistanceEstimator() for k in method_dict.keys()}\n",
    "    for i_method, (method, normalize_method) in enumerate(method_dict.items()):\n",
    "        if method == \"theoretical\":\n",
    "            slice_exp = get_freq_slice_theory(df_freq,\n",
    "                                              distance,\n",
    "                                              azimuth_deg=azimuth_deg, \n",
    "                                              chosen_mics=chosen_mics)\n",
    "            slice_exp = slice_exp.T # now it's 4x32\n",
    "            freqs = df_freq\n",
    "        else:\n",
    "            slice_exp, freqs, stds = data_collector.get_frequency_slice_fixed(\n",
    "                df_freq,\n",
    "                distance,\n",
    "                mics=chosen_mics)\n",
    "            slice_exp = np.sqrt(slice_exp)\n",
    "            \n",
    "            \n",
    "        inf_machine.add_data(slice_exp, df_freq, mics=chosen_mics)\n",
    "        inf_machine.filter_out_freqs()\n",
    "        inf_machine.add_calibration_function(normalize_method)\n",
    "\n",
    "        for i_mic, mic_idx in enumerate(chosen_mics):\n",
    "            distances_bayes, proba_bayes_norm, diff_bayes = inf_machine.do_inference(\n",
    "                algorithm=\"bayes\", \n",
    "                mic_idx=i_mic,\n",
    "                #normalize=False\n",
    "            )\n",
    "            \n",
    "            inf_machine.plot(i_mic=i_mic, ax=axs_slice[i_mic], label=method, standardize=True,\n",
    "                             ls=all_linestyles[i_method])#marker='o')\n",
    "\n",
    "            distance_estimators[method].add_distribution(\n",
    "                diff_bayes * 1e-2, proba_bayes_norm, mic_idx\n",
    "            )\n",
    "            d = get_estimate(distances_bayes, proba_bayes_norm)\n",
    "\n",
    "            axs_algo[i_mic].semilogy(\n",
    "                distances_bayes,\n",
    "                eps_normalize(proba_bayes_norm, eps=eps),\n",
    "                color=f\"C{i_method}\",\n",
    "                ls=all_linestyles[i_method],\n",
    "                label=method,\n",
    "            )\n",
    "            axs_algo[i_mic].axvline(x=d, color=f\"C{i_method}\", ls=\":\") \n",
    "            axs_algo[i_mic].set_title(f\"mic{mic_idx}\")\n",
    "            axs_slice[i_mic].set_title(f\"mic{mic_idx}\")\n",
    "        \n",
    "    label_real = f\"real: {distance:.0f}cm\"\n",
    "    #axs_slice[-1].legend(title=label_real, bbox_to_anchor=[1.0, 1.0], loc='upper left')\n",
    "    #axs_algo[-1].legend(title=label_real, bbox_to_anchor=[1.0, 1.0], loc='upper left')\n",
    "    axs_slice[0].set_ylabel('amplitude') \n",
    "    axs_algo[0].set_ylabel('probability') \n",
    "    [ax.set_xlabel('frequency [Hz]') for ax in axs_slice]\n",
    "    [ax.set_xlabel('distance [cm]') for ax in axs_algo]\n",
    "\n",
    "    fname_here = f\"{plot_dir}/{fname}_{distance}cm_raw_slices.png\"\n",
    "    save_fig(fig_slice, fname_here)\n",
    "    fname_here = f\"{plot_dir}/{fname}_{distance}cm_raw_results.png\"\n",
    "    save_fig(fig_algo, fname_here)\n",
    "\n",
    "    fig_combi, axs_combi = plt.subplots(1, 2)\n",
    "    fig_combi.set_size_inches(6, 3)\n",
    "    \n",
    "    print(\"getting distance distribution...\")\n",
    "    ax_combi = axs_combi[0]\n",
    "    for i_method, (method, distance_estimator) in enumerate(\n",
    "        distance_estimators.items()\n",
    "    ):\n",
    "        azimuth_deg_here = None if use_uniform_prior else azimuth_deg_here\n",
    "        distances_m, proba = distance_estimator.get_distance_distribution(\n",
    "            azimuth_deg=azimuth_deg_here, distances_m=distances_grid_m, verbose=False,\n",
    "            method=\"sum\"\n",
    "        )\n",
    "        print(distances_m, proba)\n",
    "        ax_combi.plot(\n",
    "            distances_m*1e2,\n",
    "            eps_normalize(proba, eps=eps),\n",
    "            color=f\"C{i_method}\",\n",
    "            ls=all_linestyles[i_method],\n",
    "            label=method,\n",
    "        )\n",
    "    ax_combi.axvline(x=distance, color=\"black\", ls=\":\")\n",
    "    ax_combi.set_xlabel(\"distance [cm]\")\n",
    "    ax_combi.set_ylabel(\"probability\")\n",
    "    #ax_combi.set_title(\"total probability\")\n",
    "    ax_combi.set_yscale(\"log\")\n",
    "\n",
    "    print(\"getting angle distribution...\")\n",
    "    ax_combi = axs_combi[1]\n",
    "    for i_method, (method, distance_estimator) in enumerate(\n",
    "        distance_estimators.items()\n",
    "    ):\n",
    "\n",
    "        # doesn't work with uniform prior!!\n",
    "        distance_m_here = d * 1e-2\n",
    "        angles, proba = distance_estimator.get_angle_distribution(\n",
    "            distance_estimate_m=distance_m_here,\n",
    "            azimuths_deg=np.arange(360),\n",
    "            method=\"sum\",\n",
    "        )\n",
    "        ax_combi.plot(\n",
    "            angles,\n",
    "            eps_normalize(proba, eps=eps),\n",
    "            color=f\"C{i_method}\",\n",
    "            ls=all_linestyles[i_method],\n",
    "            label=method,\n",
    "        )\n",
    "    ax_combi.axvline(\n",
    "        x=azimuth_deg, color=\"black\", ls=\":\", label=f\"real: {distance:.0f}cm, {azimuth_deg:.0f}$^\\\\circ$\"\n",
    "    )\n",
    "    ax_combi.legend(loc=\"upper left\", bbox_to_anchor=[1.0, 1.0])\n",
    "    ax_combi.set_xlabel(\"angle [$^\\\\circ$]\")\n",
    "    #ax_combi.set_title(\"total probability\")\n",
    "    ax_combi.set_yscale(\"log\")\n",
    "    plt.subplots_adjust(wspace=0.25)\n",
    "\n",
    "    fname_here = f\"{plot_dir}/{fname}_{distance}cm_raw_total.png\"\n",
    "    save_fig(fig_combi, fname_here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calibration analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"2021_07_08_stepper_fast\"\n",
    "mic_type = \"audio_deck\"\n",
    "motors = \"all45000\"\n",
    "snr = 5\n",
    "plot_tuples = [(0, 3125)]\n",
    "\n",
    "data_collector = DataCollector()\n",
    "backup_exists = data_collector.fill_from_backup(exp_name, mic_type, motors, snr=snr)\n",
    "if not backup_exists: \n",
    "    print('generate data using script generate_df_results.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.calibration import fit_distance_slice\n",
    "from utils.simulation import get_amplitude_function\n",
    "\n",
    "fname = f'{exp_name}_{motors}'\n",
    "all_distances = data_collector.df.distance.unique()\n",
    "\n",
    "mic_idx = 0\n",
    "max_distance = 35\n",
    "\n",
    "for i, (frequency, df_freq_here) in enumerate(data_collector.df.groupby('frequency')):\n",
    "    distances = df_freq_here.distance.unique()\n",
    "    if len(distances) < len(all_distances): # only plot distances with \"full coverage\"\n",
    "        continue\n",
    "    \n",
    "    df_here = df_freq_here.loc[df_freq_here.mic==mic_idx]\n",
    "        \n",
    "    coeffs_median, distances_median, fit_median, cost_median = data_collector.fit_to_median(frequency, [mic_idx])\n",
    "    alpha, offset, gain = coeffs_median\n",
    "        \n",
    "    # find the sigma for this frequency (per distance)\n",
    "    std_series = df_here.groupby('distance').magnitude.std() # per distance\n",
    "    std_average = np.nanmean(std_series.values)\n",
    "    amps = get_amplitude_function(std_series.index, \n",
    "                                  gain, \n",
    "                                  alpha, mic_idx)\n",
    "    valid_distances = std_series.index[amps >= std_average]\n",
    "    limit_distance = valid_distances[-1] if len(valid_distances) else 0\n",
    "\n",
    "    #print(f'raw: mic {mic}, frequency {frequency}')\n",
    "    #print(f'median: alpha={alpha:.2f}, gain={gain:.2f}, offset={offset:.0f}, cost={cost_median}')\n",
    "\n",
    "\n",
    "    label = f\"{frequency:.0f}Hz\"\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    ax_fit, ax_freq = axs\n",
    "    \n",
    "    slices_median, distances_median_all, mics, stds = data_collector.get_distance_slice(frequency)\n",
    "    for d, series in df_here.groupby('distance').magnitude: \n",
    "        ax_fit.scatter([d]*len(series), series.values, color='C0', s=4)#, s=5.0)\n",
    "    ax_fit.scatter([], [], color='C0', label='raw', s=4)#, s=5.0)\n",
    "\n",
    "    ax_fit.plot(distances_median_all, slices_median[mic_idx, :], color='C0', label='distance slice')\n",
    "    ax_fit.plot(distances_median, fit_median, color='C1', label='model fit')\n",
    "\n",
    "    ax_fit.set_title('fit for ' + label)\n",
    "    ax_fit.set_ylabel('amplitude [-]')\n",
    "    ax_fit.set_xlabel('distance [cm]')\n",
    "    ax_fit.legend(loc='lower left')\n",
    "    ax_fit.set_xlim(min(distances_median), max_distance)\n",
    "\n",
    "    ax_freq.semilogy(std_series.index, amps, ls=':', color=f'C0', label=f'magnitude')\n",
    "    ax_freq.axhline(std_average, label=f'average std', color=f'C0')\n",
    "    ax_freq.scatter(std_series.index, std_series.values, label=f'std', color=f'C0', s=4)\n",
    "    ax_freq.set_xlim(min(distances_median), max_distance)\n",
    "\n",
    "    ax_freq.set_title('magnitude vs. noise for ' + label)\n",
    "    ax_freq.legend(loc='lower left')\n",
    "    ax_freq.set_xlabel('distance [cm]')\n",
    "    #ax_freq.set_ylabel('magnitude vs. std [-]')\n",
    "\n",
    "    if (mic_idx, frequency) not in plot_tuples:\n",
    "        continue\n",
    "        \n",
    "    fname_here = f'{plot_dir}/{fname}_fitting_{frequency:.0f}_{mic_idx}.png'\n",
    "    save_fig(fig, fname_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.883px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
