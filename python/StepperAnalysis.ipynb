{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"figure.max_open_warning\"] = False\n",
    "rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "rcParams[\"font.size\"] = 14\n",
    "rcParams[\"text.usetex\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.simulation import get_setup\n",
    "from utils.plotting_tools import save_fig, FIGSIZE\n",
    "from utils.geometry import Context\n",
    "from utils.constants import PLATFORM\n",
    "\n",
    "if PLATFORM == \"crazyflie\":\n",
    "    from crazyflie_description_py.experiments import WALL_ANGLE_DEG_STEPPER\n",
    "else:\n",
    "    from epuck_description_py.experiments import WALL_ANGLE_DEG_STEPPER\n",
    "\n",
    "plot_dir = 'plots/experiments'\n",
    "\n",
    "distance = 15\n",
    "#azimuth_deg = WALL_ANGLE_DEG_STEPPER #- 180\n",
    "azimuth_deg = WALL_ANGLE_DEG_STEPPER #- 180\n",
    "\n",
    "context = Context.get_platform_setup()\n",
    "context.plot()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(FIGSIZE, FIGSIZE)\n",
    "source, mic_positions = get_setup(distance_cm=distance, azimuth_deg=azimuth_deg)\n",
    "[ax.scatter(*mic[:2], label=f'mic{i}, $\\\\theta=${azimuth_deg}$^\\\\circ$') for i, mic in enumerate(mic_positions)]\n",
    "\n",
    "source, mic_positions = get_setup(distance_cm=distance, azimuth_deg=azimuth_deg, ax=ax)\n",
    "ax.set_title(f\"wall distance $d=${distance}cm \\n and angle $\\\\theta=${azimuth_deg}degrees\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "h_mics = {l.split(', $\\\\theta')[0]: h for h, l in zip(handles, labels) if '\\\\theta' in l}\n",
    "l1 = ax.legend(h_mics.values(), h_mics.keys(),loc=\"lower left\", bbox_to_anchor=[0.6, 0])\n",
    "\n",
    "h_other = {l: h for h, l in zip(handles, labels) if not 'mic' in l}\n",
    "ax.legend(h_other.values(), h_other.keys(),loc=\"lower right\", bbox_to_anchor=[0.6, 0])\n",
    "ax.add_artist(l1)\n",
    "ax.set_xlabel(\"x [m]\")\n",
    "ax.set_ylabel(\"y [m]\")\n",
    "#save_fig(fig, f'{plot_dir}/setup_{PLATFORM}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLATFORM == \"crazyflie\":\n",
    "    exp_name = \"2021_07_08_stepper_fast\"; # thesis\n",
    "    #exp_name = \"2021_10_07_stepper\"\n",
    "    motors = \"all45000\"\n",
    "    snr = 5\n",
    "else:\n",
    "    exp_name = \"2021_07_27_epuck_wall\"; # new sweep, better pipeline\n",
    "    motors = \"sweep_and_move\" \n",
    "    snr = 0\n",
    "mic_type = \"audio_deck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.data_collector import DataCollector\n",
    "\n",
    "data_collector = DataCollector()\n",
    "backup_exists = data_collector.fill_from_backup(exp_name, mic_type, motors, snr)\n",
    "if not backup_exists: \n",
    "    print('generate data using script generate_df_results.')\n",
    "df_matrix, df_dist, df_freq = data_collector.get_df_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a utils/inference.py\n",
    "def get_uniform_grid(xvalues):\n",
    "    \"\"\" Fill too large spaces of xvalues with uniform sampling of the median spacing of xvalues.\n",
    "    Example:\n",
    "    [0, 2, 4, 10, 12, 14]\n",
    "    becomes\n",
    "    [0, 2, 4, 6, 8, 10, 12, 14]\n",
    "    \"\"\"\n",
    "    counter = 0 \n",
    "    while 1:\n",
    "        diffs = np.diff(xvalues)\n",
    "        median = np.median(diffs)\n",
    "        diffs = np.r_[median, diffs]\n",
    "        split = np.where(diffs > median * 1.5)[0]\n",
    "        if not len(split):\n",
    "            break\n",
    "        s = split[0]\n",
    "        xvalues = np.r_[xvalues[:s], np.arange(xvalues[s-1], xvalues[s]+median, step=median), xvalues[s:]]\n",
    "        counter += 1\n",
    "        if counter > 10:\n",
    "            break\n",
    "        break\n",
    "    return xvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Matrix analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.calibration import get_calibration_function_median\n",
    "from utils.constants import PLATFORM\n",
    "\n",
    "if PLATFORM == \"epuck\":\n",
    "    motors_list = [\"sweep_and_move\"]\n",
    "else:\n",
    "    motors_list = [\"all45000\", 0]\n",
    "\n",
    "for motors_here in motors_list:\n",
    "    fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    calib_function_median, freqs = get_calibration_function_median(\n",
    "        exp_name, mic_type, snr=snr, ax=axs[0], motors=motors_here\n",
    "    )\n",
    "    axs[0].legend(loc='lower right')\n",
    "    axs[0].set_title(\"calibration-individual\")\n",
    "\n",
    "    calib_function_median_one, freqs = get_calibration_function_median(\n",
    "        exp_name, mic_type, ax=axs[1], fit_one_gain=True, snr=snr, motors=motors_here\n",
    "    )\n",
    "    axs[1].set_title(\"calibration-global\")\n",
    "    axs[1].set_ylabel('')\n",
    "    axs[1].legend().set_visible(False)\n",
    "    save_fig(fig, f'{plot_dir}/{exp_name}_calibration_median_{motors_here}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.plotting_tools import plot_df_matrix, save_fig, titles, add_colorbar\n",
    "from utils.simulation import get_df_theory\n",
    "from utils.data_collector import normalize_df_matrix\n",
    "\n",
    "min_freq = min(df_freq) #3100 #min(df_freq)\n",
    "max_freq = max(df_freq) #5000 #max(df_freq)\n",
    "\n",
    "min_value = None\n",
    "max_value = None\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "figsize = 2\n",
    "\n",
    "methods = ['measured', 'theoretical'] #['raw', 'calibrated','theoretical']\n",
    "mic_idx = 1\n",
    "fig_all, axs_all = plt.subplots(1, len(methods), sharey=True)\n",
    "fig_all.set_size_inches(len(methods)*figsize, figsize) \n",
    "\n",
    "for j, method in enumerate(methods):\n",
    "    if method == \"raw\":\n",
    "        df_norm = df_matrix\n",
    "    elif method == \"theoretical\":\n",
    "        df_norm = get_df_theory(df_freq, df_dist)\n",
    "    elif method == \"measured\":\n",
    "        calib_values = calib_function_median(df_freq)[:, :, None]\n",
    "        df_norm = df_matrix #/ calib_values\n",
    "\n",
    "    n_mics = df_norm.shape[0]\n",
    "    fig, axs = plt.subplots(1, n_mics, sharey=True)\n",
    "    fig.set_size_inches(n_mics*figsize, figsize)\n",
    "    axs[0].set_ylabel('frequency [Hz]')\n",
    "    for i in range(n_mics):\n",
    "        df_exp = df_norm[i]\n",
    "        ax, im = plot_df_matrix(\n",
    "            df_dist,\n",
    "            df_freq,\n",
    "            df_exp,\n",
    "            ax=axs[i],\n",
    "            min_freq=min_freq,\n",
    "            max_freq=max_freq,\n",
    "            vmin=min_value,\n",
    "            vmax=max_value,\n",
    "        )\n",
    "        ax.set_title(f\"mic{i} {method}\")\n",
    "        ax.set_xlabel('distance [cm]')\n",
    "    #add_colorbar(fig, ax, im)\n",
    "    #save_fig(fig, f\"plots/{fname}_matrices_{normalization}.png\")\n",
    "    \n",
    "    ax, im = plot_df_matrix(\n",
    "        df_dist,\n",
    "        df_freq,\n",
    "        df_norm[mic_idx],\n",
    "        ax=axs_all[j],\n",
    "        min_freq=min_freq,\n",
    "        max_freq=max_freq,\n",
    "        vmin=min_value,\n",
    "        vmax=max_value,\n",
    "    )\n",
    "    ax.set_title(f\"{method}\")\n",
    "    ax.set_xlabel('distance [cm]')\n",
    "    #add_colorbar(fig, ax, im)\n",
    "axs_all[0].set_ylabel('frequency [Hz]')\n",
    "save_fig(fig_all, f\"{plot_dir}/{fname}_matrices_mic{mic_idx}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Frequency slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = {\n",
    "    \"theoretical\": \"black\",\n",
    "    \"calibrated\": \"C2\",\n",
    "    #\"raw\": \"C3\",\n",
    "    \"random\":\"C4\",\n",
    "    \"fixed\":\"C5\"\n",
    "}\n",
    "ls = {\n",
    "   \"histogram 1\": ':',\n",
    "   \"histogram 3\": '-.',\n",
    "   \"histogram 5\": '--',\n",
    "   \"particle\": '-',\n",
    "   \"single\": (0, (1, 4)),\n",
    "   \"\": '-' # random\n",
    "   #\"\": (0, (5, 7)), # random\n",
    "}\n",
    "units = {\n",
    "    \"bayes angle\": \"deg\",\n",
    "    \"bayes distance\": \"cm\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_pickle(\"results/stepper_results_timing.pkl\")\n",
    "#plot_df = pd.read_pickle(\"results/stepper_results_online_new.pkl\")\n",
    "\n",
    "#plot_df = plot_df.loc[plot_df.method.str.startswith(\"calibrated\")]\n",
    "#plot_df = plot_df.loc[plot_df.method.str.startswith(\"calibrated\")]\n",
    "\n",
    "# add extra columns for plots\n",
    "from generate_filtering_results import DISCRETIZATIONS\n",
    "for discretization in plot_df.discretization.unique():\n",
    "    step_cm, step_deg = DISCRETIZATIONS[discretization]\n",
    "    distances_cm = np.arange(7, 80, step=step_cm)\n",
    "    angles_deg = np.arange(360, step=step_deg)\n",
    "    n_particles = len(distances_cm) * len(angles_deg) // 2\n",
    "    plot_df.loc[plot_df.discretization == discretization, [\"number angles\", \"number distances\", \"number particles\"]] = (len(angles_deg), len(distances_cm), n_particles)\n",
    "    \n",
    "for (algorithm), df_dis in plot_df.groupby([\"algorithm\"]):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(4*figsize, 2*figsize)\n",
    "    ax_time = ax.twinx()\n",
    "    particles_error = {}\n",
    "    particles_runtime = {}\n",
    "    for method, df in df_dis.groupby(\"method\"):\n",
    "        df[\"error\"] = df[\"error\"].abs()\n",
    "        if \"particle\" in method:\n",
    "            particle_median = df.groupby(\"number particles\").median()\n",
    "            particles_error[particle_median.index[0]] = particle_median.error.values[0]\n",
    "            particles_runtime[particle_median.index[0]] = particle_median.runtime.values[0]\n",
    "        elif \"histogram\" in method:\n",
    "            color_name  = method.split(' ')[0]\n",
    "            ls_name = method.split(color_name)[1].strip()\n",
    "            print(\"using linestyle\", ls[ls_name])\n",
    "\n",
    "            median = df.groupby(\"number angles\").median()\n",
    "\n",
    "            xs = median[\"number particles\"].values\n",
    "            ax.semilogx(xs, median.error, ls=ls[ls_name], color='C0', label=ls_name)\n",
    "            ax_time.semilogx(xs, median.runtime, ls=ls[ls_name], color='C1')\n",
    "        else:\n",
    "            print(\"not plotting\", method)\n",
    "    # sort particles by number\n",
    "    particles_error = dict(sorted(particles_error.items()))\n",
    "    ax.plot(xs, particles_error.values(), ls=ls[\"particle\"], color='C0', label=\"particle\")\n",
    "    particles_runtime = dict(sorted(particles_runtime.items()))\n",
    "    ax_time.plot(xs, particles_runtime.values(), ls=ls[\"particle\"], color='C1', label=\"particle\")\n",
    "\n",
    "    xticklabels = [f\"{n_a:.0f}\\n{n_d:.0f}\\n{n_p:.0f}\" for (n_a, n_d, n_p) in zip(median.index, median[\"number distances\"], particles_error.keys())]\n",
    "    ax.set_xticks(xs, labels=xticklabels)\n",
    "\n",
    "    #leg = ax.legend(loc='upper left', bbox_to_anchor=[1.2, 1.0])\n",
    "    #leg = ax.legend(loc='lower center',ncol=2,bbox_to_anchor=[0.5, 1.0])\n",
    "    leg = ax.legend(loc='upper center',ncol=2)\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel(\"$N_{\\\\theta}$ \\n $N_d$ \\n $N_p$\")\n",
    "    ax.xaxis.set_label_coords(-0.05, -0.025)\n",
    "    ax.set_ylabel(f\"median error [{units[algorithm]}]\", color=\"C0\")\n",
    "    ax_time.set_ylabel(\"runtime [s]\", color=\"C1\")\n",
    "    ax_time.yaxis.set_tick_params(colors=\"C1\")\n",
    "    ax.yaxis.set_tick_params(colors=\"C0\")\n",
    "    #ax.set_title(f\"{algorithm}\")\n",
    "    save_fig(fig, f\"plots/experiments/{exp_name}_{algorithm.replace(' ', '_')}_time-error.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_double_legend(ax, exclude=[]):\n",
    "    leg = ax.legend(loc='lower left', bbox_to_anchor=[1.0, 0.5], title=\"discretization method\")\n",
    "    lines = []\n",
    "    for name, c in color.items():\n",
    "        if name in exclude:\n",
    "            continue\n",
    "        name = \"measured\" if name == \"calibrated\" else name\n",
    "        lines.append(ax.plot([], [], color=c)[0])\n",
    "    ax.legend(lines, color.keys(), loc='upper left', bbox_to_anchor=[1.0, 0.5], title=\"used data\")\n",
    "    ax.add_artist(leg)\n",
    "    \n",
    "\n",
    "# very good results:\n",
    "plot_df = pd.read_pickle(\"results/stepper_results_online.pkl\")\n",
    "\n",
    "# updated particle filter etc.\n",
    "#plot_df = pd.read_pickle(\"results/stepper_results_online_new.pkl\")\n",
    "plot_df = pd.read_pickle(\"results/stepper_results_online_new_uniform.pkl\")\n",
    "\n",
    "#plot_df = err_df.copy()\n",
    "\n",
    "X_MAX = {\n",
    "    \"bayes angle\": plot_df[plot_df.algorithm==\"bayes angle\"].error.max(),\n",
    "    \"bayes distance\": 30 #plot_df[plot_df.algorithm==\"bayes distance\"].error.max()\n",
    "}#plot_df.distance.max()\n",
    "print(plot_df.discretization.unique())\n",
    "for (discretization, algorithm), df_dis in plot_df.groupby([\"discretization\", \"algorithm\"], sort=False):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(4*figsize, 2*figsize)\n",
    "    for method, df in df_dis.groupby(\"method\"):\n",
    "        color_name  = method.split(' ')[0]\n",
    "        ls_name = method.split(color_name)[1].strip()\n",
    "        if \"particle\" in ls_name:\n",
    "            ls_name = \"particle\"\n",
    "        \n",
    "        cdf = sorted(np.abs(df.error))\n",
    "        if color_name == \"calibrated\":\n",
    "            label = ls_name\n",
    "        else:\n",
    "            label = None\n",
    "        ax.plot(cdf, np.linspace(0, 1, len(cdf)), color=color[color_name], linestyle=ls[ls_name], label=label)\n",
    "        \n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(0, X_MAX[algorithm])\n",
    "    ax.set_title(f\"{discretization} discretization, {algorithm}\")\n",
    "    ax.set_xlabel(f\"absolute error [{units[algorithm]}]\")\n",
    "    ax.set_ylabel(\"cdf [-]\")\n",
    "    add_double_legend(ax)\n",
    "    \n",
    "    save_fig(fig, f\"plots/experiments/{exp_name}_{algorithm.replace(' ', '_')}_{discretization.replace(' ', '_')}_cdfs.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.pandas_utils import filter_by_dict\n",
    "\n",
    "#plot_df = pd.read_pickle(\"results/stepper_results_online.pkl\")\n",
    "plot_df = pd.read_pickle(\"results/stepper_results_online_new_uniform.pkl\")\n",
    "\n",
    "#chosen_dicts = {\n",
    "    #\"algorithm\": [\"bayes distance\", \"bayes angle\"],\n",
    "    #\"discretization\": \"medium\"\n",
    "#}\n",
    "#plot_df = filter_by_dict(plot_df, chosen_dict)\n",
    "#chosen_dict = {}\n",
    "\n",
    "for (discretization, algorithm), df_dis in plot_df.groupby([\"discretization\", \"algorithm\"], sort=False):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(4*figsize, 2*figsize)\n",
    "    for method, df in df_dis.groupby(\"method\"):\n",
    "        color_name  = method.split(' ')[0]\n",
    "        if color_name in [\"fixed\", \"random\"]:\n",
    "            continue \n",
    "        if \"particle\" in method:\n",
    "            ls_name = \"particle\"\n",
    "        else:\n",
    "            ls_name = method.split(color_name)[1].strip()\n",
    "        \n",
    "        cdf = sorted(np.abs(df.error))\n",
    "        if color_name == \"calibrated\":\n",
    "            label = ls_name\n",
    "        else:\n",
    "            label = None\n",
    "        ax.plot(df.distance, df.error, color=color[color_name], linestyle=ls[ls_name], label=label)\n",
    "        \n",
    "    add_double_legend(ax, exclude=[\"fixed\", \"random\"])\n",
    "    \n",
    "    ax.grid(True)\n",
    "    ax.set_title(f\"{discretization} discretization, {algorithm}\")\n",
    "    ax.set_xlabel(\"real distance [cm]\")\n",
    "    ax.set_ylabel(f\"error [{units[algorithm]}]\")\n",
    "    \n",
    "    save_fig(fig, f\"plots/experiments/{exp_name}_{algorithm.replace(' ', '_')}_{discretization.replace(' ', '_')}_errors.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use the different online schemes and compare\n",
    "df_mat = pd.read_pickle(\"results/stepper_results_matrices.pkl\")\n",
    "df_mat = df_mat[(df_mat[\"relative std\"] == 1.0) \n",
    "              & (df_mat[\"mask bad\"]==\"fixed\")]\n",
    "\n",
    "for (calibration, n_window), df_calib in df_mat.groupby([\"calibration name\", \"n window\"]):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    for i, row in df_calib.iterrows():\n",
    "        \n",
    "        label = f'{round(row[\"calibration param\"], 1)}'\n",
    "        matrix = row[\"matrix distances\"][0]\n",
    "        distances_cm = row[\"distances_cm\"]\n",
    "        \n",
    "        real_distances = np.arange(matrix.shape[1]) + 7\n",
    "        distance_estimates = distances_cm[np.argmax(matrix, axis=0)]\n",
    "        axs[0].plot(np.arange(matrix.shape[1]), real_distances - distance_estimates, label=label)\n",
    "        \n",
    "        cdf = np.sort(np.abs(real_distances - distance_estimates))\n",
    "        axs[1].plot(cdf, np.linspace(0, 1, len(cdf)), label=label)\n",
    "    axs[0].grid(True)\n",
    "    axs[1].grid(True)\n",
    "    axs[1].set_xlim(0, 50)\n",
    "    axs[0].set_ylim(-50, 50)\n",
    "    axs[1].legend(loc=\"upper left\", bbox_to_anchor=[1.0, 1.0])\n",
    "    #plt.plot(np.arange(matrix.shape[1]), real_distances, color='k')\n",
    "    plt.ylabel(\"error [cm]\")\n",
    "    #plt.suptitle(f\"$N_w$={n_window}, calibration {calibration}\", y=0.95)\n",
    "    plt.suptitle(f\"calibration: {calibration}\", y=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO(FD): fix below if necessary. \n",
    "\n",
    "from utils.inference import eps_normalize\n",
    "from utils.simulation import get_freq_slice_theory\n",
    "from utils.plotting_tools import all_linestyles\n",
    "\n",
    "mic_idx = 1\n",
    "eps = 1e-5\n",
    "\n",
    "plot_combis = [\n",
    "    #{\"distance\": 15, \"algorithm\": \"cost\"},\n",
    "    {\"distance\": 15, \"algorithm\": \"bayes\"},\n",
    "    #{\"distance\": 17, \"algorithm\": \"bayes\"},\n",
    "    #{\"distance\": 28, \"algorithm\": \"bayes\"},\n",
    "]\n",
    "print(\"using uniform prior:\", use_uniform_prior)\n",
    "\n",
    "for plot_combi in plot_combis:\n",
    "    distance = plot_combi.get(\"distance\")\n",
    "    algorithm = plot_combi.get(\"algorithm\")\n",
    "\n",
    "    shape = (1, n_mics)\n",
    "    # plot the slices\n",
    "    fig_slice, axs_slice = plt.subplots(*shape, sharex=True, sharey=True)\n",
    "    fig_slice.set_size_inches(3 * shape[1], 2 * shape[0])\n",
    "    # plot the results \n",
    "    fig_algo, axs_algo = plt.subplots(*shape, sharex=True, sharey=True)\n",
    "    fig_algo.set_size_inches(3 * shape[1], 2 * shape[0])\n",
    "\n",
    "    distance_estimators = {k: DistanceEstimator() for k in method_dict.keys()}\n",
    "    for i_method, (method, normalize_method) in enumerate(method_dict.items()):\n",
    "        if method == \"theoretical\":\n",
    "            slice_exp = get_freq_slice_theory(df_freq,\n",
    "                                              distance,\n",
    "                                              azimuth_deg=azimuth_deg, \n",
    "                                              chosen_mics=chosen_mics)\n",
    "            slice_exp = slice_exp.T # now it's 4x32\n",
    "            freqs = df_freq\n",
    "        else:\n",
    "            slice_exp, freqs, stds = data_collector.get_frequency_slice_fixed(\n",
    "                df_freq,\n",
    "                distance,\n",
    "                mics=chosen_mics)\n",
    "            slice_exp = np.sqrt(slice_exp)\n",
    "            \n",
    "            \n",
    "        inf_machine.add_data(slice_exp, df_freq, mics=chosen_mics)\n",
    "        inf_machine.filter_out_freqs()\n",
    "        inf_machine.add_calibration_function(normalize_method)\n",
    "\n",
    "        for i_mic, mic_idx in enumerate(chosen_mics):\n",
    "            distances_bayes, proba_bayes_norm, diff_bayes = inf_machine.do_inference(\n",
    "                algorithm=\"bayes\", \n",
    "                mic_idx=i_mic,\n",
    "                #normalize=False\n",
    "            )\n",
    "            \n",
    "            inf_machine.plot(i_mic=i_mic, ax=axs_slice[i_mic], label=method, standardize=True,\n",
    "                             ls=all_linestyles[i_method])#marker='o')\n",
    "\n",
    "            distance_estimators[method].add_distribution(\n",
    "                diff_bayes * 1e-2, proba_bayes_norm, mic_idx\n",
    "            )\n",
    "            d = get_estimate(distances_bayes, proba_bayes_norm)\n",
    "\n",
    "            axs_algo[i_mic].semilogy(\n",
    "                distances_bayes,\n",
    "                eps_normalize(proba_bayes_norm, eps=eps),\n",
    "                color=f\"C{i_method}\",\n",
    "                ls=all_linestyles[i_method],\n",
    "                label=method,\n",
    "            )\n",
    "            axs_algo[i_mic].axvline(x=d, color=f\"C{i_method}\", ls=\":\") \n",
    "            axs_algo[i_mic].set_title(f\"mic{mic_idx}\")\n",
    "            axs_slice[i_mic].set_title(f\"mic{mic_idx}\")\n",
    "        \n",
    "    label_real = f\"real: {distance:.0f}cm\"\n",
    "    #axs_slice[-1].legend(title=label_real, bbox_to_anchor=[1.0, 1.0], loc='upper left')\n",
    "    #axs_algo[-1].legend(title=label_real, bbox_to_anchor=[1.0, 1.0], loc='upper left')\n",
    "    axs_slice[0].set_ylabel('amplitude') \n",
    "    axs_algo[0].set_ylabel('probability') \n",
    "    [ax.set_xlabel('frequency [Hz]') for ax in axs_slice]\n",
    "    [ax.set_xlabel('distance [cm]') for ax in axs_algo]\n",
    "\n",
    "    fname_here = f\"{plot_dir}/{fname}_{distance}cm_raw_slices.png\"\n",
    "    save_fig(fig_slice, fname_here)\n",
    "    fname_here = f\"{plot_dir}/{fname}_{distance}cm_raw_results.png\"\n",
    "    save_fig(fig_algo, fname_here)\n",
    "\n",
    "    fig_combi, axs_combi = plt.subplots(1, 2)\n",
    "    fig_combi.set_size_inches(6, 3)\n",
    "    \n",
    "    print(\"getting distance distribution...\")\n",
    "    ax_combi = axs_combi[0]\n",
    "    for i_method, (method, distance_estimator) in enumerate(\n",
    "        distance_estimators.items()\n",
    "    ):\n",
    "        azimuth_deg_here = None if use_uniform_prior else azimuth_deg_here\n",
    "        distances_m, proba = distance_estimator.get_distance_distribution(\n",
    "            azimuth_deg=azimuth_deg_here, distances_m=distances_grid_m, verbose=False,\n",
    "            method=\"sum\"\n",
    "        )\n",
    "        print(distances_m, proba)\n",
    "        ax_combi.plot(\n",
    "            distances_m*1e2,\n",
    "            eps_normalize(proba, eps=eps),\n",
    "            color=f\"C{i_method}\",\n",
    "            ls=all_linestyles[i_method],\n",
    "            label=method,\n",
    "        )\n",
    "    ax_combi.axvline(x=distance, color=\"black\", ls=\":\")\n",
    "    ax_combi.set_xlabel(\"distance [cm]\")\n",
    "    ax_combi.set_ylabel(\"probability\")\n",
    "    #ax_combi.set_title(\"total probability\")\n",
    "    ax_combi.set_yscale(\"log\")\n",
    "\n",
    "    print(\"getting angle distribution...\")\n",
    "    ax_combi = axs_combi[1]\n",
    "    for i_method, (method, distance_estimator) in enumerate(\n",
    "        distance_estimators.items()\n",
    "    ):\n",
    "\n",
    "        # doesn't work with uniform prior!!\n",
    "        distance_m_here = d * 1e-2\n",
    "        angles, proba = distance_estimator.get_angle_distribution(\n",
    "            distance_estimate_m=distance_m_here,\n",
    "            azimuths_deg=np.arange(360),\n",
    "            method=\"sum\",\n",
    "        )\n",
    "        ax_combi.plot(\n",
    "            angles,\n",
    "            eps_normalize(proba, eps=eps),\n",
    "            color=f\"C{i_method}\",\n",
    "            ls=all_linestyles[i_method],\n",
    "            label=method,\n",
    "        )\n",
    "    ax_combi.axvline(\n",
    "        x=azimuth_deg, color=\"black\", ls=\":\", label=f\"real: {distance:.0f}cm, {azimuth_deg:.0f}$^\\\\circ$\"\n",
    "    )\n",
    "    ax_combi.legend(loc=\"upper left\", bbox_to_anchor=[1.0, 1.0])\n",
    "    ax_combi.set_xlabel(\"angle [$^\\\\circ$]\")\n",
    "    #ax_combi.set_title(\"total probability\")\n",
    "    ax_combi.set_yscale(\"log\")\n",
    "    plt.subplots_adjust(wspace=0.25)\n",
    "\n",
    "    fname_here = f\"{plot_dir}/{fname}_{distance}cm_raw_total.png\"\n",
    "    save_fig(fig_combi, fname_here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Distance slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_slices(slice_exp, slice_the, dist):\n",
    "    fig_f, axs_f = plt.subplots(1, slice_exp.shape[0], squeeze=False, sharey=True)\n",
    "    fig_f.set_size_inches(2*FIGSIZE, FIGSIZE)\n",
    "    fig_f.suptitle(f\"Standardized distance slices, at frequency {f:.0f}Hz\")\n",
    "    for m in range(slice_exp.shape[0]):\n",
    "        slice_exp_norm = deepcopy(slice_exp[m])\n",
    "        slice_the_norm = deepcopy(slice_the[m])\n",
    "        slice_exp_norm -= np.mean(slice_exp_norm)\n",
    "        slice_the_norm -= np.mean(slice_the_norm)\n",
    "        slice_exp_norm /= np.std(slice_exp_norm)\n",
    "        slice_the_norm /= np.std(slice_the_norm)\n",
    "        \n",
    "        axs_f[0, m].plot(dist, slice_the_norm, label=\"theoretical\")\n",
    "        axs_f[0, m].plot(dist, slice_exp_norm, label=\"measured\")\n",
    "        axs_f[0, m].set_title(f\"mic{m}\")\n",
    "        axs_f[0, m].legend(loc=\"upper right\")\n",
    "        axs_f[0, m].set_xlabel(\"distance [cm]\")\n",
    "        axs_f[0, m].grid()\n",
    "    axs_f[0, 0].set_ylabel(\"amplitude\")\n",
    "    return fig_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pandas_utils import fill_nans\n",
    "from utils.simulation import get_dist_slice_theory\n",
    "from copy import deepcopy\n",
    "\n",
    "for i, f in enumerate(df_freq):\n",
    "        \n",
    "    slice_exp = df_matrix[:, i, :]\n",
    "    if np.any(np.isnan(slice_exp)):\n",
    "        slice_exp = fill_nans(slice_exp, df_dist)\n",
    "    slice_the = get_dist_slice_theory(f, df_dist, azimuth_deg=azimuth_deg).T\n",
    "    \n",
    "    fig_d = plot_slices(\n",
    "        slice_exp=slice_exp,\n",
    "        slice_the=slice_the,\n",
    "        dist=df_dist,\n",
    "    )\n",
    "    fname = f\"{exp_name}_{motors}\"\n",
    "    if f in [2562, 3375, 4500]: # manually picked these\n",
    "        save_fig(fig_d, f'{plot_dir}/{fname}_distance_slice_{f:.0f}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.simulation import factor_distance_to_delta\n",
    "\n",
    "d1 = df_dist[-1] # starting distance of distance slice. \n",
    "rel_movement_cm = df_dist[1]-df_dist[0]\n",
    "factors_max = {mic:factor_distance_to_delta(d1, \n",
    "                                        rel_movement_cm, \n",
    "                                        mic, azimuth_deg=azimuth_deg) \n",
    "           for mic in range(4)}\n",
    "print('factors_max:\\n', factors_max)\n",
    "dN = df_dist[0] # ending distance of distance slice. \n",
    "factors_min = {mic:factor_distance_to_delta(dN, \n",
    "                                        rel_movement_cm, \n",
    "                                        mic, azimuth_deg=azimuth_deg) \n",
    "               for mic in range(4)}\n",
    "print('factors_min:\\n', factors_min)\n",
    "print('average', np.mean(list(factors_max.values())+list(factors_min.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.inference import get_approach_angle_fft, get_approach_angle_cost\n",
    "from utils.plotting_tools import plot_performance, save_fig, titles, linestyles\n",
    "from utils.estimators import get_estimate, AngleEstimator\n",
    "from utils.inference import BAD_FREQ_RANGES, PLATFORM\n",
    "\n",
    "plot_slices = True\n",
    "gamma_min = 10\n",
    "\n",
    "start_distances_grid = [max(df_dist)+10] #[max(df_dist) + i for i in [0, 10, 20]]\n",
    "gammas_grid = np.arange(gamma_min, 91, step=1)\n",
    "\n",
    "factor = 2.0 # correction factor, 2 means we assume colocated\n",
    "gt_gamma = 90 # in degrees\n",
    "\n",
    "fig, ax_total = plt.subplots()\n",
    "ax_total.set_xlabel('approach angle $\\\\gamma$')\n",
    "ax_total.set_ylabel('probability')\n",
    "ax_total.set_title('combined distribution across mics and frequencies')\n",
    "\n",
    "#for algo in [\"bayes\"]#[\"cost\", \"bayes\"]:\n",
    "#algo = \"cost\" #\"bayes\"\n",
    "algo = \"bayes\" #\"bayes\"\n",
    "    \n",
    "estimator_all = AngleEstimator()\n",
    "\n",
    "labels = [\"all mics\"] + [f\"mic{m}\" for m in range(df_matrix.shape[0])] \n",
    "err_dict = {l: [np.nan]*len(df_freq) for l in labels}\n",
    "\n",
    "print(df_freq)\n",
    "for i, f in enumerate(df_freq):\n",
    "    if np.any([r[0] <= f <= r[1] for r in BAD_FREQ_RANGES]):\n",
    "        print('skipping', f)\n",
    "        continue\n",
    "    estimator = AngleEstimator()\n",
    "\n",
    "    d_slices = fill_nans(df_matrix[:, i, :], df_dist)\n",
    "\n",
    "    if plot_slices:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(7, 5)\n",
    "    for mic_idx in range(df_matrix.shape[0]):\n",
    "        d_slice = d_slices[mic_idx] ** 2\n",
    "\n",
    "        if algo == \"bayes\":\n",
    "            gammas, prob = get_approach_angle_fft(d_slice, f, df_dist,\n",
    "                                                         n_max=1000, bayes=True, \n",
    "                                                         reduced=False, \n",
    "                                                         factor=factor)\n",
    "        elif algo == \"cost\":\n",
    "            prob = get_approach_angle_cost(\n",
    "                d_slice,\n",
    "                f,\n",
    "                df_dist,\n",
    "                start_distances_grid,\n",
    "                gammas_grid,\n",
    "                mic_idx=mic_idx,\n",
    "                azimuth_deg=azimuth_deg\n",
    "            )  # is of shape n_start_distances x n_gammas_grid\n",
    "            gammas = gammas_grid\n",
    "            \n",
    "        prob = prob[gammas > gamma_min]\n",
    "        gammas = gammas[gammas > gamma_min]\n",
    "        \n",
    "        estimator_all.add_distribution(gammas, prob, mic_idx, f)\n",
    "        estimator.add_distribution(gammas, prob, mic_idx, f)\n",
    "\n",
    "        gamma = get_estimate(gammas, prob)\n",
    "        \n",
    "        err_dict[f\"mic{mic_idx}\"][i] = gamma - gt_gamma\n",
    "\n",
    "        if plot_slices:\n",
    "            ax.plot(gammas, prob)\n",
    "            ax.axvline(gamma, label=f'mic{mic_idx}, {algo}', color=f'C{mic_idx}', ls=linestyles[algo])\n",
    "\n",
    "    if plot_slices:\n",
    "        ax.set_title(f'frequency {f:.0f}Hz')\n",
    "        ax.set_xlabel('angle of approach $\\\\gamma$ [$^\\\\circ$]')\n",
    "        ax.set_ylabel('probability')\n",
    "        ax.legend()\n",
    "\n",
    "    #angles, prob = estimator.get_angle_distribution(mics_left_right=[[1, 2], [0, 3]])\n",
    "    angles, prob = estimator.get_angle_distribution(mics_left_right=None)\n",
    "    \n",
    "    gamma = get_estimate(angles, prob)\n",
    "    err_dict[\"all mics\"][i] = gamma - gt_gamma\n",
    "\n",
    "#angles, prob = estimator_all.get_angle_distribution(mics_left_right=[[1, 2], [0, 3]])\n",
    "angles, prob = estimator_all.get_angle_distribution(mics_left_right=None)\n",
    "ax_total.plot(angles, prob, label=algo)\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "fig, axs = plot_performance(err_dict, xs=df_freq, \n",
    "           xlabel=\"frequency [Hz]\", ylabel=\"error [$^\\\\circ$]\")\n",
    "max_err = 90 #45\n",
    "axs[1].set_xlim(0,  max_err)\n",
    "axs[0].set_ylim(-max_err, max_err)\n",
    "save_fig(fig, f'{plot_dir}/{fname}_{algo}_distance_slice_performance.pdf')\n",
    "\n",
    "ax_total.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calibration analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"2021_07_08_stepper_fast\"\n",
    "mic_type = \"audio_deck\"\n",
    "motors = \"all45000\"\n",
    "snr = 5\n",
    "plot_tuples = [(0, 3125)]\n",
    "\n",
    "data_collector = DataCollector()\n",
    "backup_exists = data_collector.fill_from_backup(exp_name, mic_type, motors, snr=snr)\n",
    "if not backup_exists: \n",
    "    print('generate data using script generate_df_results.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.calibration import fit_distance_slice\n",
    "from utils.simulation import get_amplitude_function\n",
    "\n",
    "fname = f'{exp_name}_{motors}'\n",
    "all_distances = data_collector.df.distance.unique()\n",
    "\n",
    "mic_idx = 0\n",
    "max_distance = 35\n",
    "\n",
    "for i, (frequency, df_freq_here) in enumerate(data_collector.df.groupby('frequency')):\n",
    "    distances = df_freq_here.distance.unique()\n",
    "    if len(distances) < len(all_distances): # only plot distances with \"full coverage\"\n",
    "        continue\n",
    "    \n",
    "    df_here = df_freq_here.loc[df_freq_here.mic==mic_idx]\n",
    "        \n",
    "    coeffs_median, distances_median, fit_median, cost_median = data_collector.fit_to_median(frequency, [mic_idx])\n",
    "    alpha, offset, gain = coeffs_median\n",
    "        \n",
    "    # find the sigma for this frequency (per distance)\n",
    "    std_series = df_here.groupby('distance').magnitude.std() # per distance\n",
    "    std_average = np.nanmean(std_series.values)\n",
    "    amps = get_amplitude_function(std_series.index, \n",
    "                                  gain, \n",
    "                                  alpha, mic_idx)\n",
    "    valid_distances = std_series.index[amps >= std_average]\n",
    "    limit_distance = valid_distances[-1] if len(valid_distances) else 0\n",
    "\n",
    "    #print(f'raw: mic {mic}, frequency {frequency}')\n",
    "    #print(f'median: alpha={alpha:.2f}, gain={gain:.2f}, offset={offset:.0f}, cost={cost_median}')\n",
    "\n",
    "\n",
    "    label = f\"{frequency:.0f}Hz\"\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    ax_fit, ax_freq = axs\n",
    "    \n",
    "    slices_median, distances_median_all, mics, stds = data_collector.get_distance_slice(frequency)\n",
    "    for d, series in df_here.groupby('distance').magnitude: \n",
    "        ax_fit.scatter([d]*len(series), series.values, color='C0', s=4)#, s=5.0)\n",
    "    ax_fit.scatter([], [], color='C0', label='raw', s=4)#, s=5.0)\n",
    "\n",
    "    ax_fit.plot(distances_median_all, slices_median[mic_idx, :], color='C0', label='distance slice')\n",
    "    ax_fit.plot(distances_median, fit_median, color='C1', label='model fit')\n",
    "\n",
    "    ax_fit.set_title('fit for ' + label)\n",
    "    ax_fit.set_ylabel('amplitude [-]')\n",
    "    ax_fit.set_xlabel('distance [cm]')\n",
    "    ax_fit.legend(loc='lower left')\n",
    "    ax_fit.set_xlim(min(distances_median), max_distance)\n",
    "\n",
    "    ax_freq.semilogy(std_series.index, amps, ls=':', color=f'C0', label=f'magnitude')\n",
    "    ax_freq.axhline(std_average, label=f'average std', color=f'C0')\n",
    "    ax_freq.scatter(std_series.index, std_series.values, label=f'std', color=f'C0', s=4)\n",
    "    ax_freq.set_xlim(min(distances_median), max_distance)\n",
    "\n",
    "    ax_freq.set_title('magnitude vs. noise for ' + label)\n",
    "    ax_freq.legend(loc='lower left')\n",
    "    ax_freq.set_xlabel('distance [cm]')\n",
    "    #ax_freq.set_ylabel('magnitude vs. std [-]')\n",
    "\n",
    "    if (mic_idx, frequency) not in plot_tuples:\n",
    "        continue\n",
    "        \n",
    "    fname_here = f'{plot_dir}/{fname}_fitting_{frequency:.0f}_{mic_idx}.png'\n",
    "    save_fig(fig, fname_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.883px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
