{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance: Flying Experiments\n",
    "\n",
    "Detect the distance to the wall while flying and playing sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"figure.max_open_warning\"] = False\n",
    "rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "rcParams[\"font.size\"] = 12\n",
    "\n",
    "#import rclpy\n",
    "#rclpy.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calib_function(calib=\"stepper\"):\n",
    "    from utils.calibration import get_calibration_function_median\n",
    "    from utils.calibration import get_calibration_function_moving\n",
    "    if calib == \"flying\":\n",
    "        print(\"using flying\")\n",
    "        calib_function_median, freqs = get_calibration_function_moving(\n",
    "            \"2021_10_12_flying\", motors=\"linear_buzzer_cont\", fit_one_gain=False,\n",
    "            #\"2021_07_14_flying\", motors=\"linear_buzzer_cont\", fit_one_gain=False,\n",
    "            appendix_list=[\"_new3\", \"_new4\", \"_new6\"], \n",
    "        )\n",
    "    elif calib == \"stepper\":\n",
    "        print(\"using stepper dataset\")\n",
    "        calib_function_median, freqs = get_calibration_function_median(\n",
    "            #\"2021_07_08_stepper_fast\",\n",
    "            \"2021_10_07_stepper_new_f\",\n",
    "            motors=\"all45000\",\n",
    "            mic_type=\"audio_deck\",\n",
    "            snr=5,\n",
    "            fit_one_gain=False,\n",
    "        )\n",
    "    return calib_function_median\n",
    "\n",
    "def get_estimates_here(results_matrix, xvalues):\n",
    "    valid = np.any(results_matrix > 0, axis=0)\n",
    "    estimates = xvalues[np.argmax(results_matrix, axis=0)].astype(float)\n",
    "    estimates[~valid] = np.nan\n",
    "    return estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_positions(ax, positions_cm, walls):\n",
    "    from matplotlib import cm\n",
    "    \n",
    "    cmap = cm.get_cmap('inferno') \n",
    "    n_labels = 3\n",
    "    label = None\n",
    "    step = len(positions_cm) // n_labels\n",
    "    for i, p in enumerate(positions_cm):\n",
    "        if i % step == 0 or (i == len(positions_cm) - 1):\n",
    "            label = f'position {i}'\n",
    "        ax.scatter(*p[:2], color=cmap(i / len(positions_cm)), label=label)\n",
    "        label=None\n",
    "    ax.plot(positions_cm[:, 0], positions_cm[:, 1], color='k', ls=':')\n",
    "    ax.axis('equal')\n",
    "    ax.set_xlabel('x [cm]')\n",
    "    ax.set_ylabel('y [cm]')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend([handles[0], handles[-1]], [\"start\", \"end\"], loc='upper right')\n",
    "    \n",
    "    for wall_distance, wall_angle in walls:\n",
    "        print(wall_distance, wall_angle)\n",
    "        ax.arrow(0, 0, wall_distance * np.cos(wall_angle / 180 * np.pi), \n",
    "                 wall_distance * np.sin(wall_angle / 180 * np.pi), color='k', label='_wall', \n",
    "                 width=1)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single wall approach experiments\n",
    "\n",
    "### Qualitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crazyflie_description_py.experiments import WALL_ANGLE_DEG\n",
    "from crazyflie_description_py.parameters import FLYING_HEIGHT_CM\n",
    "from generate_classifier_results import get_groundtruth_distances, WALLS_DICT\n",
    "\n",
    "from utils.plotting_tools import FIGSIZE, save_fig\n",
    "\n",
    "exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_new3\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_new4\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_new6\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_new7\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_new8\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_new10\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_new12\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_1\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_2\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_3\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_4\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_5\"\n",
    "#exp_name=\"2021_10_12_flying\"; motors=\"linear_buzzer_cont\"; appendix=\"_6\"\n",
    "\n",
    "results_df = pd.read_pickle(f\"../datasets/{exp_name}/all_data.pkl\")\n",
    "row = results_df.loc[\n",
    "    (results_df.appendix == appendix) & (results_df.motors == motors), :\n",
    "].iloc[0]\n",
    "\n",
    "bad_freqs = []\n",
    "n_calib = 5\n",
    "figsize = 3\n",
    "\n",
    "flying = row.positions[:, 2] > FLYING_HEIGHT_CM * 1e-2\n",
    "positions_cm = row.positions[flying, :2] * 1e2\n",
    "yaws_deg = row.positions[flying, 3]\n",
    "freqs = row.frequencies_matrix[0, :]\n",
    "magnitudes = np.abs(row.stft[flying][:, :, freqs>0])\n",
    "freqs = freqs[freqs > 0]\n",
    "n_points = magnitudes.shape[0]\n",
    "times = row.seconds[flying]\n",
    "distances = get_groundtruth_distances(exp_name, appendix, walls=[[100, 90]], flying=True)\n",
    "\n",
    "from utils.constants import SPEED_OF_SOUND\n",
    "print(freqs[1]-freqs[0])\n",
    "print(SPEED_OF_SOUND)\n",
    "print(SPEED_OF_SOUND / (4 * (freqs[1]-freqs[0])))\n",
    "\n",
    "# calibrate and plot calibration\n",
    "calib_on_the_fly = np.median(magnitudes[:n_calib, :, :], axis=0)\n",
    "std_values = np.std(magnitudes[:n_calib, :, :], axis=0)\n",
    "plot_name_calib = f\"plots/experiments/{exp_name}{appendix}_on_the_fly.pdf\"\n",
    "fig_calib, axs_calib = plt.subplots(1, 5, sharey=True)\n",
    "fig_calib.set_size_inches(10, 3)\n",
    "axs_calib[0].set_ylabel(f\"amplitude [-]\")\n",
    "for m in range(4):\n",
    "    axs_calib[m].plot(freqs, magnitudes[:n_calib, m, :].T, color=f\"C{m}\", marker='o')\n",
    "    axs_calib[m].set_title(f\"mic{m}\")\n",
    "    axs_calib[4].errorbar(freqs, calib_on_the_fly[m], std_values[m], label=f\"mic{m}\")\n",
    "    axs_calib[m].set_xlabel(f\"frequency [Hz]\")\n",
    "axs_calib[4].set_xlabel(f\"frequency [Hz]\")\n",
    "axs_calib[4].set_title(f\"all mics\")\n",
    "axs_calib[0].set_ylim(2, 12)\n",
    "[axs_calib[0].axvline(f, color='black') for fs in bad_freqs for f in fs]\n",
    "\n",
    "# plot positions\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(figsize, figsize)\n",
    "plot_positions(ax, positions_cm, WALLS_DICT[exp_name])\n",
    "plot_name = f\"plots/experiments/{exp_name}{appendix}_positions.pdf\"\n",
    "save_fig(fig, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "\n",
    "from utils.plotting_tools import pcolorfast_custom, plot_performance\n",
    "from utils.inference import Inference\n",
    "from utils.estimators import DistanceEstimator\n",
    "from utils.moving_estimators import MovingEstimator\n",
    "from utils.particle_estimators import ParticleEstimator\n",
    "\n",
    "# for live analysis\n",
    "from crazyflie_demo.wall_detection import DISTANCES_CM, ANGLES_DEG\n",
    "distances_cm = DISTANCES_CM\n",
    "angles_deg = ANGLES_DEG\n",
    "\n",
    "# for offline analysis\n",
    "#distances_cm = np.arange(100, step=1)\n",
    "#angles_deg = np.arange(360, step=2)\n",
    "\n",
    "#particle_method = \"gaussian\"\n",
    "particle_method = \"histogram\"\n",
    "n_calib = 5\n",
    "n_window = 3\n",
    "simplify_angles = False\n",
    "\n",
    "calib_method_list = [\"on_the_fly\"]#, [\"stepper\"]\n",
    "mics_list = [[0, 1, 2, 3]] #, [[1, 3], [0, 2], [0, 1, 3], [0, 1, 2, 3]]\n",
    "algorithm_list = [\"bayes\"]#, \"cost\"]\n",
    "no_deco = False\n",
    "errors_df = pd.DataFrame(\n",
    "    columns=[\"algorithm\", \"mics\", \"calib_method\", \"estimates\", \"distances\", \"appendix\", \"time\"]\n",
    ")\n",
    "\n",
    "inf_machine = Inference()\n",
    "dists_cm = DistanceEstimator.DISTANCES_CM \n",
    "azimuths_deg = DistanceEstimator.ANGLES_DEG.astype(float)\n",
    "inf_machine.add_geometry([dists_cm[0], dists_cm[-1]], WALL_ANGLE_DEG)\n",
    "\n",
    "for calib_method, mics, algorithm in itertools.product(calib_method_list, mics_list, algorithm_list):\n",
    "    if calib_method == \"on_the_fly\":\n",
    "        calib_values = calib_on_the_fly\n",
    "    else:\n",
    "        calib_function = get_calib_function(calib_method)\n",
    "        calib_values = calib_function(freqs)\n",
    "    magnitudes_calib = magnitudes / calib_values\n",
    "\n",
    "    mics_str = str(mics).replace(\" \", \"\")\n",
    "    plot_name = f\"plots/experiments/{exp_name}{appendix}_{algorithm}_{calib_method}_{mics_str}\"\n",
    "\n",
    "    results_matrix = np.full((len(dists_cm), n_points), np.nan)\n",
    "    results_matrix_angles = np.full((len(azimuths_deg), n_points), np.nan)\n",
    "\n",
    "    moving_estimator = MovingEstimator(n_window=n_window, distances_cm=distances_cm, angles_deg=angles_deg)\n",
    "    results_matrix_angles_moving = np.full((len(moving_estimator.angles_deg), n_points), np.nan)\n",
    "    results_matrix_moving = np.full((len(moving_estimator.distances_cm), n_points), np.nan)\n",
    "    \n",
    "    particle_estimator = ParticleEstimator(n_particles=100, global_=False)\n",
    "    results_matrix_angles_part = np.full((len(particle_estimator.ANGLES_DEG), n_points), np.nan)\n",
    "    results_matrix_part = np.full((len(particle_estimator.distances_cm), n_points), np.nan)\n",
    "\n",
    "    time_moving = 0\n",
    "    time_single = 0\n",
    "    for i in range(n_points):\n",
    "\n",
    "        # important to reinitialize!\n",
    "        distance_estimator = DistanceEstimator()\n",
    "\n",
    "        inf_machine.add_data(magnitudes_calib[i], freqs)\n",
    "        inf_machine.filter_out_freqs(freq_ranges=bad_freqs)\n",
    "\n",
    "        t1 = time.time()\n",
    "        diff_moving = {}\n",
    "        for mic_idx in mics:\n",
    "            dist, prob_mic, diff = inf_machine.do_inference(algorithm, mic_idx)\n",
    "            distance_estimator.add_distribution(diff * 1e-2, prob_mic, mic_idx)\n",
    "            diff_moving[mic_idx] = (diff, prob_mic)\n",
    "\n",
    "        __, prob = distance_estimator.get_distance_distribution(verbose=False, angle_deg=WALL_ANGLE_DEG)\n",
    "        time_single += int(1000*(time.time() - t1))\n",
    "\n",
    "        t1 = time.time()\n",
    "        moving_estimator.add_distributions(\n",
    "            diff_moving, position_cm=positions_cm[i], rot_deg=yaws_deg[i]\n",
    "        )\n",
    "        particle_estimator.add_distributions(\n",
    "            diff_moving, position_cm=positions_cm[i], rot_deg=yaws_deg[i]\n",
    "        )\n",
    "        \n",
    "        __, prob_moving, __, prob_angle_moving = moving_estimator.get_distributions(simplify_angles=simplify_angles)\n",
    "        time_moving += int(1000*(time.time() - t1))\n",
    "        \n",
    "        __, prob_part, __, prob_angle_part = particle_estimator.get_distributions(simplify_angles=simplify_angles, method=particle_method)\n",
    "        \n",
    "        dist_est_cm = dists_cm[np.argmax(prob_moving)]\n",
    "        __, prob_angle = distance_estimator.get_angle_distribution(\n",
    "            distance_estimate_cm=dist_est_cm\n",
    "        )\n",
    "\n",
    "        results_matrix[:, i] = prob\n",
    "        results_matrix_angles[:, i] = prob_angle\n",
    "        results_matrix_moving[:, i] = prob_moving \n",
    "        results_matrix_angles_moving[:, i] = prob_angle_moving \n",
    "        results_matrix_part[:, i] = prob_part\n",
    "        results_matrix_angles_part[:, i] = prob_angle_part\n",
    "\n",
    "        continue\n",
    "        # DEBUGGING ONLY\n",
    "        dist, *_ = moving_estimator.get_joint_distribution(simplify_angles=simplify_angles)\n",
    "        fig, ax = plt.subplots()\n",
    "        pcolorfast_custom(ax, distances_cm, angles_deg, dist)\n",
    "        ax.axvline(distances[i], color='white', ls=':')\n",
    "        ax.axhline(90, color='white', ls=':')\n",
    "        ax.set_xlabel('distances [cm]')\n",
    "        ax.set_ylabel('angles [deg]')\n",
    "        ax.set_title(\"joint distribution\")\n",
    "\n",
    "    d_estimates = get_estimates_here(results_matrix, dists_cm)\n",
    "    errors_df.loc[len(errors_df), :] = {\n",
    "        \"algorithm\": algorithm,\n",
    "        \"mics\": mics_str,\n",
    "        \"calib_method\": calib_method,\n",
    "        \"estimates\": d_estimates,\n",
    "        \"distances\": distances,\n",
    "        \"appendix\": appendix,\n",
    "        \"time\": time_single / n_points \n",
    "    }\n",
    "\n",
    "    d_estimates_moving = get_estimates_here(results_matrix_moving, distances_cm)\n",
    "    errors_df.loc[len(errors_df), :] = {\n",
    "        \"algorithm\": algorithm + f\"_win{n_window}\",\n",
    "        \"mics\": mics_str,\n",
    "        \"calib_method\": calib_method,\n",
    "        \"estimates\": d_estimates_moving,\n",
    "        \"distances\": distances,\n",
    "        \"appendix\": appendix,\n",
    "        \"time\": time_moving / n_points \n",
    "    }\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(yvalues, results_matrix, gt_values, xvalues=None, no_deco=False, angles=False, log=True, n_calib=0):\n",
    "    from utils.plotting_tools import add_colorbar, pcolorfast_custom, FIGSIZE\n",
    "    \n",
    "    cmap = plt.get_cmap().copy() \n",
    "    cmap.set_bad('gray')\n",
    "    if xvalues is None:\n",
    "        xvalues = np.arange(results_matrix.shape[1])\n",
    "        xlabel = \"index [-]\"\n",
    "    else:\n",
    "        xlabel = \"time [s]\"\n",
    "        \n",
    "    estimates = get_estimates_here(results_matrix, yvalues)\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(2 * FIGSIZE, FIGSIZE)\n",
    "    \n",
    "    im = ax.pcolormesh(xvalues, yvalues, np.log10(results_matrix) if log else results_matrix, cmap=cmap)\n",
    "    \n",
    "    ax.plot(\n",
    "        xvalues,\n",
    "        gt_values,\n",
    "        color=\"black\",\n",
    "        label=\"ground truth\",\n",
    "        marker='x'\n",
    "    )\n",
    "    ax.set_ylim(min(yvalues), max(yvalues))\n",
    "    ax.plot(\n",
    "        xvalues,\n",
    "        estimates,\n",
    "        color=\"white\",\n",
    "        label=\"estimates\",\n",
    "        marker='o',\n",
    "        ls='-'\n",
    "    )\n",
    "    if no_deco:\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "    else:\n",
    "        add_colorbar(fig, ax, im, title=\"log-probability\" if log else \"probability\")\n",
    "        ax.set_ylabel(\"estimated angle [deg]\" if angles else \"estimated distance [cm]\")\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        leg = ax.legend(framealpha=0, loc='upper right')\n",
    "        for text in leg.get_texts():\n",
    "            plt.setp(text, color='w')\n",
    "        #ax.set_xticks(xticks, labels=xticklabels)\n",
    "        #ax.set_yticks(yticks, labels=yticks)\n",
    "        #n_xticks = 5\n",
    "        #step = len(xvalues) // n_xticks\n",
    "        #ax.set_xticks(np.round(xvalues[::step], 1))\n",
    "        #ax.set_xticklabels(np.round(xvalues[::step], 1))\n",
    "        \n",
    "    alpha = 0.7\n",
    "    if n_calib > 0:\n",
    "        from matplotlib.patches import Rectangle\n",
    "        width = xvalues[n_calib] - xvalues[0]\n",
    "        height= max(yvalues) - min(yvalues)\n",
    "        diff_x = xvalues[1] - xvalues[0]\n",
    "        xy = (min(xvalues) - diff_x/2, min(yvalues))\n",
    "        rect = Rectangle(xy, width, height, facecolor='white', alpha=alpha)\n",
    "        ax.add_patch(rect)\n",
    "        if not no_deco:\n",
    "            ax.text(xy[0] + width/2, xy[1]+height/2, \"used for\\ncalibration\", fontdict={'color':'black', 'ha':'center', 'va':'bottom'})\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_size = (6, 4)\n",
    "fig, ax = plot_matrix(dists_cm, results_matrix, distances, xvalues=times, no_deco=no_deco, \n",
    "                      n_calib=n_calib)\n",
    "fig.set_size_inches(*fig_size)\n",
    "plot_name = f\"plots/experiments/{exp_name}{appendix}_matrix.pdf\"\n",
    "save_fig(fig, plot_name)\n",
    "\n",
    "fig, ax = plot_matrix(distances_cm, results_matrix_moving, distances, xvalues=times,no_deco=no_deco,\n",
    "                      n_calib=n_calib)\n",
    "fig.set_size_inches(*fig_size)\n",
    "plot_name = f\"plots/experiments/{exp_name}{appendix}_matrix_hist.pdf\"\n",
    "save_fig(fig, plot_name)\n",
    "fig, ax = plot_matrix(particle_estimator.distances_cm, results_matrix_part, distances, xvalues=times, no_deco=no_deco,\n",
    "                      n_calib=n_calib)\n",
    "fig.set_size_inches(*fig_size)\n",
    "plot_name = f\"plots/experiments/{exp_name}{appendix}_matrix_part.pdf\"\n",
    "save_fig(fig, plot_name)\n",
    "\n",
    "gt_angles = np.full(len(distances), 90)\n",
    "fig, ax = plot_matrix(azimuths_deg, results_matrix_angles, gt_angles, xvalues=times,\n",
    "                      no_deco=no_deco, angles=True,  \n",
    "                      n_calib=n_calib)\n",
    "fig.set_size_inches(*fig_size)\n",
    "plot_name = f\"plots/experiments/{exp_name}{appendix}_matrix_angle.pdf\"\n",
    "save_fig(fig, plot_name)\n",
    "fig, ax = plot_matrix(np.array(angles_deg), results_matrix_angles_moving,  gt_angles, xvalues=times,\n",
    "                      no_deco=no_deco, log=False, angles=True,\n",
    "                      n_calib=n_calib)\n",
    "fig.set_size_inches(*fig_size)\n",
    "plot_name = f\"plots/experiments/{exp_name}{appendix}_matrix_hist_angle.pdf\"\n",
    "save_fig(fig, plot_name)\n",
    "fig, ax = plot_matrix(np.array(particle_estimator.ANGLES_DEG), results_matrix_angles_part,  gt_angles, xvalues=times,\n",
    "                      no_deco=no_deco, log=False, angles=True,\n",
    "                      n_calib=n_calib)\n",
    "fig.set_size_inches(*fig_size)\n",
    "plot_name = f\"plots/experiments/{exp_name}{appendix}_matrix_part_angle.pdf\"\n",
    "save_fig(fig, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor graph test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from factor_graph.plot import plot_projections\n",
    "import gtsam\n",
    "from audio_gtsam.wall_backend import WallBackend\n",
    "\n",
    "X = gtsam.symbol_shorthand.X\n",
    "P = gtsam.symbol_shorthand.P\n",
    "\n",
    "wall_backend = WallBackend(use_isam=True)\n",
    "yaw_start = np.pi \n",
    "\n",
    "use_groundtruth = False\n",
    "#use_groundtruth = True \n",
    "\n",
    "dist_matrix = results_matrix_moving\n",
    "angle_matrix = results_matrix_angles_moving\n",
    "n_estimates = 1\n",
    "#print(angle_matrix.shape, dist_matrix.shape)\n",
    "\n",
    "d_estimates = []\n",
    "d_gt = []\n",
    "\n",
    "for i, prob_dists in enumerate(dist_matrix.T):\n",
    "    t1 = time.time()\n",
    "    if i < n_calib:\n",
    "        continue\n",
    "    \n",
    "    position_cm = np.r_[positions_cm[i, :], 0.0]\n",
    "    yaw = yaws_deg[i] / 180 * np.pi\n",
    "    pose_factor = wall_backend.add_pose(r_world=position_cm * 1e-2,  yaw=yaw, verbose=False)\n",
    "    \n",
    "    distance_gt = distances[i]\n",
    "    \n",
    "    if use_groundtruth:\n",
    "        prob_dists = np.zeros(len(distances_cm))\n",
    "        idx = np.where(distances_cm == distance_gt)[0]\n",
    "        prob_dists[idx] = 1.0\n",
    "        \n",
    "        prob_angles = np.zeros(len(angles_deg))\n",
    "        prob_angles[angles_deg==90] = 1.0\n",
    "    else:\n",
    "        prob_angles = angle_matrix[:, i]\n",
    "        \n",
    "    wall_backend.add_planes_from_distributions(np.array(distances_cm), prob_dists, \n",
    "                                               np.array(angles_deg), prob_angles, \n",
    "                                               limit_distance=20,\n",
    "                                               n_estimates=n_estimates, \n",
    "                                               verbose=False)\n",
    "    \n",
    "    wall_backend.check_wall(verbose=False)\n",
    "    distance_estimate = wall_backend.get_distance_estimate()\n",
    "    d_estimates.append(distance_estimate * 1e2 if distance_estimate else np.nan)\n",
    "    d_gt.append(distance_gt if distance_estimate else np.nan)\n",
    "    #print(f\"time with isam={wall_backend.use_isam}: {(time.time() - t1)*1e3:.0f}ms\")\n",
    "\n",
    "errors_df.loc[len(errors_df), :] = {\n",
    "    \"algorithm\": algorithm + f\"_win{n_window}_factorgraph\",\n",
    "    \"mics\": mics_str,\n",
    "    \"calib_method\": calib_method,\n",
    "    \"estimates\": d_estimates,\n",
    "    \"distances\": d_gt,\n",
    "    \"appendix\": appendix,\n",
    "    \"time\": time_moving / n_points \n",
    "}\n",
    "   \n",
    "#plot_projections(wall_backend.all_initial_estimates, axis_length=0.2, ls=\":\", perspective=False, side=True)\n",
    "#plt.show()\n",
    "wall_backend.get_results()\n",
    "plot_projections(wall_backend.result, axis_length=0.1, perspective=False, side=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quantitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random(axs, dists):\n",
    "    np.random.seed(1)\n",
    "    errors_rand = []\n",
    "    for d in dists:\n",
    "        d_rand = np.random.choice(range(7, 100))\n",
    "        errors_rand.append(d_rand - d)\n",
    "    axs[0].plot(dists, errors_rand, color='k', label='random', ls='', marker='x', markersize=2)\n",
    "    axs[1].plot(sorted(np.abs(errors_rand)), np.linspace(0, 1, len(errors_rand)), color='k', ls='', label='random', marker='x', markersize=2)\n",
    "    axs[1].legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.plotting_tools import plot_performance, save_fig\n",
    "\n",
    "groupby = ['mics', 'algorithm']\n",
    "\n",
    "total_err_dict = {}\n",
    "for j, (labels, df) in enumerate(errors_df.groupby(groupby, sort=False)):\n",
    "    params = dict(zip(groupby, labels))\n",
    "        \n",
    "    err_dict = {}\n",
    "    dist_dict = {}\n",
    "    errors_all = []\n",
    "    distances_all = []\n",
    "    for i, row in df.iterrows():\n",
    "        errors = np.array(row.estimates) - np.array(row.distances)\n",
    "        key = ' '.join(row.drop(['distances', 'estimates', 'time'] + groupby).values)\n",
    "        err_dict[key] = errors\n",
    "        dist_dict[key] = row.distances\n",
    "        errors_all += list(errors[~np.isnan(errors)])\n",
    "        distances_all += list(np.array(row.distances)[~np.isnan(errors)])\n",
    "        \n",
    "    sort_idx = np.argsort(distances_all)\n",
    "    total_err_dict[j] = {\n",
    "        'errors': np.array(errors_all)[sort_idx],\n",
    "        'distances': np.array(distances_all)[sort_idx],\n",
    "        **params\n",
    "    }\n",
    "    \n",
    "    title = ''\n",
    "    for k,l in params.items():\n",
    "        title = f\"{title} {k}: {l}\"\n",
    "\n",
    "    fig, axs = plot_performance(err_dict, xs_dict=dist_dict, xlabel=\"distance [cm]\", ylabel=\"error [cm]\")\n",
    "    plot_random(axs, range(10, 80))\n",
    "    #fig, axs = plot_performance(err_dict, xlabel=\"distance [cm]\", ylabel=\"error [cm]\")\n",
    "    fig.suptitle(title)\n",
    "    axs[0].get_legend().set_visible(False)\n",
    "    axs[0].set_ylim(-60, 60)\n",
    "    axs[1].set_xlim(-2, 60)\n",
    "    #save_fig(fig, f'plots/experiments/{exp_name}_{chosen_mics}_{params[\"algorithm\"]}_cdf.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = 40\n",
    "err_dict = {}\n",
    "dist_dict = {}\n",
    "for total_dict in total_err_dict.values():\n",
    "    key = total_dict['algorithm']\n",
    "    errors = total_dict['errors']\n",
    "    dists = total_dict['distances']\n",
    "    err_dict[key] = errors[dists < max_dist]\n",
    "    dist_dict[key] = dists[dists < max_dist]\n",
    "    \n",
    "fig, axs = plot_performance(err_dict, xs_dict=dist_dict, xlabel=\"distance [cm]\", ylabel=\"error [cm]\", marker_flag=False)\n",
    "axs[0].get_legend().set_visible(False)\n",
    "plot_random(axs, range(10, max_dist))\n",
    "fig.suptitle(f'overall performance up to {max_dist}cm')\n",
    "save_fig(fig, f'plots/experiments/{exp_name}_cdf.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-wall approach experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"2021_11_23_demo\"\n",
    "results_df = pd.read_pickle(f\"../datasets/{exp_name}/all_data.pkl\")\n",
    "print(\"available appendices:\", results_df.appendix.values)\n",
    "\n",
    "# glass wall\n",
    "#appendix = \"hover1\" # works super well! \n",
    "#appendix = \"hover3\" # looks good! \n",
    "#appendix = \"hover5\" # looks quite good! \n",
    "#appendix = \"hover6\" # looks ok (from here on, velocity is increased)\n",
    "appendix = \"hover8\" # works well (glass wall), but only detects one wall\n",
    "\n",
    "# normal wall\n",
    "#appendix = \"hover9\" # works not great\n",
    "#appendix = \"hover10\" # works not great\n",
    "#appendix = \"hover11\" # works okay\n",
    "#appendix = \"hover12\" # works okay \n",
    "wall_y_cm = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"2022_01_25\"\n",
    "results_df = pd.read_pickle(f\"../datasets/{exp_name}/all_data.pkl\")\n",
    "print(\"available appendices:\", results_df.appendix.values)\n",
    "\n",
    "appendix = \"test24\"  # works ok\n",
    "#appendix = \"test25\"  # doesn't work\n",
    "\n",
    "wall_y_cm = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"2022_01_27_demo\"\n",
    "results_df = pd.read_pickle(f\"../datasets/{exp_name}/all_data.pkl\")\n",
    "print(\"available appendices:\", results_df.appendix.values)\n",
    "\n",
    "#appendix = \"test3\" # works ok\n",
    "appendix = \"test4\"  # works ok\n",
    "\n",
    "wall_y_cm = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting_tools import FIGSIZE, save_fig, add_colorbar\n",
    "from crazyflie_demo.wall_detection import FLYING_HEIGHT_CM\n",
    "from generate_classifier_results import WALLS_DICT\n",
    "\n",
    "row = results_df.loc[results_df.appendix == appendix,:].iloc[0]\n",
    "\n",
    "positions_cm = row.positions[:, :3] * 1e2\n",
    "flying = (positions_cm[:, 2] > FLYING_HEIGHT_CM) & (positions_cm[:, 2] < 100)\n",
    "print(\"not flying:\", np.where(~flying)[0])\n",
    "positions_cm = positions_cm[flying, :]\n",
    "print(positions_cm.shape)\n",
    "yaws_deg = row.positions[flying, 3]\n",
    "freqs = row.frequencies_matrix[0, :]\n",
    "magnitudes = np.abs(row.stft[flying][:, :, freqs>0])\n",
    "signals_f = row.stft[flying][:, :, freqs>0]\n",
    "freqs = freqs[freqs > 0]\n",
    "times = row.seconds[flying]\n",
    "\n",
    "n_timesteps = magnitudes.shape[0] \n",
    "\n",
    "# because wall is at 90 degrees.\n",
    "# TODO: make this statement more general\n",
    "distances_wall1 = wall_y_cm - positions_cm[:, 1]\n",
    "distances_wall2 = 200 - distances_wall1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(FIGSIZE, FIGSIZE)\n",
    "plot_positions(ax, positions_cm[:n_timesteps, :], walls=WALLS_DICT[exp_name])\n",
    "plot_name = f\"plots/experiments/{exp_name}{appendix}_positions.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_classifier_results import DIST_THRESH, STD_THRESH, TAIL_THRESH\n",
    "\n",
    "def plot_distance_matrix(ax, matrix, distances_cm=None):\n",
    "    from utils.plotting_tools import pcolorfast_custom\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    if distances_cm is None:\n",
    "        distances_cm = wall_detection.estimator.distances_cm\n",
    "\n",
    "    cmap = plt.get_cmap(\"gray\").copy()\n",
    "    alpha = 0.8\n",
    "    cmap.set_bad((1 - alpha, 1 - alpha, 1 - alpha))\n",
    "    log_matrix = deepcopy(matrix)\n",
    "    log_matrix[matrix > 0] = np.log10(matrix[matrix > 0])\n",
    "    log_matrix[matrix <= 0] = np.nan\n",
    "    pcolorfast_custom(\n",
    "        ax,\n",
    "        np.arange(log_matrix.shape[1]),\n",
    "        distances_cm,\n",
    "        log_matrix,\n",
    "        n_xticks=12,\n",
    "        n_yticks=4,\n",
    "        cmap=cmap,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    ax.set_ylabel(\"distance [cm]\")\n",
    "\n",
    "\n",
    "def plot_groundtruth(ax, color=\"white\", **kwargs):\n",
    "    ax.plot(distances_wall1, color=color, **kwargs)\n",
    "    ax.plot(distances_wall2, color=color, **kwargs)\n",
    "\n",
    "\n",
    "def plot_distance_estimates(ax, distance_estimates, label=None, **kwargs):\n",
    "    ax.plot(distance_estimates, label=label, **kwargs)\n",
    "    ax.set_ylabel(\"distance [cm]\")\n",
    "    ax.axhline(DIST_THRESH, color=\"k\", ls=\"--\")\n",
    "\n",
    "\n",
    "def plot_std_estimates(ax, std_estimates, label=None, **kwargs):\n",
    "    ax.plot(std_estimates, label=label, **kwargs)\n",
    "    ax.set_ylabel(\"standard deviation [cm]\")\n",
    "    ax.axhline(STD_THRESH, color=\"k\", ls=\"--\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.grid(True, which=\"both\")\n",
    "\n",
    "\n",
    "def plot_tail(ax, matrix, **kwargs):\n",
    "    tail = np.log10(np.mean(matrix[-3:, :], axis=0))\n",
    "    ax.plot(tail, **kwargs)\n",
    "    ax.set_ylabel(\"tail probability\")\n",
    "    ax.grid(True)\n",
    "    ax.axhline(TAIL_THRESH, color=\"k\", ls=\"--\")\n",
    "\n",
    "\n",
    "def plot_angles(ax, matrix, **kwargs):\n",
    "    matrix_norm = matrix / np.sum(matrix, axis=0)[None, :]\n",
    "    for i in range(matrix_norm.shape[0]):\n",
    "        angle = ANGLES_DEG[i]\n",
    "        ax.plot(matrix_norm[i, :], label=f\"wall at {angle}\", **kwargs)\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.grid(True)\n",
    "    ax.set_ylabel(\"angle probability\")\n",
    "    \n",
    "def plot_fg_estimates(ax, d_estimates, colors):\n",
    "    ax.scatter(np.arange(len(d_estimates)), d_estimates, color=colors)\n",
    "\n",
    "def plot_all():\n",
    "    fig, axs = plt.subplots(5, 1, sharex=True)\n",
    "    fig.set_size_inches(20, 30)\n",
    "\n",
    "    plot_distance_matrix(axs[0], results_matrix_moving)\n",
    "    ymin, ymax = axs[0].get_ylim()\n",
    "    plot_groundtruth(axs[0], color=\"white\")\n",
    "    plot_distance_estimates(axs[0], distance_estimates, label=\"chosen method\")\n",
    "    \n",
    "    plot_fg_estimates(axs[0], fg_dist_estimates, fg_colors)\n",
    "    axs[0].set_ylim(ymin, ymax)\n",
    "    \n",
    "    plot_groundtruth(axs[1], color=\"black\")\n",
    "    plot_distance_estimates(axs[1], distance_estimates, label=\"chosen method\")\n",
    "    plot_fg_estimates(axs[1], fg_dist_estimates, fg_colors)\n",
    "    axs[1].set_ylim(5, 100)\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plot_std_estimates(axs[2], std_estimates, label=\"chosen method\")\n",
    "\n",
    "    plot_tail(axs[3], results_matrix_moving)\n",
    "\n",
    "    if not WallDetection.SIMPLIFY_ANGLES:\n",
    "        plot_angles(axs[4], results_matrix_angles)\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from audio_gtsam.wall_backend import WallBackend\n",
    "from utils.moving_estimators import get_estimate\n",
    "from crazyflie_demo.wall_detection import WallDetection\n",
    "from crazyflie_description_py.experiments import WALL_ANGLE_DEG\n",
    "\n",
    "estimation_method = \"mean\"\n",
    "estimator = \"particle\"\n",
    "\n",
    "no_deco = False\n",
    "wall_detection = WallDetection(python_only=True, estimator=estimator)\n",
    "wall_backend = WallBackend(use_isam=True)\n",
    "\n",
    "fg_dist_estimates = []\n",
    "fg_colors = []\n",
    "fg_angle_estimates = []\n",
    "\n",
    "angles_forward = []\n",
    "\n",
    "distance_estimates = []\n",
    "std_estimates = []\n",
    "\n",
    "results_matrix_angles = np.full((len(wall_detection.estimator.angles_deg), n_timesteps), np.nan)\n",
    "results_matrix_moving = np.full((len(wall_detection.estimator.distances_cm), n_timesteps), np.nan)\n",
    "\n",
    "for i in range(n_timesteps):\n",
    "    res = wall_detection.listener_callback_offline(\n",
    "        signals_f[i].T, freqs, positions_cm[i], yaws_deg[i], timestamp=times[i]*1e3\n",
    "    )\n",
    "    #fig, ax = plt.subplots()\n",
    "    #ax.pcolorfast(wall_detection.calibration_data[0, :, :])\n",
    "    \n",
    "    if i <= WallDetection.N_CALIBRATION:\n",
    "        fg_dist_estimates.append(None)\n",
    "        fg_angle_estimates.append(None)\n",
    "        fg_colors.append(\"k\")\n",
    "        \n",
    "        angles_forward.append(None)\n",
    "        \n",
    "        distance_estimates.append(None)\n",
    "        std_estimates.append(None)\n",
    "        continue\n",
    "        \n",
    "    if res is None:\n",
    "        print(\"no result yet!\")\n",
    "        \n",
    "    #plt.plot(freqs, wall_detection.calibration[0, :])\n",
    "    #plt.plot(freqs, wall_detection.calibration_std[0, :])\n",
    "        \n",
    "    #angle_local = wall_detection.estimator.get_local_forward_angle()\n",
    "    #angles_forward.append(angle_local)\n",
    "        \n",
    "    __, __, prob_moving_dist, prob_moving_angle = res\n",
    "        \n",
    "    results_matrix_moving[:, i] = prob_moving_dist\n",
    "    \n",
    "    d, std = get_estimate(wall_detection.estimator.distances_cm, prob_moving_dist, method=estimation_method)\n",
    "    distance_estimates.append(d)\n",
    "    std_estimates.append(std)\n",
    "    \n",
    "    if not WallDetection.SIMPLIFY_ANGLES:\n",
    "        results_matrix_angles[:, i] = prob_moving_angle\n",
    "    \n",
    "    yaw = yaws_deg[i] / 180 * np.pi\n",
    "    pose_factor = wall_backend.add_pose(r_world=positions_cm[i] * 1e-2,  yaw=yaw, verbose=False)\n",
    "    #wall_backend.add_planes_from_distributions(distances_cm, prob_moving_dist, angles_deg, prob_moving_angle, n_estimates=1, verbose=True)\n",
    "    \n",
    "    wall_backend.add_plane_from_distances(wall_detection.estimator.distances_cm, prob_moving_dist, verbose=False, method=estimation_method)\n",
    "    #wall_backend.check_wall(verbose=True)\n",
    "    \n",
    "    d_estimate = wall_backend.get_distance_estimate()\n",
    "    angle_deg = wall_backend.get_angle_estimate()\n",
    "    \n",
    "    fg_dist_estimates.append(d_estimate * 1e2 if d_estimate else None)\n",
    "    fg_angle_estimates.append(angle_deg)\n",
    "    fg_colors.append(f\"C{wall_backend.plane_index+1}\")\n",
    "#plt.plot(times[:n_timesteps], angles_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_all()\n",
    "save_fig(fig, f'plots/experiments/{exp_name}{appendix}_distributions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    matrix_df = pd.read_pickle(\"results/demo_results_matrices.pkl\")\n",
    "    # full results with all paramteres\n",
    "    #matrix_df = pd.read_pickle(\"results/DistanceFlying_matrices.pkl\")\n",
    "    \n",
    "    # results with a bit fewer parameters\n",
    "    #matrix_df_0 = pd.read_pickle(\"results/DistanceFlying_matrices_std0.pkl\")\n",
    "    #matrix_df_1 = pd.read_pickle(\"results/DistanceFlying_matrices_std1.pkl\")\n",
    "    #matrix_df = pd.concat([matrix_df_0, matrix_df_1])\n",
    "except FileNotFoundError:\n",
    "    print(\"Run generate_flying_results.py to generate results.\")\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = matrix_df.columns.drop([\"matrix distances\", \"matrix angles\", \"distances_cm\", \"angles_deg\"]).values\n",
    "\n",
    "def get_title(row, ignore=[]):\n",
    "    title = ''\n",
    "    for param_name in row.index:\n",
    "        if param_name in ignore:\n",
    "            continue\n",
    "        if param_name in categories:\n",
    "            param_value = row[param_name]\n",
    "            if type(param_value) in (float, np.float64, np.float32):\n",
    "                param_value = round(param_value, 1)\n",
    "            title += f'{param_name}: {param_value}, '\n",
    "    return title\n",
    "print(get_title(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"mean\", \"peak\", \"max\"]\n",
    "row = matrix_df.iloc[0]\n",
    "matrix = row['matrix distances'][0]\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, sharex=True)\n",
    "fig.set_size_inches(20, 20)\n",
    "\n",
    "plot_groundtruth(axs[0], color=\"white\")\n",
    "plot_groundtruth(axs[1], color=\"black\")\n",
    "plot_tail(axs[3], matrix)\n",
    "\n",
    "# try different wall detection schemes\n",
    "for method in methods:\n",
    "    distance_estimates = []\n",
    "    std_estimates = []\n",
    "    \n",
    "    for i, prob_moving_dist in enumerate(matrix.T):\n",
    "        \n",
    "        d, std = get_estimate(row.distances_cm, prob_moving_dist, method=method)\n",
    "        distance_estimates.append(d)\n",
    "        std_estimates.append(std)\n",
    "    print(len(distance_estimates))\n",
    "        \n",
    "    plot_distance_estimates(axs[0], distance_estimates, label=method)\n",
    "    plot_distance_estimates(axs[1], distance_estimates, label=method)\n",
    "    plot_std_estimates(axs[2], std_estimates, label=method)\n",
    "    \n",
    "axs[1].grid(True)\n",
    "axs[1].set_ylim(5, 100)\n",
    "\n",
    "#if not WallDetection.SIMPLIFY_ANGLES:\n",
    "#    plot_angles(axs[4], results_matrix_angles)\n",
    "plot_distance_matrix(axs[0], matrix, row.distances_cm)\n",
    "\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[1].legend(loc='upper right')\n",
    "#axs[0].set_ylim(ymin, ymax)\n",
    "\n",
    "axs[0].set_title(get_title(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    scores = pd.read_pickle(\"results/DistanceFlying_classifier.pkl\")\n",
    "    scores.loc[~scores[\"mask bad\"].isin([\"adaptive\", \"fixed\"]), \"mask bad\"] = \"None\"\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Generate it using generate_flying_results.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(\n",
    "    df_here, \n",
    "    x_name = \"calibration param\",\n",
    "    y_name = \"auc\",\n",
    "    row_name = None,\n",
    "    col_name = None,\n",
    "    color_name = None,\n",
    "    marker_name = None,\n",
    "    linestyle_name = None,\n",
    "):\n",
    "    \n",
    "    from matplotlib.lines import Line2D\n",
    "    marker_list = list(Line2D.markers.keys())[1:]\n",
    "    linestyle_list = list(Line2D.lineStyles.keys())\n",
    "    \n",
    "    groupby = {}\n",
    "\n",
    "    if color_name is not None:\n",
    "        colors = {col: f\"C{i}\" for i, col in enumerate(df_here[color_name].unique())}\n",
    "        groupby[\"color\"] = color_name\n",
    "    else:\n",
    "        colors = [\"C0\"]\n",
    "    \n",
    "    if marker_name is not None:\n",
    "        markers = {mark: marker_list[i] for i, mark in enumerate(df_here[marker_name].unique())}\n",
    "        groupby[\"marker\"] = marker_name\n",
    "    else:\n",
    "        markers = [\"\"]\n",
    "    \n",
    "    if linestyle_name is not None:\n",
    "        linestyles = {ls: linestyle_list[i] for i,ls in enumerate(df_here[linestyle_name].unique())}\n",
    "        groupby[\"ls\"] = linestyle_name\n",
    "    else:\n",
    "        linestyles = [\"-\"]\n",
    "    \n",
    "    rows = df_here[row_name].unique()\n",
    "    cols = df_here[col_name].unique()\n",
    "    fig, axs = plt.subplots(len(rows), len(cols), sharey=True)\n",
    "    fig.set_size_inches(5 * len(cols), 5 * len(rows))\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, col in enumerate(cols):\n",
    "            df_plot = df_here.loc[(df_here[row_name] == row) & (df_here[col_name] == col)]\n",
    "            \n",
    "            for groupby_vals, df_col in df_plot.groupby(list(groupby.values())):\n",
    "                \n",
    "                groupby_dict = dict(zip(groupby.keys(), groupby_vals))\n",
    "                \n",
    "                # if these elements are not tin the keys, then we access\n",
    "                # 0th element of corresponding list.\n",
    "                l = groupby_dict.get(\"ls\", 0)\n",
    "                c = groupby_dict.get(\"color\", 0)\n",
    "                m = groupby_dict.get(\"marker\", 0)\n",
    "                \n",
    "                axs[i, j].plot(df_col[x_name], df_col[y_name], ls=linestyles[l], marker=markers[m], color=colors[c])\n",
    "            axs[i, j].grid(True)\n",
    "    [axs[0, j].set_title(f\"{col_name}:\\n{col}\") for j, col in enumerate(cols)]\n",
    "    [axs[i, -1].twinx().set_ylabel(f\"{row_name}:\\n{row}\") for i, row in enumerate(rows)]\n",
    "    [axs[i, -1].twinx().set_yticks([]) for i, row in enumerate(rows)]\n",
    "    \n",
    "    if linestyle_name is not None:\n",
    "        for label, ls in linestyles.items():\n",
    "            axs[0, -1].plot([], [], ls=ls, label=label, color=\"C0\")\n",
    "        axs[0, -1].legend(title=linestyle_name)    \n",
    "    \n",
    "    if marker_name is not None:\n",
    "        for label, marker in markers.items():\n",
    "            axs[1, -1].plot([], [], marker=marker, label=label, color=\"C0\")\n",
    "        axs[1, -1].legend(title=marker_name)    \n",
    "        \n",
    "    if color_name is not None:\n",
    "        for label, color in colors.items():\n",
    "            axs[2, -1].plot([], [], color=color, label=label)\n",
    "        axs[2, -1].legend(title=color_name)    \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_here = scores[scores.method == \"distance-mean\"]\n",
    "fig, axs = plot_grid(df_here, \n",
    "    row_name = \"mask bad\",\n",
    "    col_name = \"calibration name\",\n",
    "    x_name = \"calibration param\",\n",
    "    y_name = \"auc\",\n",
    "    color_name = \"n window\",\n",
    "    marker_name = \"simplify angles\",\n",
    "    linestyle_name = \"relative std\"\n",
    ")\n",
    "\n",
    "#import seaborn as sns\n",
    "#g = sns.FacetGrid(df_here, col=\"calibration name\", row=\"mask bad\", hue=\"n window\", margin_titles=True)\n",
    "#g.map(sns.pointplot, \"calibration param\", \"auc\")\n",
    "#g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# based on above, choose parameters. \n",
    "\n",
    "from generate_classifier_results import get_groundtruth_distances, get_precision_recall, THRESHOLDS_DICT\n",
    "from utils.pandas_utils import filter_by_dict\n",
    "\n",
    "chosen_method = \"distance-mean\"\n",
    "chosen_dict = {\n",
    "    \"n window\": None, # is filled below\n",
    "    \"simplify angles\": False,\n",
    "    \"relative std\": 0.0,\n",
    "    \"calibration name\": \"iir\",\n",
    "    \"calibration param\": 0.3,\n",
    "    \"mask bad\": \"None\"\n",
    "}\n",
    "\n",
    "distances_wall = get_groundtruth_distances(\"2022_01_27_demo\", \"test4\") \n",
    "matrix_df.loc[~matrix_df[\"mask bad\"].isin([\"adaptive\", \"fixed\"]), \"mask bad\"] = \"None\"\n",
    "matrix_df = matrix_df.apply(pd.to_numeric, errors='ignore', axis=0)\n",
    "matrix_df[\"calibration param\"] = np.round(matrix_df[\"calibration param\"], 1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "delta = 0.05\n",
    "for i_window, n_window in enumerate([3, 5, 10]):\n",
    "    chosen_dict[\"n window\"] = n_window\n",
    "    rows = filter_by_dict(matrix_df, chosen_dict)\n",
    "    #[print(key, matrix_df[key].unique()) for key in chosen_dict.keys()]\n",
    "    assert len(rows) == 1, len(rows)\n",
    "    matrix = rows.iloc[0][\"matrix distances\"][0]\n",
    "    precision, recall = get_precision_recall(matrix, distances_wall, method=chosen_method, verbose=False, sort=False) \n",
    "    ax.plot(precision, recall, marker='o', label=f\"n window: {n_window}\")\n",
    "    thresholds = THRESHOLDS_DICT[chosen_method]\n",
    "    for t, p, r in zip(thresholds, precision, recall):\n",
    "        if r < 1: \n",
    "            ax.annotate(t, (p + -delta*i_window, r+delta*i_window))\n",
    "    fig_mat, ax_mat = plt.subplots()\n",
    "    ax_mat.pcolorfast(np.arange(matrix.shape[1]), DISTANCES_CM, np.log10(matrix))\n",
    "    ax_mat.plot(DISTANCES_CM[np.argmax(matrix, axis=0)], color='white')\n",
    "ax.set_xlabel(\"precision\")\n",
    "ax.set_ylabel(\"recall\")\n",
    "ax.set_xlim(-0.1, 1.1)\n",
    "ax.set_ylim(-0.1, 1.1)\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "ax.legend(loc='upper left', bbox_to_anchor=[1.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### alternative angle calculation: geometric averaging based on mic level differences\n",
    "\n",
    "mic_angles = np.array([90, 180, -90, 0])\n",
    "mics = [0, 1, 2, 3]\n",
    "\n",
    "total = np.sum(magnitudes[:, :, :]**2, axis=(0, 2))\n",
    "powers = np.sum(magnitudes[:, mics]**2, axis=2) / total[None, :]\n",
    "\n",
    "fig = plt.figure()\n",
    "for i, mic in enumerate(mics): #range(powers.shape[1]):\n",
    "    plt.plot(range(powers.shape[0]), powers[:, i], label=f\"mic{mic}\")\n",
    "plt.legend()\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "fig = plt.figure()\n",
    "norm = powers[:] / np.mean(powers, axis=1)[:, None]\n",
    "print(norm[0, :])\n",
    "\n",
    "angle_vectors = np.array([[np.cos(a / 180 * np.pi), np.sin(a / 180 * np.pi)] for a in mic_angles[mics]])\n",
    "vectors = norm.dot(angle_vectors)\n",
    "angles = np.arctan2(vectors[:, 1], vectors[:, 0]) * 180 / np.pi\n",
    "weights = np.linalg.norm(vectors, axis=1)\n",
    "\n",
    "significant = np.where(weights > 0.2)[0]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(range(powers.shape[0]), angles, label=f\"all\")\n",
    "plt.scatter(significant, angles[significant], label=f\"significant\")\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(range(powers.shape[0]), weights, label=f\"mic{mic}\")\n",
    "fig.set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### statistics tests for alternatives to exponentiation in moving average\n",
    "\n",
    "import scipy.stats\n",
    "import scipy.signal\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "scale1 = 1.0\n",
    "scale2 = 4.0\n",
    "loc1=0\n",
    "loc2=3.0\n",
    "step = 0.1\n",
    "xmax = 30\n",
    "\n",
    "n1 = scipy.stats.norm(loc=loc1, scale=scale1)\n",
    "n2 = scipy.stats.norm(loc=loc2, scale=scale2)\n",
    "\n",
    "scale_conv = np.sqrt(scale1**2 + scale2**2)\n",
    "n_conv = scipy.stats.norm(loc=loc1 + loc2, scale=scale_conv)\n",
    "\n",
    "values = np.arange(-xmax, xmax, step=step)\n",
    "n1_pdf = n1.pdf(values)\n",
    "n1_pdf /= np.sum(n1_pdf)\n",
    "plt.plot(values, n1_pdf, label=f'N1')\n",
    "\n",
    "n2_pdf = n2.pdf(values)\n",
    "n2_pdf /= np.sum(n2_pdf)\n",
    "plt.plot(values, n2_pdf, label=f'N2')\n",
    "\n",
    "n_conv_pdf = n_conv.pdf(values)\n",
    "n_conv_pdf /= np.sum(n_conv_pdf)\n",
    "plt.plot(values, n_conv_pdf, label=f'analytical')\n",
    "\n",
    "# compute new distribution through exponentiation. \n",
    "n2_new = scipy.stats.norm(loc1 + loc2, scale=scale1)\n",
    "alpha = scale1**2 / (scale1**2 + scale2**2)\n",
    "\n",
    "n2_approx_pdf = n2_new.pdf(values) ** alpha\n",
    "n2_approx_pdf /= np.sum(n2_approx_pdf)\n",
    "plt.plot(values, n2_approx_pdf, label=f'N1 ^ {alpha:.1f}', ls=\":\", color='C0')\n",
    "\n",
    "n2_conv = scipy.signal.fftconvolve(n1_pdf, n2_pdf, mode='same')\n",
    "plt.plot(values, n2_conv, label=f'N1 * N2', ls=\":\", color='C1')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "multimodal = np.zeros(len(values))\n",
    "means = [-5, 0, 7.5]\n",
    "stds = [1, 2, 3]\n",
    "print(dict(zip(means, stds)))\n",
    "plt.figure()\n",
    "for mean, std in zip(means, stds):\n",
    "    mode = scipy.stats.norm(loc=mean, scale=std)\n",
    "    multimodal += mode.pdf(values)\n",
    "    #plt.plot(values, vals, color='C2', ls=':')\n",
    "multimodal /= np.sum(multimodal)\n",
    "plt.plot(values, multimodal, color='C0', label='P1')\n",
    "plt.plot(values, n2_pdf, color='C1', label='N2')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.figure()\n",
    "# shift multimodal distribution\n",
    "for scale in np.linspace(min(stds), max(stds), 3):\n",
    "    alpha = scale**2 / (scale**2 + scale2**2)\n",
    "    multimodal_approx_pdf = np.zeros_like(multimodal) \n",
    "    shift = int((loc2 - loc1) / step)\n",
    "    if shift > 0:\n",
    "        multimodal_approx_pdf[shift:] = multimodal[:int(len(multimodal) - shift)] ** alpha\n",
    "    else:\n",
    "        multimodal_approx_pdf[:int(len(multimodal) - shift)] = multimodal[shift:] ** alpha\n",
    "    multimodal_approx_pdf /= np.sum(multimodal_approx_pdf)\n",
    "    plt.plot(values, multimodal_approx_pdf, label=f'P1 ^ {alpha:.1f} (std={scale:.1f})', ls=\"-\")\n",
    "\n",
    "multimodal_conv = scipy.signal.fftconvolve(multimodal, n2_pdf, mode='same')\n",
    "multimodal_conv /= np.sum(multimodal_conv)\n",
    "plt.plot(values, multimodal_conv, label=f'P1 * N2', ls=\"-\")\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "import timeit\n",
    "print(\"time for convolution: \", end=\"\")\n",
    "print(round(timeit.timeit(stmt='scipy.signal.fftconvolve(multimodal, n2_pdf, mode=\"same\")', globals=globals(), number=1000), 2))\n",
    "print(\"time for exponentiation: \", end=\"\")\n",
    "print(round(timeit.timeit(stmt='multimodal_approx_pdf[shift:] = multimodal[:int(len(multimodal) - shift)] ** alpha', globals=globals(), number=1000), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
